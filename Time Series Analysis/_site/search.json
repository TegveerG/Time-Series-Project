[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tegveer Ghura",
    "section": "",
    "text": "Tegveer is a first-year graduate student pursuing an MS in Data Science & Analytics at Georgetown University. When not producing insights from data, Tegveer enjoys spending time playing cricket and exploring the DMV."
  },
  {
    "objectID": "Data-Visualization.html",
    "href": "Data-Visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "The analysis of the data collected begins from this pivotal section. Every data science project, especially those utilizing Time Series data, starts with Data Visualization because it allows for easy and intuitive interpretation of complex data sets. These visualizations help data scientists identify patterns, trends, and relationships that might otherwise be difficult to discern by looking at the summary statistics the raw data, for example. The visualizations presented below were created using Tableau and the packages ggplot2 and Plotly in the R software.\nCode for this section can be found here"
  },
  {
    "objectID": "Data-Visualization.html#ethereum-eth-line-plots",
    "href": "Data-Visualization.html#ethereum-eth-line-plots",
    "title": "Data Visualization",
    "section": "Ethereum (ETH) Line Plots",
    "text": "Ethereum (ETH) Line Plots\n\n\n\n\nStatic PlotInteractive Plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestors who bought stocks during the COVID-19 market crash in 2020 have generally experienced some big gains in the past two years. Several factors led to a surge in Ethereum buying in 2020 and especially in 2021. Younger Americans receiving three rounds of direct stimulus payments have poured a significant chunk of that cash into investments, including Ethereum. In addition, cryptocurrency investing became extremely trendy in 2021, and Ethereum was one of the most popular cryptos in the market. At the beginning of 2020, Ethereum was trading around $129. By the beginning of March, the cryptocurrency had risen to $218 as news of the virus spreading in China prompted concerns about a U.S. pandemic. On March 13, 2020, Ethereum plummeted to its pandemic low of $88.50 as global stock markets tanked. The good news for Ethereum investors is the crypto bounced off that level as the stock market began to stabilize shortly thereafter and the government started printing money."
  },
  {
    "objectID": "Data-Visualization.html#ethereum-candlestick-plot",
    "href": "Data-Visualization.html#ethereum-candlestick-plot",
    "title": "Data Visualization",
    "section": "Ethereum Candlestick Plot",
    "text": "Ethereum Candlestick Plot\n\n\n\n\n\n\nTo visualize the candlesticks carefully, we subset the data by viewing only the last few months’ data from the current date, January 15th 2023. Ethereum’s price was generally decreasing since November 2022, experiencing massive drops on November 9th notably. The crypto was trading at a similar level until the hopeful New Year, which then saw its price increase back to former levels in November 2022."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Tegveer Ghura",
    "section": "Education",
    "text": "Education\nBoston University | Boston, MA\nB.A (Cum Laude) Economics | Sept 2017 - May 2021\nGeorgetown University | Washington, DC\nM.S Data Science & Analytics | Aug 2022 - May 2024 (anticipated)"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Tegveer Ghura",
    "section": "Experience",
    "text": "Experience\nMetricStream, Inc. | Finance Associate | Sept 2021 - Apr 2022\nMetricStream, Inc. | Finance Intern | June 2021 - Aug 2022\nUnimoni Financial Services Ltd. | Project Intern | Jul 2019 - Aug 2019"
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Warning\n\n\n\nTrigger warning: The following content contains descriptions of violent acts and extremism related to terrorism, which may be disturbing or triggering for some readers.\n\n\nTerrorism is a puzzling and gripping phenomenon. Its relationship with tourism is intricate and multi-dimensional. Interestingly, international terrorism and tourism share common traits, such as being transnational in nature, involving citizens from different nations, and utilizing travel and communication technologies. The impact of terrorist attacks extends to several other industries related to tourism, including airlines, hotels, restaurants, and tourist-oriented shops and services (Baker, n.d.).\n\nBaker, David. n.d. “The Effects of Terrorism on the Travel and Tourism Industry.” International Journal of Religious Tourism and Pilgrimage. https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1052&amp;context=ijrtp.\n\n“World Tourism Organization.” n.d. UNWTO. https://www.unwto.org/.\nReceipts from international tourism in destinations around the world grew by 4% in 2012 reaching USD 1,075 billion. This growth is equal to a 4% increase in international tourist arrivals over the previous year which reached 1,035 million in 2012. An additional USD 219 billion was recorded in receipts from international passenger transport, bringing total exports generated by international tourism in 2012 to US$ 1.3 trillion (“World Tourism Organization,” n.d.).\n\n\n\n\n\n\n\n\n\nThe Global Terrorism Database™ (GTD) (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.) defines a terrorist attack as the threatened or actual use of illegal force and violence by a nonstate actor to attain a political, economic, religious, or social goal through fear, coercion, or intimidation. In practice this means in order to consider an incident for inclusion in the GTD (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.), all three of the following attributes must be present:\n\nThe incident must be intentional – the result of a conscious calculation on the part of a perpetrator.\nThe incident must entail some level of violence or immediate threat of violence, including property violence, as well as violence against people.\nThe perpetrators of the incidents must be sub-national actors. The database does not include acts of state terrorism.\n\nIn addition, at least two of the following three criteria must be present for an incident to be included in the GTD (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.):\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\n\nCriterion 1: The act must be aimed at attaining a political, economic, religious, or social goal. In terms of economic goals, the exclusive pursuit of profit does not satisfy this criterion. It must involve the pursuit of more profound, systemic economic change.\nCriterion 2: There must be evidence of an intention to coerce, intimidate, or convey some other message to a larger audience (or audiences) than the immediate victims. It is the act taken as a totality that is considered, irrespective if every individual involved in carrying out the act was aware of this intention. As long as any of the planners or decision-makers behind the attack intended to coerce, intimidate or publicize, the intentionality criterion is met.\nCriterion 3: The action must be outside the context of legitimate warfare activities. That is, the act must be outside the parameters permitted by international humanitarian law, insofar as it targets non-combatants"
  },
  {
    "objectID": "Data-Sources.html",
    "href": "Data-Sources.html",
    "title": "Data Sources",
    "section": "",
    "text": "In order to collect time-series data on terrorism, choosing The Global Terrorism Database™ (GTD) by University of Maryland was a pragmatic decision because it contains detailed information of global attacks that occurred daily. This gave enormous flexibility to search for short-term seasonal patterns, if any, regarding terrorist attacks. For assessing the impact of terrorism on economic activity, the SIPRI Military Expenditure Database was employed. Military expenditure as a share of GDP can provide key insights about a country’s allocation of resources. Nonimmigrant Admissions data was also collected from the Department of Homeland Security (DHS) to add an extra dimension of how the sentiment of the US government changed regarding tourist admits in the overall analysis.\nThe Quantmod R package seamlessly allows R users to get stock data, which aids in exploring both changes in prices due to certain terror attacks and how weapons manufacturing companies reacted to these attacks. To analyze domestic financial impacts from terror attacks at a granular level, daily historical stock prices of some of the largest weapons manufacturers in the United States, including Lockheed Martin and Raytheon Technologies, were obtained. Not only stock prices of individual companies, but also data of the Dow Jones U.S. Travel & Tourism Index was gathered to approach the financial analysis at a larger scale."
  },
  {
    "objectID": "Data-Sources.html#the-global-terrorism-database-gtd-by-university-of-maryland",
    "href": "Data-Sources.html#the-global-terrorism-database-gtd-by-university-of-maryland",
    "title": "Data Sources",
    "section": "The Global Terrorism Database™ (GTD) by University of Maryland",
    "text": "The Global Terrorism Database™ (GTD) by University of Maryland\nAn open-source database containing information on terrorist events around the world from 1970 through 2020 (with annual updates planned for the future). Unlike many other event databases, the GTD includes systematic data on domestic as well as international terrorist incidents that have occurred during this time period and now includes more than 200,000 cases.\n\n\n\nClick on the logo to access the data!"
  },
  {
    "objectID": "Data-Sources.html#sipri-military-expenditure-database",
    "href": "Data-Sources.html#sipri-military-expenditure-database",
    "title": "Data Sources",
    "section": "SIPRI Military Expenditure Database",
    "text": "SIPRI Military Expenditure Database\nThe SIPRI Military Expenditure Database contains consistent time series on the military spending of countries for the period 1949–2021. The database is updated annually, which may include updates to data for any of the years included in the database. The main purpose of the data on military expenditure is to provide an easily identifiable measure of the scale of resources absorbed by the military. Military expenditure is an input measure which is not directly related to the ‘output’ of military activities, such as military capability or military security. Military expenditure data measured in constant dollars is a trend indicator of the volume of resources used for military activities, which allow comparisons to be made over time for individual countries and between countries.\n\n\n\nClick on the logo to access the data!"
  },
  {
    "objectID": "Data-Sources.html#department-of-homeland-security-dhs",
    "href": "Data-Sources.html#department-of-homeland-security-dhs",
    "title": "Data Sources",
    "section": "Department of Homeland Security (DHS)",
    "text": "Department of Homeland Security (DHS)\nThe United States Department of Homeland Security (DHS) is the U.S. federal executive department responsible for public security, roughly comparable to the interior or home ministries of other countries. Its stated missions involve anti-terrorism, border security, immigration and customs, cyber security, and disaster prevention and management. Collected data comprises of the following US Visa holders from the years 1998 to 2021:\n\nTemporary Business Visitors (B-1, WB, CNMI, GMB)\nTemporary Visitors for Pleasure - Tourism/Vacation or Medical Treatment (B-2, WT, CNMI, GMT)\nStudents (F-1, F-2, M-1, M-2)\n\n\n\n\nClick on the logo to access the data!"
  },
  {
    "objectID": "Data-Sources.html#quantmod-r-package",
    "href": "Data-Sources.html#quantmod-r-package",
    "title": "Data Sources",
    "section": "Quantmod R Package",
    "text": "Quantmod R Package\nThe quantmod package for R is designed to assist the quantitative trader in the development, testing, and deployment of statistically based trading models. The getSymbols() function in the package aids in collecting stock price data of US companies and indexes. As previously mentioned, the historical stock prices of Lockheed Martin and the Dow Jones U.S. Travel & Tourism Index were chosen for this analysis.\nSee data collection code and time-series plots below:\n\n\n\n\n\nShow the code\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\n# Collecting Lockheed Martin's Stock Price since IPO\n\ntickers = c(\"LMT\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"1995-03-17\",\n             to = \"2023-01-30\")}\n\nlmt <- data.frame(LMT$LMT.Adjusted)\n\nlmt <- data.frame(lmt,rownames(lmt))\ncolnames(lmt) <- append(tickers,'Dates')\n\nlmt$date<-as.Date(lmt$Dates,\"%Y-%m-%d\")\n\n# Collecting Raytheon Tech Corp Stock Price since IPO\n\ntickers = c(\"RTX\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"1983-03-04\",\n             to = \"2023-01-30\")}\n\nrtx <- data.frame(RTX$RTX.Adjusted)\n\nrtx <- data.frame(rtx,rownames(rtx))\ncolnames(rtx) <- append(tickers,'Dates')\n\nrtx$date<-as.Date(rtx$Dates,\"%Y-%m-%d\")\n\n# Collecting DJUSTT since formation\n\ntickers = c(\"^DJUSTT\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"2008-12-01\",\n             to = \"2023-01-30\")}\n\ndow <- data.frame(DJUSTT$DJUSTT.Adjusted)\n\ndow <- data.frame(dow,rownames(dow))\ncolnames(dow) <- append(tickers,'Dates')\ncolnames(dow)[1] =\"DJUSTT\"\n\ndow$date<-as.Date(dow$Dates,\"%Y-%m-%d\")\n\n\n\nVisualizing Lockheed Martin’s and Raytheon Tech’s Stock Prices and Dow Jones U.S. Travel & Tourism Index\n\nLockheed MartinRaytheon Technologies (formerly American Appliance Company)Dow Jones U.S. Travel & Tourism Index\n\n\n\n\nShow the code\ng1 <- ggplot(lmt, aes(x=date, y=LMT)) +\n  geom_line(color=\"#005BAD\") +\n   labs(\n    title = \"Stock Prices for Lockheed Martin\",\n    subtitle = \"From Dec 2008 - January 2023\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices ($)\") + \n  theme_minimal() \n\nggplotly(g1) %>%\n  layout(hovermode = \"x\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ng2 <- ggplot(rtx, aes(x=date, y=RTX)) +\n  geom_line(color=\"#E61231\") +\n   labs(\n    title = \"Stock Prices for Raytheon Technologies\",\n    subtitle = \"From Mar 1983 - January 2023\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices ($)\") + \n  theme_minimal() \n\nggplotly(g2) %>%\n  layout(hovermode = \"x\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ng3 <- ggplot(dow, aes(x=date, y=DJUSTT)) +\n  geom_line() +\n   labs(\n    title = \"Dow Jones U.S. Travel & Tourism Index\",\n    subtitle = \"From March 2020 - December 2022\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices ($)\") + \n     theme_minimal() \n\nggplotly(g3) %>%\n  layout(hovermode = \"x\")"
  },
  {
    "objectID": "Data-Sources.html#questions-to-adress",
    "href": "Data-Sources.html#questions-to-adress",
    "title": "Data Sources",
    "section": "Questions to Adress",
    "text": "Questions to Adress\n Q1\n Q2\n Q3\n Q4\n Q5\n Q6\n Q7\n Q8\n Q9\n Q10"
  },
  {
    "objectID": "Introduction.html#questions-to-adress",
    "href": "Introduction.html#questions-to-adress",
    "title": "Introduction",
    "section": "Questions to Adress",
    "text": "Questions to Adress\n How has the pattern of conducting terror attacks in the United States evolved over the last 50 years?\n How have the targets or victims of terror attacks in the United States evolved over the last 50 years?\n Do certain states in the United States suffer more terrorist attacks than others do?\n Are we able to use univariate time-series models (ARIMA/SARIMA) on monthly number of terrorist attacks (1970-2020) to predict the number of future attacks in the United States?\n Can multivariate time series models, including ARIMAX and VAR, help us predict the number of yearly attacks in the United States by employing other variables, such as yearly US military expenditure as a percentage of US GDP and yearly number of non-immigrant entrants (B-1, B-2, F-1 visa)?\n What is the correlation between terror attacks and military expenditure over time in the United States? How robust is the VAR model in doing so and does the literature review support the findings?\n How do the predictions of yearly number of terrorist attacks obtained from the full ARIMAX model differ from other time series models (univariate and multivariate) and from Deep Recurrent Neural Networks?\n With the help of volatility plots obtained from fitting ARCH/GARCH models, to what extent do stock prices of Lockheed Martin, Raytheon Technologies, and the Dow Jones U.S. Travel & Tourism Index help us understand trends in terrorist attacks in the United States?\n Can Deep Recurrent Neural Networks capture best the underlying ground truth of the pattern of monthly terrorist attacks from 1970-2020? Which Deep Recurrent Neural Networks perform best and why?\n How far into the future can Deep Recurrent Neural Networks forecast or predict the monthly number of terrorist attacks? Which Deep Recurrent Neural Networks perform best and why?"
  },
  {
    "objectID": "Introduction.html#public-us-sentiment",
    "href": "Introduction.html#public-us-sentiment",
    "title": "Introduction",
    "section": "Public US Sentiment",
    "text": "Public US Sentiment\nThe September 11 attacks, commonly known as 9/11, on the World Trade Center in 2001 were a historic aberration in US history, with significant and far-reaching impacts on national security policy, international relations, and the collective psyche of the American people. Immediately after the 9/11 attacks, public sentiment in the US was marked by a strong sense of shock, anger, and a desire for justice, along with a surge in patriotism and a willingness to support government actions to prevent future terrorist attacks. There was also a significant increase in concerns about national security and a greater willingness to sacrifice personal freedoms in the interest of greater security. The figure below conveys that, immediately after 9/11, a share of the US public’s stance on venturing outdoors and travelling overseas stagnated for the next decade. The public’s confidence seemed to restore around 2011."
  },
  {
    "objectID": "Introduction.html#references",
    "href": "Introduction.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\nBaker , David. “The Effects of Terrorism on the Travel and Tourism Industry .” Technological University Dublin. International Journal of Religious Tourism and Pilgrimage. Accessed February 1, 2023. https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1052&context=ijrtp.\n“Codebook Methodology Inclusion Criteria and Ariables - UMD.” Codebook Methodology Inclusion criteria and variables - UMD. University of Maryland. Accessed February 1, 2023. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\n“World Tourism Organization.” UNWTO. Accessed February 1, 2023. https://www.unwto.org/."
  },
  {
    "objectID": "Data-Visualization.html#visualizing-the-gtd",
    "href": "Data-Visualization.html#visualizing-the-gtd",
    "title": "Data Visualization",
    "section": "Visualizing the GTD™",
    "text": "Visualizing the GTD™\nFor the purpose of this project, the focus will be on the United States, so the data has been filtered accordingly. An important point to keep in mind is that incidents of terrorism from 1993 are not present in the GTD™ because they were lost by the authors. Hence, few visualizations created in R, using the GTD™, do reflect this aberration, as missing values for the year 1993 were not imputed.\nTo start, the visualizations below provide a general overview of how the number of terrorist attacks and fatalities have changed over time.\n\nEvolution of Volume of Terrorist Attacks and Fatalaties (1970-2020) in the US\n\nNumber of Monthly Attacks and FatalitiesNumber of Monthly Attacks and Fatalities (adjusted for 9/11)Cumulative Count of Terrorist Attacks & Fatalities\n\n\n\n\nCode\nplot_ly(data=gtd_monthly_attacks_deaths, x=~Date)  %>% \n    add_trace(type = 'scatter', mode = 'lines', y=~num_attacks, \n            name=\"Attacks\", line = list(color = 'red')) %>%\n    add_trace(type = 'scatter', mode = 'lines', y=~num_fatal, \n            name=\"Fatalities\", line = list(color = 'black')) %>%\n  layout(title=\"Monthly Count of Terrorist Attacks & Fatalities in the US\",\n         yaxis=list(title=(\"Count\")),\n         xaxis=list(title=(\"Date\"))) %>%\n  layout(hovermode = \"x\")\n\n\n\n\n\n\n\n\n\n\nCode\nplot_ly(data=gtd_monthly_attacks_deaths %>% filter(num_fatal<20), x=~Date)  %>% \n    add_trace(type = 'scatter', mode = 'lines', y=~num_attacks, \n            name=\"Attacks\", line = list(color = 'red')) %>%\n    add_trace(type = 'scatter', mode = 'lines', y=~num_fatal, \n            name=\"Fatalities\", line = list(color = 'black')) %>%\n  layout(title=\"Monthly Count of Terrorist Attacks & Fatalities in the US\",\n         yaxis=list(title=(\"Count\")),\n         xaxis=list(title=(\"Date\"))) %>%\n  layout(hovermode = \"x\")\n\n\n\n\n\n\n\n\n\n\nCode\ngtd_yearly <- gtd_USA %>% \n              group_by(year(Date)) %>% \n                  summarise(num_attacks = n(), \n                            nkill=sum(nkill))\n\ngtd_yearly_cum_attacks_deaths <- gtd_yearly %>% \n                      summarise(cum_attacks=cumsum(num_attacks),\n                             cum_deaths = cumsum(nkill)) %>% \n  mutate(Date=gtd_yearly$`year(Date)`)\n\nplot_ly(data=gtd_yearly_cum_attacks_deaths, x=~Date)  %>% \n    add_trace(type = 'scatter', mode = 'lines', y=~cum_attacks, \n            name=\"Cumulative Attacks\", line = list(color = 'red')) %>%\n    add_trace(type = 'scatter', mode = 'lines', y=~cum_deaths, \n            name=\"Cumulative Fatalities\", line = list(color = 'black')) %>%\n  layout(title=\"Yearly Cumulative Count of Terrorist Attacks & Fatalities in the US\",\n         yaxis=list(title=(\"Cumulative Count\")),\n         xaxis=list(title=(\"Date\"))) %>%\n  layout(hovermode = \"x\")\n\n\n\n\n\n\n\n\n\nThe first plot (Number of Monthly Attacks and Fatalities) conveys the significance of the 9/11 Attacks on US history. The big black spike in fatalities, totaling approximately 3000, is representative of the attack and an “outlier” from both series. As a result, in order to depict the trend of both series clearly, it was imperative to filter out the 9/11 Attacks and that is why the second plot was created. A cumulative graph of number of attacks and fatalities is showcased as well that provides further context about the impact of the 9/11 Attacks. Total fatalities were much lower than total number of attakcs from 1970 to 2000, but the toll of the 9/11 Attacks were significant enough to surpass the 2,424 attacks that occurred up until the tragedy.\nMoreover, the total number of fatalities between 1970 and 2000 was 492 and the total number of fatalities between 2001 and 2020 was 419, suggesting that attacks apart from 9/11 follow a similar trend in death rate. Lastly, the number of attacks between the years 1976 and 2004 follow a concave shape, implying that the volume of attacks must be diminishing through the years. However, a steep, exponential rise in not only the number of attacks but also the number of fatalities is noticed after 2004!\nHere are a few facts (“Terrorist Attacks in the u.s Between 1970 and 2013: Data from the ... - DHS,” n.d.) attacks in the US between 1970 and 2013:\n\nApproximately 85% of all deaths from terrorist attacks during this period occurred in the coordinated attacks on September 11, 2001.\nNearly 80% of all terrorist attacks involved no casualties (fatalities or injuries).\nMore than half of terrorist attacks took place during the 1970s. Between 2000 and 2013, there were fewer than 20 attacks per year on average.\n\n\n\nEvolution of Terrorist Attacks: Approach, Victims, and Weapons (Raw Counts)\n\nNumber of Distinct Attacks Over TimeTrends in Attacks Over Time by Victim TypeTrends in Attacks Over Time by Weapon Type\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nThe above bar chart races allow for an animated way to display the number of attacks changing over time by the categorical variables, Attack Type, Victim Type, and Weapon Type. The 1970s and 1980s were dominated by Bombing/Explosion Terrorist Attacks in the US, with Facility/Infrastructure Attacks gaining momentum by the end of the 1980s. Many of these bombings were carried out by leftist extremist groups, such as the Weather Underground and the Black Liberation Army, who were motivated by a variety of political and social causes, including opposition to the Vietnam War, racial injustice, and government oppression (Serrano 2008).\n\nSerrano, Richard A. 2008. “The 1970s Bombing Spree.” Los Angeles Times.\n\nRosenau, William. n.d. “Leftist Terrorism in the United States.” Taylor &Amp; Francis. The Journal of Strategic Studies (2013). https://www.tandfonline.com/journals/fjss20.\nOne factor that contributed to the prevalence of domestic bombing attacks during this period was the rise of radical political activism and social unrest. The Vietnam War was a major source of division in American society, and many activists were inspired to use violent tactics in their protests. Additionally, the civil rights movement and the Black Power movement brought attention to issues of racial inequality, and some extremist groups sought to further their agendas through bombings and other violent actions. Another factor was the relative ease with which these groups could obtain explosives and other materials necessary to carry out bombings. Many of the bombs used in these attacks were constructed using readily available materials such as dynamite and pipe bombs, and there were few restrictions on the purchase of these materials at the time (Rosenau, n.d.).\nIn the 1970s and 1980s, a majority of the victims of these attacks included businesses (corporate offices, restaurants, gas stations, bars, cafés, etc.), the government (government building, government member, former members, or events sponsored by political parties, etc.), and private citizens and property (the public in general or attacks in public areas including markets, commercial streets, busy intersections and pedestrian malls) (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.). Moreover, numerous attacks on abortion clinics were conducted in the 1980s and 1990s by anti-abortion activists. These attacks took various forms, including bombings, arson, and other acts of violence, as well as peaceful protests and acts of civil disobedience. Another factor that contributed to the attacks on abortion clinics was the political and legal context of the time. In 1973, the US Supreme Court issued its landmark decision in Roe v. Wade, which established a constitutional right to abortion. This decision was highly controversial and sparked a wave of political and social activism on both sides of the issue.\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\nFrom recent years, the data portrays an increase in attacks against both Religious Figures/Institutions and the police. Therefore, terrorists’ aims and agendas have transformed over time as the underlying narrative of a country’s political climate changes. In a smaller sense, to conduct an attack, the US has also suffered from the evolution of weapons used by terrorists. As aforementioned, the 1970s and 1980s experienced bombings as the majority of attacks and the weapons used during that time support this finding. Explosives and incendiaries made up the majority of weapons used in the 1970s and 1980s, with firearms gaining traction. By the late 90s, less use of explosives is seen and a shift to incendiaries, firearms, chemical, and biological weapons becomes prominent.\nHere are some more facts (“Terrorist Attacks in the u.s Between 1970 and 2013: Data from the ... - DHS,” n.d.) related to the bar chart races:\n\n“Terrorist Attacks in the u.s Between 1970 and 2013: Data from the ... - DHS.” n.d. Terrorist Attacks in the U.S Between 1970 and 2013: Data from the Global Terrorism Database (GTD). START Consortium at the University of Maryland. https://www.dhs.gov/sites/default/files/publications/OPSR_TP_TEVUS_Terrorist-Attacks-US_1970-2013_Overview-508.pdf.\n\n94% of attacks against abortion‐related targets were on clinics, while 6% targeted providers or personnel.\n78% of attacks against educational targets were on schools, universities, or\nother buildings, while 22% targeted teachers or other educational personnel.\n73% of attacks against government targets were on government buildings, facilities, or offices, while 27% targeted personnel, public officials, or politicians.\n\n\n\nEvolution of Terrorist Attacks: Approach, Victims, and Weapons (Percent of Total)\n\nPercentage of Distinct Attacks Over TimePercentage of Attacks Over Time by Victim TypePercentage of Attacks Over Time by Weapon Type\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\nEvolution of Terrorist Attacks By US State (Geospatial)"
  },
  {
    "objectID": "Introduction.html#bibliography",
    "href": "Introduction.html#bibliography",
    "title": "Introduction",
    "section": "Bibliography",
    "text": "Bibliography"
  },
  {
    "objectID": "Data-Visualization.html#visualizing-the-sipri-military-expenditure-database",
    "href": "Data-Visualization.html#visualizing-the-sipri-military-expenditure-database",
    "title": "Data Visualization",
    "section": "Visualizing the SIPRI Military Expenditure Database",
    "text": "Visualizing the SIPRI Military Expenditure Database\n\n\nCode\n# new dataframe for total number of attacks 1970-2020\nsipri_usa <- sipri_gdp %>% filter(Country==\"United States of America\")\n\n# transpose to make columns into rows\nsipri_usa <- as.data.frame(t(sipri_usa))\nsipri_usa <- as.numeric(sipri_usa[-1,]) # delete first row \nsipri_usa <- round(sipri_usa*100, 4)\n\n# convert to time series object\nsipri_usa_ts <- ts(sipri_usa, start = c(1949), frequency = 1)\n\ng <- autoplot(sipri_usa_ts, \n         main=\"Yearly US Military Expenditure as % of GDP\",\n         ylab = \"Military Expenditure as % of GDP\",\n         xlab = \"Date\") +\n  theme_minimal()\nggplotly(g) %>% layout(hovermode = \"x\")"
  },
  {
    "objectID": "Data-Visualization.html#visualizing-department-of-homeland-securitys-non-immigrant-admissions-data",
    "href": "Data-Visualization.html#visualizing-department-of-homeland-securitys-non-immigrant-admissions-data",
    "title": "Data Visualization",
    "section": "Visualizing Department of Homeland Security’s Non-Immigrant Admissions Data",
    "text": "Visualizing Department of Homeland Security’s Non-Immigrant Admissions Data\n\n\nCode\ndhs <- dhs %>% filter(Year>=2002)\nfig <- plot_ly(dhs, x = ~Year, y = ~`Temporaryvisitorsforpleasure(B2)`,name = 'B2 Tourist Visa Holders', type = 'scatter', mode = 'lines')\nfig <- fig %>% add_trace(y = ~`Temporaryvisitorsforbusiness(B1)`, name = 'B1 Business Visa Holders', type = 'scatter', mode = 'lines')\nfig <- fig %>% add_trace(y = ~`Academicstudents(F1)`, name = 'F1 Student Visa Holders', type = 'scatter', mode = 'lines')\n\nfig <- fig %>% layout(title = 'Select Non-Immigrant Admissions 2002-2021',\n                      yaxis=list(title = 'Number of Admissions (in millions)'))\nfig"
  },
  {
    "objectID": "Data-Visualization.html#references",
    "href": "Data-Visualization.html#references",
    "title": "Data Visualization",
    "section": "References",
    "text": "References\n“Terrorist Attacks in the U.S between 1970 and 2013: Data from the … - DHS.” Terrorist Attacks in the U.S Between 1970 and 2013: Data from the Global Terrorism Database (GTD). START Consortium at the University of Maryland. Accessed February 12, 2023. https://www.dhs.gov/sites/default/files/publications/OPSR_TP_TEVUS_Terrorist-Attacks-US_1970-2013_Overview-508.pdf.\nSerrano, Richard A. “The 1970s Bombing Spree.” Los Angeles Times. May 19, 2008.\nRosenau, William. “Leftist Terrorism in the United States.” Taylor & Francis. Accessed February 12, 2023. https://www.tandfonline.com/journals/fjss20.\n“Codebook Methodology Inclusion Criteria and Ariables - UMD.” Codebook Methodology Inclusion criteria and variables - UMD. University of Maryland. Accessed February 1, 2023. https://www.start.umd.edu/gtd/downloads/Codebook.pdf."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html",
    "href": "Exploratory-Data-Analysis.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "After producing the data visualizations to gain rudimentary insights about the various datasets collected, the next step of the process is to complete an exploratory data analysis (EDA). Several time series packages exist in the R software that have been utilized to unravel deeper details about the data sets. Some of the famous time series analysis methods used in this section include decomposing and identifying time series components, producing auto-correlation function (ACF) and partial auto-correlation function (PACF) plots, and differencing, and checking for stationarity by the use of the Augmented Dickey-Fuller Test.\nCode for this section can be found here"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#identifying-time-series-components-of-monthly-attacks",
    "href": "Exploratory-Data-Analysis.html#identifying-time-series-components-of-monthly-attacks",
    "title": "Exploratory Data Analysis",
    "section": "Identifying Time Series Components of Monthly Attacks",
    "text": "Identifying Time Series Components of Monthly Attacks"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#identifying-time-series-components-of-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#identifying-time-series-components-of-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Identifying Time Series Components of Monthly Attacks (GTD)",
    "text": "Identifying Time Series Components of Monthly Attacks (GTD)\nPlease note that as per the GTD Codebook (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.), incidents of terrorism from 1993 are not present because they were lost prior to START’s compilation of the database from multiple data collection efforts. Therefore, monthly attack counts for the year 1993 have been interpolated using the na.approx() function from the zoo library in R. Appendix II of the GTD Codebook provides Country-level statistics for 1993 and for the US, the attack count was 28. However, our interpolated estimates, which took into calculation 1992 and 1994 attack counts, sum up to 54 attacks, which shall be used for EDA.\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\nAlso, the data analyzed is count data rather than the measure of a metric. Hence, the results from the time series functions used on this data might not seem like “traditional” outputs seen from data used in class.\n\n\n\n\n\n\n\n\n\nFrom the graph, we see an initial downward trend from 1970 to 1972 and an upward trend soon after until 1975. The trend, however, then remains constant until the 2000s. Another upward trend is noticed after 2010 as more attacks were conducted in recent years. Some seasonality is noticed, with more attacks occurring towards the end of Spring (April and May) and end of Fall (August to October), across the whole timeline, but the number of attacks does vary across months, suggesting periodic fluctuations. From these insights, the series does not seem stationary. Moreover, because we cannot identify whether the average length of cycles is longer than the length of a seasonal pattern, the graph is not cyclical. A stationary time series will have no predictable patterns in the long-term, but given the count of attacks now increasing in recent years, one could deduce or forecast patterns in the number of attacks for the next few months ahead from the present (Dec 2020). Lastly, as the time of the series increases, the seasonal variation remains fairly constant, so we should use an additive decomposition. Next, we shall take a look at this series’ lag plots to check for autocorrelations, if any."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#references",
    "href": "Exploratory-Data-Analysis.html#references",
    "title": "Exploratory Data Analysis",
    "section": "References",
    "text": "References\n“Codebook Methodology Inclusion Criteria and Ariables - UMD.” Codebook Methodology Inclusion criteria and variables - UMD. University of Maryland. Accessed February 1, 2023. https://www.start.umd.edu/gtd/downloads/Codebook.pdf."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#lag-plots-gtd",
    "href": "Exploratory-Data-Analysis.html#lag-plots-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Lag Plots (GTD)",
    "text": "Lag Plots (GTD)"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#lag-plots-of-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#lag-plots-of-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Lag Plots of Monthly Attacks (GTD)",
    "text": "Lag Plots of Monthly Attacks (GTD)\n\n\n\n\n\nConcerning the the faceted lag plots of the monthly series, we see a relatively strong positive autocorrelation at lag 1. Thus indicates that there is a strong relationship between the values of the series in adjacent months. Specifically, it suggests that the value of the series in the current month is positively related to the value of the series in the previous month. This can indicate the presence of some underlying trend or seasonality in the data. There is no evidence of negative autocorrelation too. Therefore, this could make a case for weak autocorrelation. As the level of autocorrelation increases, the points shift away from the diagonal; however, the points move closer at lag 12, indicating that . A positive linear trend (i.e. going upwards from left to right) is suggestive of positive autocorrelation.\nWhen comparing the lag plots for the series with different months, there is not much difference, except for a cluster of data points in the bottom left side of the graph, reinforcing our earlier finding that more than half the attacks from 1970 to 2013 took place in 1970. The trend and seasonal components are very much similar and, hence, the plots hint to us that all the series seem to not be stationary."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#decomposing-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#decomposing-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Decomposing Monthly Attacks (GTD)",
    "text": "Decomposing Monthly Attacks (GTD)"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#acf-and-pacf-plots-of-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#acf-and-pacf-plots-of-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "ACF and PACF Plots of Monthly Attacks (GTD)",
    "text": "ACF and PACF Plots of Monthly Attacks (GTD)\n\n\n\n\n\nThe autocorrelation function (ACF) and partial autocorrelation function (PACF) plots are used to help determine the order of an ARMA model. The ACF plot shows the correlation between the time series and its lagged values, while the PACF plot shows the correlation between the time series and its lagged values after controlling for the effects of any intermediate lagged values.\nBy looking at the ACF, it can be concluded that the series is not Stationary. The dashed blue lines indicate whether the correlations are significantly different from zero. The ACF Plot shows a downward trend in attack counts, with the initial insignificant correlations beginning from lag 24. No clear seasonality is depicted from the ACF plot. If a time series is stationary, its PACF should decline to zero relatively quickly, beyond a certain lag value. On the other hand, if a time series is not stationary, its PACF will show significant autocorrelation for many lag values. The former seems true for these PACF plots, as we see autocorrelations for only lags 1 and 2 in the PACF plot. The PACF does decrease after and stays within the confines of the Confidence Interval, which could mean that it is not significantly different from zero and therefore has no significant correlation with the time series from lag 2 onwards. Therefore, the original series might be weakly stationary!"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#adf-test-of-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#adf-test-of-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "ADF Test of Monthly Attacks (GTD)",
    "text": "ADF Test of Monthly Attacks (GTD)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  monthly_attacks_ts\nDickey-Fuller = -7.3335, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#detrending-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#detrending-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Detrending Monthly Attacks (GTD)",
    "text": "Detrending Monthly Attacks (GTD)\n\n\n\nCall:\nlm(formula = monthly_attacks_ts ~ time(monthly_attacks_ts), na.action = NULL)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.347 -3.363 -1.524  1.317 59.172 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              376.72017   36.25612   10.39   <2e-16 ***\ntime(monthly_attacks_ts)  -0.18622    0.01817  -10.25   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.617 on 610 degrees of freedom\nMultiple R-squared:  0.1469,    Adjusted R-squared:  0.1455 \nF-statistic:   105 on 1 and 610 DF,  p-value: < 2.2e-16\n\n\n\n\n\nOur trend using OLS was:\n\\(\\hat\\mu_t\\) = 376.72 - 0.18622t\nTherefore, equation of the fit of the underlying stationary process is:\n\\(\\hat{y_t}\\) = \\(x_t\\) + 376.72 - 0.18622t\nThe Detrended series is very much similar to the original series, signaling that differencing could provide a more stationary transformation. The linear model’s \\(R^2\\) value is 0.1469, suggesting that the model captures 15% of the variation in prices. Therefore, a quadratic model or first differencing would perhaps provide a better fit.\nWe then see that, even after detrending, the series contains seasonality, which further reinforces our above point that the linear model does not do very well in capturing the initial decreasing trend and then the increasing trend for recent years. Moreover, the data is not trend stationary, which bolsters the above argument."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#acf-and-pacf-plots-after-differencing-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#acf-and-pacf-plots-after-differencing-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "ACF and PACF Plots After Differencing Monthly Attacks (GTD)",
    "text": "ACF and PACF Plots After Differencing Monthly Attacks (GTD)\n\n\n\n\n\nFirst order differencing performs better than detrending, so we shall use this series in the next section when building our autoregressive models. However, we also saw from the original PACF plot that the PACF declineS to zero relatively quickly than that of the differenced series. Therefore, the original series could also directly be fitted to the autoregressive models."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#global-terrorism-database-exploratory-data-analysis",
    "href": "Exploratory-Data-Analysis.html#global-terrorism-database-exploratory-data-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Global Terrorism Database Exploratory Data Analysis",
    "text": "Global Terrorism Database Exploratory Data Analysis\n\nIdentifying Time Series Components of Monthly Attacks\nPlease note that as per the GTD Codebook (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.), incidents of terrorism from 1993 are not present because they were lost prior to START’s compilation of the database from multiple data collection efforts. Therefore, monthly attack counts for the year 1993 have been interpolated using the na.approx() function from the zoo library in R. Appendix II of the GTD Codebook provides Country-level statistics for 1993 and for the US, the attack count was 28. However, our interpolated estimates, which took into calculation 1992 and 1994 attack counts, sum up to 54 attacks, which shall be used for EDA.\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\nAlso, the data analyzed is count data rather than the measure of a metric. Hence, the results from the time series functions used on this data might not seem like “traditional” outputs seen from data used in class.\n\n\n\n\n\nCode\n(orig_plot <- plot_ly(data=gtd_monthly_attacks_deaths, x=~Date)  %>% \n    add_trace(type = 'scatter', mode = 'lines', y=~num_attacks, \n            name=\"Attacks\", line = list(color = 'red')) %>%\n  layout(title=\"Monthly Count of Terrorist Attacks in the US\",\n         yaxis=list(title=(\"Count\")),\n         xaxis=list(title=(\"Date\"))) %>%\n  layout(hovermode = \"x\"))\n\n\n\n\n\n\nFrom the graph, we see an initial downward trend from 1970 to 1972 and an upward trend soon after until 1975. The trend, however, then remains constant until the 2000s. Another upward trend is noticed after 2010 as more attacks were conducted in recent years. Some seasonality is noticed, with more attacks occurring towards the end of Spring (April and May) and end of Fall (August to October), across the whole timeline, but the number of attacks does vary across months, suggesting periodic fluctuations. From these insights, the series does not seem stationary. Moreover, because we cannot identify whether the average length of cycles is longer than the length of a seasonal pattern, the graph is not cyclical. A stationary time series will have no predictable patterns in the long-term, but given the count of attacks now increasing in recent years, one could deduce or forecast patterns in the number of attacks for the next few months ahead from the present (Dec 2020). Lastly, as the time of the series increases, the seasonal variation remains fairly constant, so we should use an additive decomposition. Next, we shall take a look at this series’ lag plots to check for autocorrelations, if any.\n\n\nLag Plots of Monthly Attacks\n\n\nCode\n# convert to time series object again\nmonthly_attacks_ts <- ts(gtd_monthly_attacks_deaths$num_attacks, start = c(1970, 1), frequency = 12)\n\n# plot\ngglagplot(monthly_attacks_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for Monthly Terrorist Attacks, 1970-2020\") +\n  xlab(\"Lags\") + ylab(\"Yt\") + \n  theme(axis.text.x=element_text(angle=45, hjust=1))\n\n\n\n\n\nConcerning the the faceted lag plots of the monthly series, we see a relatively strong positive autocorrelation at lag 1. Thus indicates that there is a strong relationship between the values of the series in adjacent months. Specifically, it suggests that the value of the series in the current month is positively related to the value of the series in the previous month. This can indicate the presence of some underlying trend or seasonality in the data. There is no evidence of negative autocorrelation too. Therefore, this could make a case for weak autocorrelation. As the level of autocorrelation increases, the points shift away from the diagonal; however, the points move closer at lag 12, indicating that . A positive linear trend (i.e. going upwards from left to right) is suggestive of positive autocorrelation.\nWhen comparing the lag plots for the series with different months, there is not much difference, except for a cluster of data points in the bottom left side of the graph, reinforcing our earlier finding that more than half the attacks from 1970 to 2013 took place in 1970. The trend and seasonal components are very much similar and, hence, the plots hint to us that all the series seem to not be stationary.\n\n\nDecomposing Monthly Attacks\n\n\nCode\nstl(monthly_attacks_ts, t.window=NULL, s.window=\"periodic\", robust=TRUE) %>%\n    autoplot()+ggtitle(\"Additive Decomposition of Number of Terrorist Attacks\")\n\n\n\n\n\n\n\nACF and PACF Plots of Monthly Attacks\n\n\nCode\nmonthly_attacks_ts %>% \n  ggtsdisplay(main=\"ACF and PACF Plots of Monthly Attacks\")\n\n\n\n\n\nThe autocorrelation function (ACF) and partial autocorrelation function (PACF) plots are used to help determine the order of an ARMA model. The ACF plot shows the correlation between the time series and its lagged values, while the PACF plot shows the correlation between the time series and its lagged values after controlling for the effects of any intermediate lagged values.\nBy looking at the ACF, it can be concluded that the series is not Stationary. The dashed blue lines indicate whether the correlations are significantly different from zero. The ACF Plot shows a downward trend in attack counts, with the initial insignificant correlations beginning from lag 24. No clear seasonality is depicted from the ACF plot. If a time series is stationary, its PACF should decline to zero relatively quickly, beyond a certain lag value. On the other hand, if a time series is not stationary, its PACF will show significant autocorrelation for many lag values. The former seems true for these PACF plots, as we see autocorrelations for only lags 1 and 2 in the PACF plot. The PACF does decrease after and stays within the confines of the Confidence Interval, which could mean that it is not significantly different from zero and therefore has no significant correlation with the time series from lag 2 onwards. Therefore, the original series might be weakly stationary!\n\n\nADF Test of Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\nCode\nadf.test(monthly_attacks_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  monthly_attacks_ts\nDickey-Fuller = -7.3335, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we cannot reject the null hypothesis and conclude that the time series is non-stationary.\n\n\nDetrending Monthly Attacks\n\n\nCode\nfit <- lm(monthly_attacks_ts~time(monthly_attacks_ts), na.action = NULL)\nsummary(fit)\n\n\n\nCall:\nlm(formula = monthly_attacks_ts ~ time(monthly_attacks_ts), na.action = NULL)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.347 -3.363 -1.524  1.317 59.172 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              376.72017   36.25612   10.39   <2e-16 ***\ntime(monthly_attacks_ts)  -0.18622    0.01817  -10.25   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.617 on 610 degrees of freedom\nMultiple R-squared:  0.1469,    Adjusted R-squared:  0.1455 \nF-statistic:   105 on 1 and 610 DF,  p-value: < 2.2e-16\n\n\nCode\ndetrended <- autoplot(resid(fit), \n         main=\"Detrended: Monthly Terrorist Attacks in the US\",\n         ylab = \"Residuals\",\n         xlab = \"Date\") +\n    theme_minimal()\ndetrended\n\n\n\n\n\nCode\n#subplot(detrended, orig_plot, nrows = 2, heights = c(0.5, 0.5))\n\n\nOur trend using OLS was:\n\\(\\hat\\mu_t\\) = 376.72 - 0.18622t\nTherefore, equation of the fit of the underlying stationary process is:\n\\(\\hat{y_t}\\) = \\(x_t\\) + 376.72 - 0.18622t\nThe Detrended series is very much similar to the original series, signaling that differencing could provide a more stationary transformation. The linear model’s \\(R^2\\) value is 0.1469, suggesting that the model captures 15% of the variation in prices. Therefore, a quadratic model or first differencing would perhaps provide a better fit.\nWe then see that, even after detrending, the series contains seasonality, which further reinforces our above point that the linear model does not do very well in capturing the initial decreasing trend and then the increasing trend for recent years. Moreover, the data is not trend stationary, which bolsters the above argument.\n\n\nACF and PACF Plots After Differencing Monthly Attacks\n\n\nCode\nmonthly_attacks_ts %>% diff %>% \n  ggtsdisplay(main=\"ACF and PACF Plots After Differencing Monthly Attacks\")\n\n\n\n\n\nFirst order differencing performs better than detrending, so we shall use this series in the next section when building our autoregressive models. However, we also saw from the original PACF plot that the PACF declineS to zero relatively quickly than that of the differenced series. Therefore, the original series could also directly be fitted to the autoregressive models.\n\n\nSimple Moving Average Smoothing\n\n\nCode\nma3 <- autoplot(monthly_attacks_ts, series=\"Data\") +\n  autolayer(ma(monthly_attacks_ts,3), series=\"3-MA\") +\n  xlab(\"Year\") + ylab(\"Number of Monthly Attacks\") +\n  ggtitle(\"3-MA: Monthly US Terrorist Attacks\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"3-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"3-MA\"))\n\nma5 <- autoplot(monthly_attacks_ts, series=\"Data\") +\n  autolayer(ma(monthly_attacks_ts,5), series=\"5-MA\") +\n  xlab(\"Year\") + ylab(\"Number of Monthly Attacks\") +\n  ggtitle(\"5-MA: Monthly US Terrorist Attacks\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"5-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"5-MA\"))\n\n\nma7 <- autoplot(monthly_attacks_ts, series=\"Data\") +\n  autolayer(ma(monthly_attacks_ts,7), series=\"7-MA\") +\n  xlab(\"Year\") + ylab(\"Number of Monthly Attacks\") +\n  ggtitle(\"7-MA: Monthly US Terrorist Attacks\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"7-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"7-MA\"))\n\nma9 <- autoplot(monthly_attacks_ts, series=\"Data\") +\n  autolayer(ma(monthly_attacks_ts,9), series=\"9-MA\") +\n  xlab(\"Year\") + ylab(\"Number of Monthly Attacks\") +\n  ggtitle(\"9-MA: Monthly US Terrorist Attacks\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"9-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"9-MA\"))\n\ngrid.arrange(ma3, ma5,ma7,ma9, nrow = 2, ncol=2)\n\n\n\n\n\n\n\nMoving Average Smoothing with Windowing (2x4)\n\n\nCode\nmonthly_attacks_ts_2 <- window(monthly_attacks_ts,start= c(1970, 1))\nma4 <- ma(monthly_attacks_ts_2, order=4, centre=FALSE)\nma2x4 <- ma(monthly_attacks_ts_2, order=4, centre=TRUE)\nMA_2x4=data.frame(monthly_attacks_ts_2,ma4,ma2x4)\n\nknitr::kable(head(MA_2x4), align=rep('c', 3))\n\n\n\n\n\nmonthly_attacks_ts_2\nma4\nma2x4\n\n\n\n\n26\nNA\nNA\n\n\n50\n49.75\nNA\n\n\n54\n58.50\n54.125\n\n\n69\n55.50\n57.000\n\n\n61\n55.00\n55.250\n\n\n38\n45.00\n50.000\n\n\n\n\n\nCode\nautoplot(monthly_attacks_ts_2, series=\"Data\") +\n  autolayer(ma(monthly_attacks_ts_2, order=4, centre=FALSE), series=\"4-MA\") +\n  autolayer(ma(monthly_attacks_ts_2, order=4, centre=TRUE), series=\"2x4-MA\") +\n  xlab(\"Year\") + ylab(\"Number of Monthly Attacks\") +\n  ggtitle(\"Count of Monthly Terrorist Attacks in the US\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey\",\"4-MA\"=\"red\",\"2x4-MA\"=\"blue\"),\n                      breaks=c(\"Data\",\"4-MA\",\"2x4-MA\"))\n\n\n\n\n\nIn this case, m is even, so it is no longer be symmetric. Therefore, when windowing, we are applying a moving average to a moving average. One reason for doing this is to make an even-order moving average symmetric. Here we have employed a centered 4-month moving average followed by a centered 2-month moving average. Although this helps smooth out both seasonal and longer-term trends in the data, we notice some seasonality still being present in the smoothed overlay. Let’s us try to use other moving averaging windows to obtain a more stationary overlay.\n\n\nMoving Average Smoothing with Windowing (2x6)\n\n\nCode\nmonthly_attacks_ts_2 <- window(monthly_attacks_ts,start= c(1970, 1))\nma6 <- ma(monthly_attacks_ts_2, order=6, centre=FALSE)\nma2x6 <- ma(monthly_attacks_ts_2, order=6, centre=TRUE)\nMA_2x6=data.frame(monthly_attacks_ts_2,ma6,ma2x6)\n\nknitr::kable(head(MA_2x6), align=rep('c', 3))\n\n\n\n\n\nmonthly_attacks_ts_2\nma6\nma2x6\n\n\n\n\n26\nNA\nNA\n\n\n50\nNA\nNA\n\n\n54\n49.66667\nNA\n\n\n69\n54.00000\n51.83333\n\n\n61\n50.50000\n52.25000\n\n\n38\n44.83333\n47.66667\n\n\n\n\n\nCode\nautoplot(monthly_attacks_ts_2, series=\"Data\") +\n  autolayer(ma(monthly_attacks_ts_2, order=6, centre=FALSE), series=\"6-MA\") +\n  autolayer(ma(monthly_attacks_ts_2, order=6, centre=TRUE), series=\"2x6-MA\") +\n  xlab(\"Year\") + ylab(\"Number of Monthly Attacks\") +\n  ggtitle(\"Count of Monthly Terrorist Attacks in the US\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey\",\"6-MA\"=\"red\",\"2x6-MA\"=\"blue\"),\n                      breaks=c(\"Data\",\"6-MA\",\"2x6-MA\"))\n\n\n\n\n\nThe moving average did smooth out both seasonal and longer-term trends in the monthly time series. Although, we could still do better by further smoothing out longer-term trends by using a centered 8-month moving average, showcased below.\n\n\nMoving Average Smoothing with Windowing (2x8)\n\n\nCode\nmonthly_attacks_ts_2 <- window(monthly_attacks_ts,start= c(1970, 1))\nma8 <- ma(monthly_attacks_ts_2, order=8, centre=FALSE)\nma2x8 <- ma(monthly_attacks_ts_2, order=8, centre=TRUE)\nMA_2x8=data.frame(monthly_attacks_ts_2,ma8,ma2x8)\n\nknitr::kable(head(MA_2x8), align=rep('c', 3))\n\n\n\n\n\nmonthly_attacks_ts_2\nma8\nma2x8\n\n\n\n\n26\nNA\nNA\n\n\n50\nNA\nNA\n\n\n54\nNA\nNA\n\n\n69\n47.375\nNA\n\n\n61\n46.625\n47.0\n\n\n38\n44.375\n45.5\n\n\n\n\n\nCode\nautoplot(monthly_attacks_ts_2, series=\"Data\") +\n  autolayer(ma(monthly_attacks_ts_2, order=8, centre=FALSE), series=\"8-MA\") +\n  autolayer(ma(monthly_attacks_ts_2, order=8, centre=TRUE), series=\"2x8-MA\") +\n  xlab(\"Year\") + ylab(\"Number of Monthly Attacks\") +\n  ggtitle(\"Count of Monthly Terrorist Attacks in the US\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey\",\"8-MA\"=\"red\",\"2x8-MA\"=\"blue\"),\n                      breaks=c(\"Data\",\"8-MA\",\"2x8-MA\"))\n\n\n\n\n\nThe above plot employed a centered 8-month moving average followed by a centered 2-month moving average. The output is similar to that of the 2x6-MA. Let’s make our analysis more constrained by fitting 4x3-MA: A centered 3-month moving average repeated four times. This should smooth out both seasonal and shorter-term fluctuations even further, providing the least seasonal moving average out of all the other moving averages applied yet."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#detrending-monthly-attacks",
    "href": "Exploratory-Data-Analysis.html#detrending-monthly-attacks",
    "title": "Exploratory Data Analysis",
    "section": "Detrending Monthly Attacks",
    "text": "Detrending Monthly Attacks\n\n\n\nCall:\nlm(formula = monthly_attacks_ts ~ time(monthly_attacks_ts), na.action = NULL)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.347 -3.363 -1.524  1.317 59.172 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              376.72017   36.25612   10.39   <2e-16 ***\ntime(monthly_attacks_ts)  -0.18622    0.01817  -10.25   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.617 on 610 degrees of freedom\nMultiple R-squared:  0.1469,    Adjusted R-squared:  0.1455 \nF-statistic:   105 on 1 and 610 DF,  p-value: < 2.2e-16\n\n\n\n\n\nOur trend using OLS was:\n\\(\\hat\\mu_t\\) = 376.72 - 0.18622t\nTherefore, equation of the fit of the underlying stationary process is:\n\\(\\hat{y_t}\\) = \\(x_t\\) + 376.72 - 0.18622t\nThe Detrended series is very much similar to the original series, signaling that differencing could provide a more stationary transformation. The linear model’s \\(R^2\\) value is 0.1469, suggesting that the model captures 15% of the variation in prices. Therefore, a quadratic model or first differencing would perhaps provide a better fit.\nWe then see that, even after detrending, the series contains seasonality, which further reinforces our above point that the linear model does not do very well in capturing the initial decreasing trend and then the increasing trend for recent years. Moreover, the data is not trend stationary, which bolsters the above argument.\n\nACF and PACF Plots After Differencing Monthly Attacks\n\n\n\n\n\nFirst order differencing performs better than detrending, so we shall use this series in the next section when building our autoregressive models. However, we also saw from the original PACF plot that the PACF declineS to zero relatively quickly than that of the differenced series. Therefore, the original series could also directly be fitted to the autoregressive models.\n\n\nMoving Average Smoothing"
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html",
    "href": "ARMA-ARIMA-SARIMA.html",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "",
    "text": "After completing the exploratory data analysis (EDA) phase, the next step is to begin building time series models. In order to do so, one must first choose an appropriate model type, such as an ARMA (AutoRegressive Moving Average) model or one of its variations, including ARIMA (AutoRegressive Integrated Moving Average) or SARIMA (Seasonal AutoRegressive Integrated Moving Average).\nAn ARIMA model is generally notated as ARIMA(p,d,q) where p is the order of the AR process, d is the degree of differencing and q is the order of the MA process. The general equation of the model is given as follows:\n\\(\\phi(B)(1-B)^d x_t = \\delta + \\theta(B) w_t\\), where \\(B\\) is the backshift operator, \\(w_t\\) is the Gaussian white noise process, \\(\\delta\\) is the drift term and \\(\\phi(B)\\) and \\(\\theta(B)\\) correspond to the AR and MA parts respectively.\nLag plots, auto-correlation function (ACF) and partial auto-correlation function (PACF) plots, decomposing the time series, and differencing are all useful techniques that were employed during the EDA phase to help inform the choice of model type and parameters. With a solid understanding of the data and its characteristics, one can begin to develop and refine time series models that can be used for forecasting.\nCode for this section can be found here"
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-time-series-modeling",
    "href": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-time-series-modeling",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Global Terrorism Database Time Series Modeling",
    "text": "Global Terrorism Database Time Series Modeling\n\n\n\n\nACF and PACF Plots of Monthly Attacks\n\n\n\n\n\n\n\nADF Test of Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  monthly_attacks_ts\nDickey-Fuller = -7.3335, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we reject the null hypothesis and conclude that the monthly attacks series is stationary. Although the ADF states that the original series is stationary, the ACF plots, which clearly indicate seasonality and trend, are more reliable than the ADF test. Therefore, it is safe to conclude that the series non-stationary as per the (ACF?) section above.\n\n\nLog-Transformation of Monthly Attacks\n\n\n\n\n\n\n\n\nSimply taking log of the number of monthly attacks does not make it stationary. First-differencing the log number of monthly attacks does, however, make the series stationary and this series should be employed for building our time series model. Keep in mind that because first-differencing was enough to make the series stationary, we do not need to second-difference it, helping us avoid over differencing the number of monthly attacks.\n\n\nADF Test of Log First-Differenced Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  dlx\nDickey-Fuller = -13.177, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we reject the null hypothesis and conclude that the log first-differenced monthly attacks series is stationary. Let us now check whether the ACF plots supports this hypothesis.\n\n\nACF and PACF Plots of Log First-Differenced Monthly Attacks\n\n\n\n\n\np values obtained from PACF are 1, 2, 3, 4 q values obtained from ACF are: 1 d (Difference): 1\n\n\nFitting ARIMA(p,d,q)\n\n\n\n\n\n\np\nd\nq\nAIC\nBIC\nAICc\n\n\n\n\n2\n1\n1\n2\n1184.760\n1206.827\n1184.859\n\n\n3\n1\n1\n3\n1187.562\n1214.043\n1187.702\n\n\n6\n2\n1\n2\n1188.993\n1215.473\n1189.132\n\n\n4\n1\n1\n4\n1184.796\n1215.690\n1184.982\n\n\n10\n3\n1\n2\n1184.825\n1215.719\n1185.011\n\n\n7\n2\n1\n3\n1188.316\n1219.210\n1188.502\n\n\n11\n3\n1\n3\n1186.472\n1221.780\n1186.712\n\n\n8\n2\n1\n4\n1188.815\n1224.122\n1189.054\n\n\n12\n3\n1\n4\n1187.936\n1227.657\n1188.236\n\n\n9\n3\n1\n1\n1250.578\n1277.059\n1250.718\n\n\n5\n2\n1\n1\n1265.762\n1287.830\n1265.862\n\n\n1\n1\n1\n1\n1319.040\n1336.694\n1319.106\n\n\n\n\n\n\n Best Model in terms of AIC: \n\n\n  p d q     AIC      BIC     AICc\n2 1 1 2 1184.76 1206.827 1184.859\n\n\n\n Best Model in terms of AICc: \n\n\n  p d q     AIC      BIC     AICc\n2 1 1 2 1184.76 1206.827 1184.859\n\n\n\n Best Model in terms of BIC: \n\n\n  p d q     AIC      BIC     AICc\n2 1 1 2 1184.76 1206.827 1184.859\n\n\nThe best model with the lowest AIC, BIC, and AICc metrics is the ARIMA(1, 1, 2) model. The equation of the model is given by:\n\\(\\begin{equation}(1-B)(1-B^1)y_t = \\delta + (1+\\phi_1B)(1-\\theta_1B-\\theta_2B^2)w_t\\end{equation}\\), where \\((1-B)\\) and \\((1-B^1)\\) are the differencing operators, which represent the first-order difference of the series. \\(y_t\\) is the time series, \\(\\delta\\) is the drift term, \\(\\phi_1\\) and \\(\\theta_1\\), \\(\\theta_2\\) are the parameters of the AR and MA parts, respectively, and \\(w_t\\) is the Gaussian white noise process.\nNote that \\(B\\) is the backshift operator, which shifts the time series back by one period.\n\n\nModel Diagnostics of ARIMA(1,1,2)\n\n\n\n\n\nStandardized Residuals: Essentially stating that if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\nACF Of Residuals: Auto-correlation of the residuals. The only q value to inspect is 1.\nQ-Q Plot: The series follows a normal distribution pretty closely as even the tails seem to be on the normal line.\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value greater than 0.05, our series is stationary.\n\n\nChecking Model Output of ARIMA(1,1,2) with auto.arima()\n\n\nModel metrics using auto.arima(): \n\n\nSeries: monthly_attacks_ts \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.1389  -0.7431\ns.e.  0.0645   0.0432\n\nsigma^2 = 18.69:  log likelihood = -1760.85\nAIC=3527.7   AICc=3527.74   BIC=3540.95\n\nTraining set error measures:\n                    ME     RMSE      MAE  MPE MAPE    MASE       ACF1\nTraining set -0.154373 4.313143 2.764126 -Inf  Inf 0.72581 0.01754544\n\n\n\nModel metrics of ARIMA(1, 1, 2) using Arima(): \n\n\nSeries: dlx \nARIMA(1,1,2) \n\nCoefficients:\n         ar1      ma1     ma2\n      0.0327  -1.8568  0.8579\ns.e.  0.0503   0.0299  0.0292\n\nsigma^2 = 0.4:  log likelihood = -589.26\nAIC=1186.51   AICc=1186.58   BIC=1204.17\n\nTraining set error measures:\n                     ME      RMSE       MAE MPE MAPE      MASE         ACF1\nTraining set 0.05076924 0.6304084 0.5003311 NaN  Inf 0.5417286 -0.007967481\n\n\nFrom the above output, auto.arima() outputted an ARIMA(1,1,1) model, which is slightly simpler than the best model obtained with the Arima() function. In fact, the ARIMA(1,1,1) model was the worst model obtained using the Arima() function and that is noted in the table outputted in (best-fit?). This difference can be expected when using auto.arima() because it is not as reliable as the Arima() when building ARIMA models. The case is different when building SARIMA models, which is covered in the next section.\nThe best model outputted by Arima() performs significantly better than the model outputted by auto.arima() in terms of model selection metrics, including AIC, BIC, and AICc. Moreover, the best model outputted by Arima() also outperforms the model outputted by auto.arima() in terms of training set metrics, including RMSE, MAE, and MAPE. Although the auto.arima() model does well to closely match the best Arima() model by including a differenced order in its model and by choosing the right p or AR order, it does not select an additional MA order that would make the model more robust, as seen by the comparison of metrics. Some points to keep in mind when using these functions is as follows.\nThe auto.arima() function in R uses a stepwise algorithm to search through the space of possible ARIMA models and select the one with the lowest AIC value. While this approach can be computationally efficient and provide a good starting point for model selection, it does not necessarily find the best possible model for a given time series.\nOn the other hand, the Arima() function in R allows you to specify the exact order of the ARIMA model and can be used to fit more complex models, such as those with seasonality, exogenous variables, or other constraints. By specifying the exact order of the model, you have more control over the modeling process and can potentially obtain a better fit to the data.\nIn summary, the auto.arima() function can be a useful tool for quickly identifying a potentially good model, but it is not a substitute for careful model selection and customization using the Arima() function.\n\n\nForecasting ARIMA(1,1,2)\n\n\n\n\n\n$pred\n            Jan        Feb        Mar        Apr        May        Jun\n2021 0.37759011 0.02555481 0.01273564 0.01231300 0.01234339 0.01239033\n2022 0.01272329 0.01277086                                            \n            Jul        Aug        Sep        Oct        Nov        Dec\n2021 0.01243788 0.01248544 0.01253301 0.01258058 0.01262815 0.01267572\n2022                                                                  \n\n$se\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2021 0.6282655 0.8166695 0.8168888 0.8168890 0.8168890 0.8168890 0.8168890\n2022 0.8168890 0.8168890                                                  \n           Aug       Sep       Oct       Nov       Dec\n2021 0.8168890 0.8168890 0.8168890 0.8168890 0.8168890\n2022                                                  \n\n\nFrom the above graph, we can note that the number of attacks will fluctuate anywhere between 0 to 6 (converting from log data) every month from 2021 to 2022, as per the 95% confidence bound. A spike is noticed for the first observed forecast after which the model does poorly to forecast the rest of the year. Since the ARIMA(1,1,2) is relatively simple, it is not as robust and complex to forecast more than a month into the future. The straight red line forecast after the first forecasted month suggests that 1 attack per month (converting from log data) would take place, an averaged out value. This is expected.\nMoreover, the other suboptimal models outputted by Arima() also give the same forecast, so overlaying them onto the above plot would be redundant. It is, however, pragmatic to check whether the auto.arima() model’s forecast may forecast differently. Let us find out below.\n\n\nForecasting ARIMA(1,1,1) Outputted by auto.arima()\n\n\n\n\n\n$pred\n              Jan          Feb          Mar          Apr          May\n2021  0.160739303 -0.066511129  0.048747789 -0.009617016  0.020030951\n2022  0.010443266  0.010418886                                       \n              Jun          Jul          Aug          Sep          Oct\n2021  0.005063770  0.012712754  0.008897226  0.010893251  0.009943302\n2022                                                                 \n              Nov          Dec\n2021  0.010486717  0.010273121\n2022                          \n\n$se\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2021 0.7049204 0.7897960 0.8104291 0.8155169 0.8168849 0.8172028 0.8173013\n2022 0.8173278 0.8173277                                                  \n           Aug       Sep       Oct       Nov       Dec\n2021 0.8173181 0.8173267 0.8173267 0.8173278 0.8173276\n2022                                                  \n\n\nLike the previous forecast, we can note that, for the auto.arima() model, the number of attacks will fluctuate anywhere between 0 to 6 every month from 2021 to 2022 (again this is logged data), as per the 95% confidence bound. However, from the above plot, it can be discerned from red line that the auto.arima() model’s forecasts fluctuate more for the initial months’ forecasts than that of the Arima() model’s forecasts, which was smoother for the initial 2 months. Like the Arima() model’s forecasts, the the auto.arima() model’s forecast then lie on a single value, 1 attack per month, as the red line flattens out. Note that the output of the auto.arima() model was ARIMA(1,1,1), so it was expected that the forecast would be slightly less smoother than the ARIMA(1,1,2) model outputted by Arima(). This is attributed to the fact that ARIMA(1,1,2) has an additional Moving-Average term, which help make its forecasts smoother.\n\n\nComparing ARIMA(1,1,2) with Benchmarks\n\n\n\n\n\nBest model metrics: \n\n\nSeries: dlx \nARIMA(1,1,2) \n\nCoefficients:\n         ar1      ma1     ma2\n      0.0327  -1.8568  0.8579\ns.e.  0.0503   0.0299  0.0292\n\nsigma^2 = 0.4:  log likelihood = -589.26\nAIC=1186.51   AICc=1186.58   BIC=1204.17\n\nTraining set error measures:\n                     ME      RMSE       MAE MPE MAPE      MASE         ACF1\nTraining set 0.05076924 0.6304084 0.5003311 NaN  Inf 0.5417286 -0.007967481\n\n\n\nSnaive metrics: \n\n\n                       ME     RMSE       MAE MPE MAPE MASE       ACF1\nTraining set -0.000351788 1.145667 0.9235824 NaN  Inf    1 -0.5112064\n\n\nFrom the above plot, only the Snaive benchmark method’s forecasts seem more plausible compared to that of the ARIMA(1,1,2) model. The forecasts produced from the Snaive benchmark have the greatest amount of fluctuations or seasonality in a higher range of number of monthly attacks. However, the metrics paint a different story. The ARIMA(1,1,2) model’s training error measures are better than those of the Snaive benchmark. There are several reasons for this phenomenon:\nModel Assumptions: The ARIMA model assumes that the data is stationary, which means that the mean and variance of the data do not change over time. If the data violates this assumption, the ARIMA model may not perform well. In contrast, the Snaive model does not assume stationarity, which may make it more robust to non-stationary data.\nParameter Estimation: The ARIMA model has three parameters (p, d, q) that need to be estimated, whereas the Snaive model has only one parameter (the seasonality). It is possible that the parameter estimation process for the ARIMA model was not optimal, leading to suboptimal forecast performance.\nForecast Horizon: The Snaive model may perform better than the ARIMA model for shorter forecast horizons, while the ARIMA model may perform better for longer forecast horizons. This is because the Snaive model assumes that the future values of the time series will be the same as the past values at the same time of year, which may be a reasonable assumption for short forecast horizons, but not for longer ones."
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-arima-modeling",
    "href": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-arima-modeling",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Global Terrorism Database ARIMA Modeling",
    "text": "Global Terrorism Database ARIMA Modeling\n\n\n\n\nSplitting Series into Train and Test Sets for Model Validation Process\nAfter cleaning and aggregating the Global Terrorism Database™ (GTD) (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.) by month, we shall be splitting the aggregated monthly data set into train and test sets for model validation. I have kept 587 observations for training and the remaining 48 observations for testing or validating. Therefore, I have kept aside 2 years (48 months or 48 observations) for forecasting purposes.\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\n\n\nCode\ntrain_series=monthly_attacks_ts[1:587] # close to 92%\ntest_series=monthly_attacks_ts[588:612] # keeping 2 years (48 months or 48 observations) to predict/forecast\n\n\n\n\nACF and PACF Plots of Monthly Attacks\n\n\nCode\ntrain_series %>% \n  ggtsdisplay(main=\"ACF and PACF Plots of Monthly Attacks\")\n\n\n\n\n\n\n\nADF Test of Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\nCode\nadf.test(train_series)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  train_series\nDickey-Fuller = -7.2458, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we reject the null hypothesis and conclude that the monthly attacks series is stationary. Although the ADF states that the original series is stationary, the ACF plots, which clearly indicate seasonality and trend, are more reliable than the ADF test. Therefore, it is safe to conclude that the series non-stationary as per the ACF section above.\n\n\nLog-Transformation of Monthly Attacks and its First and Second Order Differencing\n\n\nCode\nlx = log(train_series+1); dlx = diff(lx); ddlx = diff(dlx, 12) # add 1 to lx to not get NAs\n\nx = train_series\n\nplot.ts(cbind(x,lx,dlx,ddlx), main=\"\")\n\n\n\n\n\nCode\npar(mfrow=c(2,1))\nmonthplot(dlx); monthplot(ddlx)\n\n\n\n\n\nSimply taking log of the number of monthly attacks does not make it stationary. First-differencing the log number of monthly attacks does, however, make the series stationary and this series should be employed for building our time series model. Keep in mind that because first-differencing was enough to make the series stationary, we do not need to second-difference it, helping us avoid over differencing the number of monthly attacks.\n\n\nADF Test of Log First-Differenced Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\nCode\nadf.test(dlx)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  dlx\nDickey-Fuller = -12.802, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we reject the null hypothesis and conclude that the log first-differenced monthly attacks series is stationary. Let us now check whether the ACF plots supports this hypothesis.\n\n\nACF and PACF Plots of Log First-Differenced Monthly Attacks\n\n\nCode\ndlx %>% \n  ggtsdisplay(main=\"ACF and PACF Plots of Log First-Differenced Monthly Attacks\")\n\n\n\n\n\np values obtained from PACF are 0, 1, 2, 3, 4 q values obtained from ACF are: 0, 1 d (Difference): 1\n\n\nFitting ARIMA(p,d,q)\n\n\nCode\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*24),nrow=24) # roughly nrow = 3x4x2\n\n\nfor (p in 1:5)# p=0,1,2,3,4 \n{\n  for(q in 1:4)# q=0,1,2,3 (although we only found q=1 to be significant in ACF, we may want to compare a complex ARIMA model with greater \"q\" value compared to a simpler ARIMA model)\n  {\n    for(d in 1)# d=1\n    {\n      \n      if(p-1+d+q-1<=8)\n      {\n        \n        model<- Arima(lx,order=c(p-1,d,q-1)) \n        ls[i,]= c(p-1,d,q-1,model$aic,model$bic,model$aicc)\n        i=i+1\n        #print(i)\n        \n      }\n      \n    }\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\ntemp <- temp[order(temp$BIC, decreasing = FALSE),] \nknitr::kable(temp)\n\n\n\n\n\n\np\nd\nq\nAIC\nBIC\nAICc\n\n\n\n\n2\n0\n1\n1\n1129.146\n1137.892\n1129.166\n\n\n6\n1\n1\n1\n1131.028\n1144.148\n1131.069\n\n\n3\n0\n1\n2\n1131.045\n1144.165\n1131.087\n\n\n12\n2\n1\n3\n1120.047\n1146.287\n1120.192\n\n\n10\n2\n1\n1\n1130.116\n1147.609\n1130.185\n\n\n4\n0\n1\n3\n1130.121\n1147.614\n1130.189\n\n\n7\n1\n1\n2\n1133.117\n1150.610\n1133.186\n\n\n14\n3\n1\n1\n1131.179\n1153.046\n1131.283\n\n\n8\n1\n1\n3\n1131.272\n1153.139\n1131.376\n\n\n11\n2\n1\n2\n1131.710\n1153.577\n1131.813\n\n\n16\n3\n1\n3\n1126.189\n1156.802\n1126.383\n\n\n18\n4\n1\n1\n1132.357\n1158.597\n1132.502\n\n\n15\n3\n1\n2\n1132.897\n1159.137\n1133.042\n\n\n19\n4\n1\n2\n1132.672\n1163.285\n1132.866\n\n\n20\n4\n1\n3\n1134.670\n1169.657\n1134.920\n\n\n17\n4\n1\n0\n1176.672\n1198.538\n1176.775\n\n\n13\n3\n1\n0\n1187.101\n1204.594\n1187.170\n\n\n9\n2\n1\n0\n1201.337\n1214.457\n1201.379\n\n\n5\n1\n1\n0\n1255.509\n1264.255\n1255.529\n\n\n1\n0\n1\n0\n1434.634\n1439.007\n1434.640\n\n\n21\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n22\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n23\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n24\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\n\n\nCode\ncat(\"\\n Best Model in terms of AIC: \\n\")\n\n\n\n Best Model in terms of AIC: \n\n\nCode\ntemp[which.min(temp$AIC),] \n\n\n   p d q      AIC      BIC     AICc\n12 2 1 3 1120.047 1146.287 1120.192\n\n\nCode\ncat(\"\\n Best Model in terms of AICc: \\n\")\n\n\n\n Best Model in terms of AICc: \n\n\nCode\ntemp[which.min(temp$AICc),]\n\n\n   p d q      AIC      BIC     AICc\n12 2 1 3 1120.047 1146.287 1120.192\n\n\nCode\ncat(\"\\n Best Model in terms of BIC: \\n\")\n\n\n\n Best Model in terms of BIC: \n\n\nCode\ntemp[which.min(temp$BIC),]\n\n\n  p d q      AIC      BIC     AICc\n2 0 1 1 1129.146 1137.892 1129.166\n\n\nCode\ncat(\"\\nModel summary and error metrics of ARIMA(0, 1, 1): \\n\")\n\n\n\nModel summary and error metrics of ARIMA(0, 1, 1): \n\n\nCode\nfit <- Arima(lx, order=c(0,1,1)) # no drift included \nsummary(fit)\n\n\nSeries: lx \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8436\ns.e.   0.0240\n\nsigma^2 = 0.3992:  log likelihood = -562.57\nAIC=1129.15   AICc=1129.17   BIC=1137.89\n\nTraining set error measures:\n                     ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.0182295 0.6307598 0.4949849 -Inf  Inf 0.7886882 0.01012716\n\n\nThe best model with the lowest BIC metric is the ARIMA(0,1,1). This model is a pure moving average model with first-order differencing and a single lagged moving average term. Therefore, the model has no autoregressive terms, i.e., it does not use the past values of the variable to predict its future values. It uses only the difference between the current and previous values of the variable and the error term to make the forecast. Although, according to both AIC and AICc metrics, the ARIMA(2,1,3) model is better, we shall choose our model using the BIC metric because BIC is more stringent than AIC in penalizing the number of parameters used in the model, making it more effective in helping reduce overfitting.\nARIMA(2,1,3) is a time series model that involves taking the first-order difference of the series, using two Autoregressive (AR) terms and three Moving Average (MA) terms. This means that the model uses not only the past two values of the variable, but also the past three errors to make the forecast. The inclusion of the MA terms allows the model to capture the influence of random shocks or noise in the data. However, including too many autoregressive terms may lead to overfitting, which can result in poor forecast performance and we shall explore that in the next few sections\nThe choice between ARIMA(0,1,1) and ARIMA(2,1,3) depends on the nature of the data and the performance of the models in terms of RMSE or other error metrics. If the data has a clear trend, then including Autoregressive terms may improve the forecast accuracy. On the other hand, if the data is more random, then a simpler model like ARIMA(0,1,1) may be sufficient. There is a clear decreasing trend of monthly terrorist attacks from the 1970s to 2015, with random and/or seasonal fluctuations, but the number of attacks does start increasing sharply after 2015. Therefore, no single pattern is discerned along the entire series and, moreover, we shall be abiding by the principle of parsimony if we select ARIMA(0,1,1) as the best model.\nThe equation of the ARIMA(0,1,1) model is given by:\n\\(\\begin{equation}(1-B)(1-\\theta_1B)X_t = \\omega_t\\end{equation}\\), giving us:\n\\(\\begin{equation}\\left(1-\\theta_1B+B-\\theta_1B^2\\right)X_t = \\omega_t\\end{equation}\\), giving us:\n\\(\\begin{equation}\\left(1-\\theta_1B\\right)X_t - B\\left(1-\\theta_1B\\right)X_t = \\omega_t\\end{equation}\\), giving us:\n\\(\\begin{equation}X_t - \\theta_1X_{t-1} - B\\left(X_{t-1}-\\theta_1X_{t-2}\\right) = \\omega_t\\end{equation}\\), finally substituting the MA(1) values from the model’s summary:\n\\(\\begin{equation}X_t = -0.8436X_{t-1} + X_{t-1} + 0.8436X_{t-2} + \\omega_t\\end{equation}\\), where \\((1-B)\\) is the differencing operator, which represents the first-order difference of the series. \\(X_t\\) is the time series, \\(\\theta_1\\) is the parameter of the MA component, and \\(\\omega_t\\) is the Gaussian white noise process.\nNote that \\(B\\) is the backshift operator, which shifts the time series back by one period.\n\n\nModel Diagnostics of ARIMA(0,1,1)\n\n\nCode\nmodel_output <- capture.output(sarima(lx, 0,1,1))\n\n\n\n\n\n\n\nCode\ncat(model_output[24:55], model_output[length(model_output)], sep = \"\\n\") \n\n\nconverged\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, \n        REPORT = 1, reltol = tol))\n\nCoefficients:\n          ma1  constant\n      -0.8453   -0.0028\ns.e.   0.0239    0.0041\n\nsigma^2 estimated as 0.3982:  log likelihood = -562.33,  aic = 1130.67\n\n$degrees_of_freedom\n[1] 584\n\n$ttable\n         Estimate     SE  t.value p.value\nma1       -0.8453 0.0239 -35.3385  0.0000\nconstant  -0.0028 0.0041  -0.6943  0.4877\n\n$AIC\n[1] 1.929468\n\n$AICc\n[1] 1.929504\n\n$BIC\n[1] 1.951857\n\n\nStandardized Residuals: Essentially stating that if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\nACF Of Residuals: Auto-correlation of the residuals. The only q value to inspect is 1.\nQ-Q Plot: The series follows a normal distribution pretty closely as even the tails seem to be on the normal line.\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value greater than 0.05, the residuals have no remaining autocorrelations.\nThe only MA term in the ARIMA(0,1,1) model is also significant at the \\(\\alpha\\)=5% level as shown by its p-value = 0. Let’s check whether all terms in the ARIMA(2,1,3) model are significant or not.\n\n\nModel Diagnostics of ARIMA(2,1,3)\n\n\nCode\nmodel_output2 <- capture.output(sarima(lx, 2,1,3))\n\n\n\n\n\n\n\nCode\ncat(model_output2[205:239], model_output2[length(model_output2)], sep = \"\\n\") \n\n\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, \n        REPORT = 1, reltol = tol))\n\nCoefficients:\n         ar1      ar2      ma1     ma2      ma3  constant\n      0.8068  -0.5518  -1.6452  1.2913  -0.5429   -0.0026\ns.e.  0.4763   0.4308   0.4609  0.7776   0.3347    0.0036\n\nsigma^2 estimated as 0.3934:  log likelihood = -558.77,  aic = 1131.54\n\n$degrees_of_freedom\n[1] 580\n\n$ttable\n         Estimate     SE t.value p.value\nar1        0.8068 0.4763  1.6939  0.0908\nar2       -0.5518 0.4308 -1.2809  0.2007\nma1       -1.6452 0.4609 -3.5693  0.0004\nma2        1.2913 0.7776  1.6608  0.0973\nma3       -0.5429 0.3347 -1.6223  0.1053\nconstant  -0.0026 0.0036 -0.7029  0.4824\n\n$AIC\n[1] 1.93095\n\n$AICc\n[1] 1.931198\n\n$BIC\n[1] 1.983192\n\n\nLike the ARIMA(0,1,1) output for the summary of residuals, the ARIMA(2,1,3) does as well, if not better. The ACF of residuals for ARIMA(2,1,3), although, has spikes less significant than ARIMA(0,1,1) and the p-values for Ljung-Box test for ARIMA(2,1,3) are higher than those of ARIMA(0,1,1). However, a key difference is that only the MA(1) term in the ARIMA(2,1,3) model is significant at the \\(\\alpha\\)=5% level as shown by its p-value = 0.0004 and all other terms are not significant. Therefore, a simpler model, ARIMA(0,1,1), would be a better fit to the log of monthly attacks series.\nLet’s see what model is outputted by auto.arima().\n\n\nChecking Model Output of Log Monthly Attacks with auto.arima()\n\n\nCode\nfit = auto.arima(lx, seasonal = FALSE)\ncat(\"Model metrics using auto.arima(): \\n\")\n\n\nModel metrics using auto.arima(): \n\n\nCode\nsummary(fit)\n\n\nSeries: lx \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8436\ns.e.   0.0240\n\nsigma^2 = 0.3992:  log likelihood = -562.57\nAIC=1129.15   AICc=1129.17   BIC=1137.89\n\nTraining set error measures:\n                     ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.0182295 0.6307598 0.4949849 -Inf  Inf 0.7886882 0.01012716\n\n\nFrom the above output, auto.arima() too outputted an ARIMA(0,1,1) model, which is is the best model returned by the Arima() function in terms of lowest BIC. Some points to keep in mind when using these functions is as follows:\nThe auto.arima() function in R uses a stepwise algorithm to search through the space of possible ARIMA models and select the one with the lowest AIC value. While this approach can be computationally efficient and provide a good starting point for model selection, it does not necessarily always find the best possible model for a given time series.\nOn the other hand, the Arima() function in R allows us to specify the exact order of the ARIMA model and can be used to fit more complex models, such as those with seasonality, exogenous variables, or other constraints. By specifying the exact order of the model, we have more control over the modeling process and can potentially obtain a better fit to the data.\nIn summary, the auto.arima() function can be a useful tool for quickly identifying a potentially good model, but it is not a substitute for careful model selection and customization seen when using the Arima() function.\n\n\nForecasting ARIMA(0,1,1) and ARIMA(2,1,3)\n\n\nCode\narimaModel_1 <- arima(lx, order = c(0,1,1))\narimaModel_2 <- arima(lx, order = c(2,1,3))\n\nforecast1=predict(arimaModel_1, length(test_series)) # make forecasts for 2 years ahead as given by length of test_series\nforecast2=predict(arimaModel_2, length(test_series))\n\n# Convert the time series and forecast objects to data frames\nts_df <- data.frame(date = time(monthly_attacks_ts), value = as.numeric(monthly_attacks_ts))\ntrain_df <- data.frame(date = time(monthly_attacks_ts)[1:587], value = as.numeric(lx))\nforecast1_df <- data.frame(date = time(monthly_attacks_ts)[588:612], value = forecast1$pred)\nforecast2_df <- data.frame(date = time(monthly_attacks_ts)[588:612], value = forecast2$pred)\n\n# Plot the time series and forecasts\nggplotly(ggplot() +\n    geom_line(data = train_df[500:588,], aes(x = date, y = value, \n              color = \"Actual Train Values\"), linetype = \"solid\", alpha=0.6, show.legend = TRUE) +\n    geom_point(data = train_df[500:588,], aes(x = date, y = value), \n               color = \"red\", shape = 16, alpha=0.4, show.legend = TRUE) +\n    geom_line(data = forecast1_df, aes(x = date, y = value, \n                                       color = \"ARIMA(0,1,1) Forecast\"), linetype = \"solid\", show.legend = TRUE) +\n    geom_line(data = forecast2_df, aes(x = date, y = value, \n                                       color = \"ARIMA(2,1,3) Forecast\"), linetype = \"solid\", show.legend = TRUE) +\n    geom_line(data = ts_df[588:612,], aes(x = date, y = log(value), \n                                       color = \"Actual Forecast Values\"), linetype = \"solid\", show.legend = TRUE) +\n    labs(x = \"Date\", y = \"Log of Number of Monthly Attacks\", title = \"Forecasting ARIMA(0,1,1) and ARIMA(2,1,3)\") +\n    theme_minimal() +\n    scale_color_manual(name = \"Forecast\", \n                       values = c(\"ARIMA(0,1,1) Forecast\" = \"blue\", \n                                  \"ARIMA(2,1,3) Forecast\" = \"green\",\n                                   \"Actual Forecast Values\" = \"orange\"),\n                       labels = c(\"ARIMA(0,1,1) Forecast\", \n                                  \"ARIMA(2,1,3) Forecast\",\n                                  \"Actual Forecast Values\")))\n\n\n\n\n\n\nFrom the above graph, we can note that the forecasted number of attacks remains constant at around 1 for both models on the test set (October 2010 to December 2020). This performance is not what was expected and, hence, it is possible that the models are not able to capture the underlying patterns in the data. This can be due to a variety of reasons, such as insufficient data and the models not being complex enough to capture the variation in the data. It is, however, pragmatic to check whether the sarima.for() function’s predictions may forecast differently. Let us find out below.\n\n\nForecasting ARIMA(0,1,1) using sarima.for()\n\n\nCode\nlog_monthly_attacks <- ts(lx, start = c(1970, 1), frequency = 12) # Objects of class <numeric> are not supported by autoplot.\nsarima.for(ts(train_df$value, start = c(1970, 1), frequency = 12), 24, p = 0, d = 1, q = 1, main = \"Forecasting ARIMA(0,1,1) using sarima.for()\") \n\n\n\n\n\n$pred\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2018                                                                        \n2019 1.954087 1.951260 1.948432 1.945605 1.942778 1.939950 1.937123 1.934296\n2020 1.920159 1.917332 1.914505 1.911678 1.908850 1.906023 1.903196 1.900368\n          Sep      Oct      Nov      Dec\n2018                            1.956914\n2019 1.931469 1.928641 1.925814 1.922987\n2020 1.897541 1.894714 1.891886         \n\n$se\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2018                                                                      \n2019 0.6385446 0.6459664 0.6533040 0.6605600 0.6677372 0.6748381 0.6818650\n2020 0.7225930 0.7291599 0.7356681 0.7421193 0.7485148 0.7548562 0.7611448\n           Aug       Sep       Oct       Nov       Dec\n2018                                         0.6310354\n2019 0.6888203 0.6957060 0.7025242 0.7092769 0.7159659\n2020 0.7673818 0.7735685 0.7797062 0.7857959          \n\n\nLike the previous forecast, we can note that sarima.for() too does not accurately capture the inherent randomness and/or seasonality in the series and, hence, it outputs a highly linear, downward trending forecast. As per its 95% confidence bound, the number of attacks will fluctuate anywhere between 3 to 12 attacks every month from 2019 to end of 2020 (keep in mind that the plot is log of monthly attacks).\n\n\nComparing ARIMA(0,1,1) with Benchmarks\n\n\nCode\nautoplot(log_monthly_attacks) +\n  autolayer(meanf(log_monthly_attacks, h=24),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(log_monthly_attacks, h=24),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(log_monthly_attacks, h=24),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(log_monthly_attacks, h=24, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n  autolayer(forecast(Arima(log_monthly_attacks, order=c(0,1,1)), 24), \n            series=\"ARIMA(0,1,1)\",PI=FALSE) +\n  guides(colour=guide_legend(title=\"Forecast\")) +\n  ylab(\"Log of Monthly Attacks\") + ggtitle(\"Forecasting ARIMA(0,1,1) and Benchmarks\") + theme_minimal()\n\n\n\n\n\nCode\ncat(\"ARIMA(0,1,1) model metrics: \\n\")\n\n\nARIMA(0,1,1) model metrics: \n\n\nCode\nfit <- Arima(log_monthly_attacks, order=c(0,1,1))\nsummary(fit)\n\n\nSeries: log_monthly_attacks \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8436\ns.e.   0.0240\n\nsigma^2 = 0.3992:  log likelihood = -562.57\nAIC=1129.15   AICc=1129.17   BIC=1137.89\n\nTraining set error measures:\n                     ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.0182295 0.6307598 0.4949849 -Inf  Inf 0.7143174 0.01012716\n\n\nCode\ncat(\"\\nMean metrics: \\n\")\n\n\n\nMean metrics: \n\n\nCode\nf1 <- meanf(log_monthly_attacks, h=24) \n\ncheckresiduals(f1)\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Mean\nQ* = 2327.6, df = 23, p-value < 2.2e-16\n\nModel df: 1.   Total lags used: 24\n\n\nCode\naccuracy(f1)\n\n\n                       ME      RMSE       MAE  MPE MAPE      MASE     ACF1\nTraining set 1.113627e-15 0.8556503 0.6744582 -Inf  Inf 0.9733169 0.534751\n\n\nCode\ncat(\"\\nSnaive metrics: \\n\")\n\n\n\nSnaive metrics: \n\n\nCode\nf2 <- snaive(log_monthly_attacks, h=24) \n\ncheckresiduals(f2)\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Seasonal naive method\nQ* = 173.01, df = 24, p-value < 2.2e-16\n\nModel df: 0.   Total lags used: 24\n\n\nCode\naccuracy(f2)\n\n\n                      ME      RMSE       MAE  MPE MAPE MASE      ACF1\nTraining set -0.03643642 0.8807625 0.6929481 -Inf  Inf    1 0.1556335\n\n\nCode\ncat(\"\\nRandom Walk metrics: \\n\")\n\n\n\nRandom Walk metrics: \n\n\nCode\nf3 <- rwf(log_monthly_attacks, h=24) \n\ncheckresiduals(f3)\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Random walk\nQ* = 178.32, df = 24, p-value < 2.2e-16\n\nModel df: 0.   Total lags used: 24\n\n\nCode\naccuracy(f3)\n\n\n                       ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.001694969 0.8215562 0.6276053 -Inf  Inf 0.9057032 -0.5152558\n\n\nFrom the above plot, only the Snaive benchmark method’s forecasts seem more plausible compared to that of the ARIMA(0,1,1) model. The forecasts produced from the Snaive benchmark have the greatest amount of fluctuations or seasonality in a higher range of number of monthly attacks. However, the metrics paint a different story. The ARIMA(0,1,1) model’s training error measures are better than those of all the benchmarks. There are several reasons for this phenomenon:\nModel Assumptions: The ARIMA model assumes that the data is stationary, which means that the mean and variance of the data do not change over time. If the data violates this assumption, the ARIMA model may not perform well. In contrast, the Snaive model does not assume stationarity, which may make it more robust to non-stationary data.\nParameter Estimation: The ARIMA model has three parameters (p, d, q) that need to be estimated, whereas the Snaive model has only one parameter (the seasonality). It is possible that the parameter estimation process for the ARIMA model was not optimal, leading to suboptimal forecast performance.\nForecast Horizon: The Snaive model may perform better than the ARIMA model for shorter forecast horizons, while the ARIMA model may perform better for longer forecast horizons. This is because the Snaive model assumes that the future values of the time series will be the same as the past values at the same time of year, which may be a reasonable assumption for short forecast horizons, but not for longer ones."
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-sarima-modeling",
    "href": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-sarima-modeling",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Global Terrorism Database SARIMA Modeling",
    "text": "Global Terrorism Database SARIMA Modeling\n\nVisualizing Seasonal Components of Monthly Attacks\n\n\nCode\n# Visualize Seasonal Component\nattacks.s=decompose(monthly_attacks_ts)$seasonal\nplot(attacks.s, axes=FALSE, main='Seasonal Component of Number of Monthly Terrorist Attacks in the US Over Time', xlab=\"Time\", type='c') \nQuarters = c(\"1\",\"2\",\"3\",\"4\") \npoints(attacks.s, pch=Quarters, cex=1, font=4, col=1:4)\naxis(1, 1:4); abline(v=1:4, lty=2, col=gray(.7))\naxis(2); box()\n\n\n\n\n\nFrom the above seasonal component graph of the number of monthly terrorist attacks, we notice there does exist some level of seasonality in the original series. The seasonal component graph illustrates the degree of seasonal variation in the number of terrorist attacks. The magnitude of the seasonal variation is shown on the y-axis of the graph, and it indicates how much the number of terrorist attacks deviates from the average value for each season. The graph shows a repeating pattern in the number of terrorist attacks over time, with clear peaks in the first and second quarters and troughs in the third quarter. This pattern implies that the number of terrorist attacks in the US might be influenced by the season of the year.\n\n\nVisualizing Seasonally Differenced Monthly Attacks\n\n\nCode\n# Seasonal differenced\nattacks.diff=diff(monthly_attacks_ts,12)\nplot(attacks.diff, axes=FALSE, main='Number of Monthly Terrorist Attacks (S. differenced)',type='c') #with type='c' I get dashed lines\nQuarters = c(\"1\",\"2\",\"3\",\"4\") \npoints(attacks.diff, pch=Quarters, cex=1, font=4, col=1:4)\naxis(1, 1:4); abline(v=1:4, lty=2, col=gray(.7))\naxis(2); box()\n\n\n\n\n\n\n\nACF and PACF Plots of Seasonally Differenced Monthly Attacks\n\n\nCode\nmonthly_attacks_ts %>% \n  diff(lag=12) %>% \n  ggtsdisplay(main=\"ACF and PACF Plots of First Seasonal Differenced Monthly Attacks\")\n\n\n\n\n\nAfter first ordinary differencing the original series (ACF?), we saw a lot of seasonal correlation left, suggesting that first order differencing did not help in transforming the raw data into a stationary series. This differenced series cannot be used for building a robust SARIMA model. Therefore, a seasonal differencing on the original monthly attacks was performed above and we can still notice some correlation left, but lesser compared to when the raw series was differenced with first order. Therefore, it could be that D=1 and d=0. Let’s keep this as one option and let’s proceed with performing both seasonal differencing and first-order differencing the raw monthly attacks series.\n\n\nACF and PACF Plots of Seasonally and First Order Differenced Monthly Attacks\n\n\nCode\nmonthly_attacks_ts %>% \n  diff(lag=12) %>% \n  diff() %>%\n  ggtsdisplay(main=\"ACF and PACF Plots of Seasonally and First Order Differenced Monthly Attacks\")\n\n\n\n\n\nAfter both seasonal differencing and ordinary differencing together the raw data, the ACF and PACF plots seem to portray the least correlation than the individual differencing methods. Next, we shall difference and select the relevant p,d,q,P,D,Q values from the original monthly attacks series for our SARIMA model.\nFrom the seasonal differencing and ordinary differencing (together) ACF and PACF plots, the following combinations for p,d,q,P,D,Q are:\nq values obtained from ACF = 0,1,2,3,4 Q values obtained from ACF = 1 p values obtained from PACF = 0,1,2,3,4 P values obtained from PACF = 1,2 d (Difference) = 1 D (Seasonal Difference) = 1\n\n\nFitting ARIMA(p,d,q)(P,D,Q)\n\n\nCode\n######################## Check for different combinations ########\n\n\n#write a funtion\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  #K=(p2+1)*(q2+1)*(P2+1)*(Q2+1)\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*29),nrow=29)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q<=9) # parsimonious principle\n          {\n            \n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n            }\n          }\n        }\n      }\n    }\n  \n  \n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\n\n\nCode\n# q=0,1,2,3,4; Q=1 and PACF plot: p=0,1,2,3,4; P=1,2; D=1 and d=1\n\noutput=SARIMA.c(p1=1,p2=5,q1=1,q2=5,P1=1,P2=3,Q1=1,Q2=2,data=monthly_attacks_ts)\n#output\n\nknitr::kable(output)\n\n\n\n\n\np\nd\nq\nP\nD\nQ\nAIC\nBIC\nAICc\n\n\n\n\n0\n1\n0\n0\n1\n0\n3952.891\n3957.286\n3952.897\n\n\n0\n1\n0\n0\n1\n1\n3670.269\n3679.059\n3670.289\n\n\n0\n1\n0\n1\n1\n0\n3827.797\n3836.587\n3827.817\n\n\n0\n1\n0\n1\n1\n1\n3670.336\n3683.521\n3670.376\n\n\n0\n1\n0\n2\n1\n0\n3765.751\n3778.937\n3765.791\n\n\n0\n1\n0\n2\n1\n1\n3671.380\n3688.961\n3671.447\n\n\n0\n1\n1\n0\n1\n0\n3705.459\n3714.249\n3705.479\n\n\n0\n1\n1\n0\n1\n1\n3495.035\n3508.220\n3495.075\n\n\n0\n1\n1\n1\n1\n0\n3596.169\n3609.355\n3596.209\n\n\n0\n1\n1\n1\n1\n1\n3492.557\n3510.138\n3492.625\n\n\n0\n1\n1\n2\n1\n0\n3570.165\n3587.746\n3570.232\n\n\n0\n1\n2\n0\n1\n0\n3701.229\n3714.415\n3701.269\n\n\n0\n1\n2\n0\n1\n1\n3493.391\n3510.972\n3493.458\n\n\n0\n1\n2\n1\n1\n0\n3595.313\n3612.894\n3595.381\n\n\n0\n1\n3\n0\n1\n0\n3699.991\n3717.572\n3700.058\n\n\n1\n1\n0\n0\n1\n0\n3818.806\n3827.596\n3818.826\n\n\n1\n1\n0\n0\n1\n1\n3553.235\n3566.421\n3553.276\n\n\n1\n1\n0\n1\n1\n0\n3693.837\n3707.023\n3693.878\n\n\n1\n1\n0\n1\n1\n1\n3552.817\n3570.398\n3552.884\n\n\n1\n1\n0\n2\n1\n0\n3651.212\n3668.793\n3651.279\n\n\n1\n1\n1\n0\n1\n0\n3700.223\n3713.408\n3700.263\n\n\n1\n1\n1\n0\n1\n1\n3492.442\n3510.023\n3492.510\n\n\n1\n1\n1\n1\n1\n0\n3594.929\n3612.510\n3594.996\n\n\n1\n1\n2\n0\n1\n0\n3704.894\n3722.475\n3704.961\n\n\n2\n1\n0\n0\n1\n0\n3777.584\n3790.770\n3777.624\n\n\n2\n1\n0\n0\n1\n1\n3521.643\n3539.224\n3521.710\n\n\n2\n1\n0\n1\n1\n0\n3654.644\n3672.225\n3654.712\n\n\n2\n1\n1\n0\n1\n0\n3700.164\n3717.745\n3700.232\n\n\n3\n1\n0\n0\n1\n0\n3772.136\n3789.717\n3772.204\n\n\n\n\n\nCode\ncat(\"\\n Best Model in terms of AIC: \\n\")\n\n\n\n Best Model in terms of AIC: \n\n\nCode\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n\n\nCode\ncat(\"\\n Best Model in terms of AICc: \\n\")\n\n\n\n Best Model in terms of AICc: \n\n\nCode\noutput[which.min(output$AICc),]\n\n\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n\n\nCode\ncat(\"\\n Best Model in terms of BIC: \\n\")\n\n\n\n Best Model in terms of BIC: \n\n\nCode\noutput[which.min(output$BIC),]\n\n\n  p d q P D Q      AIC     BIC     AICc\n8 0 1 1 0 1 1 3495.035 3508.22 3495.075\n\n\nThe best model with the lowest BIC metric is the SARIMA(0,1,1,0,1,1) model. Although, according to both AIC and AICc metrics, the SARIMA(1,1,1,0,1,1) is better, we shall choose our model using the BIC metric because BIC is more stringent than AIC in penalizing the number of parameters used in the model, making it more effective in helping reduce overfitting. The equation of the SARIMA(0,1,1,0,1,1) model is given by:\n\\(\\begin{equation}(1-B)(1-B^1)y_t = \\delta + (1+\\phi_1B)(1-\\theta_1B-\\theta_2B^2)w_t\\end{equation}\\), where \\((1-B)\\) and \\((1-B^1)\\) are the differencing operators, which represent the first-order difference of the series. \\(y_t\\) is the time series, \\(\\delta\\) is the drift term, \\(\\phi_1\\) and \\(\\theta_1\\), \\(\\theta_2\\) are the parameters of the AR and MA parts, respectively, and \\(w_t\\) is the Gaussian white noise process.\nNote that \\(B\\) is the backshift operator, which shifts the time series back by one period.\n\n\nModel Diagnostics of ARIMA(0,1,1)(0,1,1)\n\n\nCode\nmodel_output <- capture.output(sarima(monthly_attacks_ts, 0,1,1,0,1,1,12))\n\n\n\n\n\nStandardized Residuals: Essentially stating if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\nACF Of Residuals: However, looking at the ACF of the Residuals gives us a definitive answer to whether the model is stationary. Because some spikes are not within the significance limits, the model is not being able to capture all the signal in the data. In fact, the ARIMA(1,1,2) model’s diagnostics are better than that of ARIMA(0,1,1)(0,1,1) above.\nQ-Q Plot: The series weakly follows a normal distribution as the tails waver away significantly from the normal line.\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value less than 0.05, residuals have remaining autocorrelations.\n\n\nForecast for the next 3 years using ARIMA(0,1,1)(0,1,1)\n\n\nCode\nfit <- Arima(monthly_attacks_ts, order=c(0,1,1), seasonal=c(0,1,1))\nsummary(fit)\n\n\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n\n\nCode\nfit %>% forecast(h=36) %>% autoplot() #next 3 years\n\n\n\n\n\n\n\nComparing ARIMA(0,1,1)(0,1,1) with benchmarks\n\n\nCode\ncat(\"Best model metrics: \\n\")\n\n\nBest model metrics: \n\n\nCode\nfit <- Arima(monthly_attacks_ts, order=c(0,1,1), seasonal=c(0,1,1))\n\nautoplot(monthly_attacks_ts) +\n  autolayer(meanf(monthly_attacks_ts, h=36),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(monthly_attacks_ts, h=36),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(monthly_attacks_ts, h=36),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(monthly_attacks_ts, h=36, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n  autolayer(forecast(fit,36), \n            series=\"fit\",PI=FALSE) +\n  guides(colour=guide_legend(title=\"Forecast\"))\n\n\n\n\n\nCode\ncat(\"Best model metrics: \\n\")\n\n\nBest model metrics: \n\n\nCode\nsummary(fit)\n\n\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n\n\nCode\ncat(\"Snaive metrics: \\n\")\n\n\nSnaive metrics: \n\n\nCode\nf2 <- snaive(monthly_attacks_ts, h=36) \n\naccuracy(f2)\n\n\n                     ME     RMSE      MAE  MPE MAPE MASE      ACF1\nTraining set -0.6016667 6.093029 3.808333 -Inf  Inf    1 0.4168619\n\n\n\n\nSeasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 1 step ahead forecasts\n\n\nCode\nk <- 75 # minimum data length for fitting a model \nn <- length(monthly_attacks_ts)\n#n-k # rest of the observations\n\nset.seed(133)\n\nfarima1 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(0,1,1),seasonal=c(0,1,1)), h=h)}\ne <- tsCV(monthly_attacks_ts, farima1, h=1)\n\nMAE1 <-abs(mean(e,na.rm=TRUE))\ncat(\"MAE for ARIMA(0,1,1)(0,1,1) is: \", MAE1)\n\n\nMAE for ARIMA(0,1,1)(0,1,1) is:  2.155092\n\n\nCode\nRMSE1=sqrt(mean(e^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"\\nRMSE for ARIMA(0,1,1)(0,1,1) is: \", RMSE1)\n\n\n\nRMSE for ARIMA(0,1,1)(0,1,1) is:  7.428068\n\n\nCode\nfarima2 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(1,1,1),seasonal=c(0,1,1)), h=h)}\ne <- tsCV(monthly_attacks_ts, farima2, h=1)\n\nMAE2 <-abs(mean(e,na.rm=TRUE))\ncat(\"\\nMAE for ARIMA(1,1,1)(0,1,1) is: \", MAE2)\n\n\n\nMAE for ARIMA(1,1,1)(0,1,1) is:  2.092574\n\n\nCode\nRMSE2=sqrt(mean(e^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"\\nRMSE for ARIMA(1,1,1)(0,1,1) is: \", RMSE2)\n\n\n\nRMSE for ARIMA(1,1,1)(0,1,1) is:  7.410171\n\n\nBoth MAE and RMSE metrics agree that ARIMA(1,1,1)(0,1,1) is the best model by a slight margin. However, the BIC metric does not agree with this result as it outputted ARIMA(0,1,1)(0,1,1) as the model with lowest BIC. AIC and AICc metrics, however, do agree with the MAE and RMSE metrics generated from Seasonal Cross Validation using 1 step ahead forecasts. Let’s see whether this is the case when forecasting 12 steps ahead.\n\n\nSeasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 12 steps (seasonal period) ahead forecasts\n\n\nCode\nk <- 75 # minimum data length for fitting a model \nn <- length(monthly_attacks_ts)\nn-k # rest of the observations\n\n\n[1] 537\n\n\nCode\nset.seed(133)\n\nfarima1 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(0,1,1),seasonal=c(0,1,1)), h=h)}\n\n# Compute cross-validated errors for up to 12 steps ahead\ne <- tsCV(monthly_attacks_ts, forecastfunction = farima1, h = 12)\n\nmse1 <- colMeans(e^2, na.rm = TRUE)\n\nfarima2 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(1,1,1),seasonal=c(0,1,1)), h=h)}\n# Compute cross-validated errors for up to 12 steps ahead\ne <- tsCV(monthly_attacks_ts, forecastfunction = farima2, h = 12)\n\n# Compute the MSE values and remove missing values\nmse2 <- colMeans(e^2, na.rm = TRUE)\n\n# Plot the MSE values against the forecast horizon\ndata.frame(h = 1:12, MSE1 = mse1, MSE2 = mse2) %>%\n  ggplot() + geom_point(aes(y=MSE1,x= h)) + geom_point(aes(y=MSE2,x= h)) +\n           geom_line(aes(y=MSE1,x= h,colour=\"MSE for ARIMA(0,1,1)(0,1,1)\")) + \n           geom_line(aes(y=MSE2,x= h,colour=\"MSE for ARIMA(1,1,1)(0,1,1)\"))+\n  theme_minimal()\n\n\n\n\n\nThis plot gives cross-validation statistics up to horizon 12. The procedure for seasonal cross validation using 12 steps ahead is very similar to seasonal cross validation using 1 step ahead. We need to change the “h” parameter to the desired the number of time horizons we want to forecast for. The farima() function manually written by us helps us call our desired SARIMA model with the number of horizons. Then, farima() function is called inside the tsCV() function, which helps us store the cross-validated errors for up to 12 steps ahead. Then, because we get forecasts for each time horizon, we need to take the mean of the squared column using colMeans to obtain MSE.\nAlthough we observed that the MSE and RMSE of ARIMA(1,1,1)(0,1,1) when forecasting 1 step ahead was lower than that of ARIMA(0,1,1)(0,1,1), from the above plot it can be seen that the cross-validated MSEs get lower or better as the number of forecasting steps increases. Both models’ MSE performance follow a very similar pattern, with ARIMA(0,1,1)(0,1,1), picked by lowest BIC, having a lower MSE across all forecasting steps, except for step 1. Therefore, ARIMA(0,1,1)(0,1,1) is the better SARIMA model!"
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#visualizing-seasonal-components-of-monthly-attacks",
    "href": "ARMA-ARIMA-SARIMA.html#visualizing-seasonal-components-of-monthly-attacks",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Visualizing Seasonal Components of Monthly Attacks",
    "text": "Visualizing Seasonal Components of Monthly Attacks\n\n\n\n\n\nFrom the above seasonal component graph of the number of monthly terrorist attacks, we notice there does exist some level of seasonality in the original series. The seasonal component graph illustrates the degree of seasonal variation in the number of terrorist attacks. The magnitude of the seasonal variation is shown on the y-axis of the graph, and it indicates how much the number of terrorist attacks deviates from the average value for each season. The graph shows a repeating pattern in the number of terrorist attacks over time, with clear peaks in the first and second quarters and troughs in the third quarter. This pattern implies that the number of terrorist attacks in the US might be influenced by the season of the year."
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#visualizing-seasonally-differenced-monthly-attacks",
    "href": "ARMA-ARIMA-SARIMA.html#visualizing-seasonally-differenced-monthly-attacks",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Visualizing Seasonally Differenced Monthly Attacks",
    "text": "Visualizing Seasonally Differenced Monthly Attacks\n\n\n\n\n\n\nACF and PACF Plots of Seasonally Differenced Monthly Attacks\n\n\n\n\n\nAfter first ordinary differencing the original series (ACF?), we saw a lot of seasonal correlation left, suggesting that first order differencing did not help in transforming the raw data into a stationary series. This differenced series cannot be used for building a robust SARIMA model. Therefore, a seasonal differencing on the original monthly attacks was performed above and we can still notice some correlation left, but lesser compared to when the raw series was differenced with first order. Therefore, it could be that D=1 and d=0. Let’s keep this as one option and let’s proceed with performing both seasonal differencing and first-order differencing the raw monthly attacks series.\n\n\nACF and PACF Plots of Seasonally and First Order Differenced Monthly Attacks\n\n\n\n\n\nAfter both seasonal differencing and ordinary differencing together the raw data, the ACF and PACF plots seem to portray the least correlation than the individual differencing methods. Next, we shall difference and select the relevant p,d,q,P,D,Q values from the original monthly attacks series for our SARIMA model.\nFrom the seasonal differencing and ordinary differencing (together) ACF and PACF plots, the following combinations for p,d,q,P,D,Q are:\nq values obtained from ACF = 0,1,2,3,4 Q values obtained from ACF = 1 p values obtained from PACF = 0,1,2,3,4 P values obtained from PACF = 1,2 d (Difference) = 1 D (Seasonal Difference) = 1\n\n\nFitting ARIMA(p,d,q)(P,D,Q)\n\n\n\n\n# q=0,1,2,3,4; Q=1 and PACF plot: p=0,1,2,3,4; P=1,2; D=1 and d=1\n\noutput=SARIMA.c(p1=1,p2=5,q1=1,q2=5,P1=1,P2=3,Q1=1,Q2=2,data=monthly_attacks_ts)\n#output\n\nknitr::kable(output)\n\n\n\n\np\nd\nq\nP\nD\nQ\nAIC\nBIC\nAICc\n\n\n\n\n0\n1\n0\n0\n1\n0\n3952.891\n3957.286\n3952.897\n\n\n0\n1\n0\n0\n1\n1\n3670.269\n3679.059\n3670.289\n\n\n0\n1\n0\n1\n1\n0\n3827.797\n3836.587\n3827.817\n\n\n0\n1\n0\n1\n1\n1\n3670.336\n3683.521\n3670.376\n\n\n0\n1\n0\n2\n1\n0\n3765.751\n3778.937\n3765.791\n\n\n0\n1\n0\n2\n1\n1\n3671.380\n3688.961\n3671.447\n\n\n0\n1\n1\n0\n1\n0\n3705.459\n3714.249\n3705.479\n\n\n0\n1\n1\n0\n1\n1\n3495.035\n3508.220\n3495.075\n\n\n0\n1\n1\n1\n1\n0\n3596.169\n3609.355\n3596.209\n\n\n0\n1\n1\n1\n1\n1\n3492.557\n3510.138\n3492.625\n\n\n0\n1\n1\n2\n1\n0\n3570.165\n3587.746\n3570.232\n\n\n0\n1\n2\n0\n1\n0\n3701.229\n3714.415\n3701.269\n\n\n0\n1\n2\n0\n1\n1\n3493.391\n3510.972\n3493.458\n\n\n0\n1\n2\n1\n1\n0\n3595.313\n3612.894\n3595.381\n\n\n0\n1\n3\n0\n1\n0\n3699.991\n3717.572\n3700.058\n\n\n1\n1\n0\n0\n1\n0\n3818.806\n3827.596\n3818.826\n\n\n1\n1\n0\n0\n1\n1\n3553.235\n3566.421\n3553.276\n\n\n1\n1\n0\n1\n1\n0\n3693.837\n3707.023\n3693.878\n\n\n1\n1\n0\n1\n1\n1\n3552.817\n3570.398\n3552.884\n\n\n1\n1\n0\n2\n1\n0\n3651.212\n3668.793\n3651.279\n\n\n1\n1\n1\n0\n1\n0\n3700.223\n3713.408\n3700.263\n\n\n1\n1\n1\n0\n1\n1\n3492.442\n3510.023\n3492.510\n\n\n1\n1\n1\n1\n1\n0\n3594.929\n3612.510\n3594.996\n\n\n1\n1\n2\n0\n1\n0\n3704.894\n3722.475\n3704.961\n\n\n2\n1\n0\n0\n1\n0\n3777.584\n3790.770\n3777.624\n\n\n2\n1\n0\n0\n1\n1\n3521.643\n3539.224\n3521.710\n\n\n2\n1\n0\n1\n1\n0\n3654.644\n3672.225\n3654.712\n\n\n2\n1\n1\n0\n1\n0\n3700.164\n3717.745\n3700.232\n\n\n3\n1\n0\n0\n1\n0\n3772.136\n3789.717\n3772.204\n\n\n\n\ncat(\"\\n Best Model in terms of AIC: \\n\")\n\n\n Best Model in terms of AIC: \n\noutput[which.min(output$AIC),] \n\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n\ncat(\"\\n Best Model in terms of AICc: \\n\")\n\n\n Best Model in terms of AICc: \n\noutput[which.min(output$AICc),]\n\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n\ncat(\"\\n Best Model in terms of BIC: \\n\")\n\n\n Best Model in terms of BIC: \n\noutput[which.min(output$BIC),]\n\n  p d q P D Q      AIC     BIC     AICc\n8 0 1 1 0 1 1 3495.035 3508.22 3495.075\n\n\nThe best model with the lowest BIC metric is the SARIMA(0,1,1,0,1,1) model. Although, according to both AIC and AICc metrics, the SARIMA(1,1,1,0,1,1) is better, we shall choose our model using the BIC metric because BIC is more stringent than AIC in penalizing the number of parameters used in the model, making it more effective in helping reduce overfitting. The equation of the SARIMA(0,1,1,0,1,1) model is given by:\n\\(\\begin{equation}(1-B)(1-B^1)y_t = \\delta + (1+\\phi_1B)(1-\\theta_1B-\\theta_2B^2)w_t\\end{equation}\\), where \\((1-B)\\) and \\((1-B^1)\\) are the differencing operators, which represent the first-order difference of the series. \\(y_t\\) is the time series, \\(\\delta\\) is the drift term, \\(\\phi_1\\) and \\(\\theta_1\\), \\(\\theta_2\\) are the parameters of the AR and MA parts, respectively, and \\(w_t\\) is the Gaussian white noise process.\nNote that \\(B\\) is the backshift operator, which shifts the time series back by one period.\n\n\nModel Diagnostics of ARIMA(0,1,1)(0,1,1)\n\nmodel_output <- capture.output(sarima(monthly_attacks_ts, 0,1,1,0,1,1,12))\n\n\n\n\nStandardized Residuals: Essentially stating if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\nACF Of Residuals: However, looking at the ACF of the Residuals gives us a definitive answer to whether the model is stationary. Because some spikes are not within the significance limits, the model is not being able to capture all the signal in the data. In fact, the ARIMA(1,1,2) model’s diagnostics (ARIMA-Diag?) are better than that of ARIMA(0,1,1)(0,1,1) above.\nQ-Q Plot: The series weakly follows a normal distribution as the tails waver away significantly from the normal line.\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value less than 0.05, residuals have remaining autocorrelations.\n\n\nForecast for the next 3 years using ARIMA(0,1,1)(0,1,1)\n\nfit <- Arima(monthly_attacks_ts, order=c(0,1,1), seasonal=c(0,1,1))\nsummary(fit)\n\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n\nfit %>% forecast(h=36) %>% autoplot() #next 3 years\n\n\n\n\n\n\nComparing ARIMA(0,1,1)(0,1,1) with benchmarks\n\ncat(\"Best model metrics: \\n\")\n\nBest model metrics: \n\nfit <- Arima(monthly_attacks_ts, order=c(0,1,1), seasonal=c(0,1,1))\n\nautoplot(monthly_attacks_ts) +\n  autolayer(meanf(monthly_attacks_ts, h=36),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(monthly_attacks_ts, h=36),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(monthly_attacks_ts, h=36),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(monthly_attacks_ts, h=36, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n  autolayer(forecast(fit,36), \n            series=\"fit\",PI=FALSE) +\n  guides(colour=guide_legend(title=\"Forecast\"))\n\n\n\ncat(\"Best model metrics: \\n\")\n\nBest model metrics: \n\nsummary(fit)\n\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n\ncat(\"Snaive metrics: \\n\")\n\nSnaive metrics: \n\nf2 <- snaive(monthly_attacks_ts, h=36) \n\naccuracy(f2)\n\n                     ME     RMSE      MAE  MPE MAPE MASE      ACF1\nTraining set -0.6016667 6.093029 3.808333 -Inf  Inf    1 0.4168619\n\n\n\n\nSeasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 1 step ahead forecasts\n\nk <- 75 # minimum data length for fitting a model \nn <- length(monthly_attacks_ts)\n#n-k # rest of the observations\n\nset.seed(133)\n\nfarima1 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(0,1,1),seasonal=c(0,1,1)), h=h)}\ne <- tsCV(monthly_attacks_ts, farima1, h=1)\n\nMAE1 <-abs(mean(e,na.rm=TRUE))\ncat(\"MAE for ARIMA(0,1,1)(0,1,1) is: \", MAE1)\n\nMAE for ARIMA(0,1,1)(0,1,1) is:  2.155092\n\nRMSE1=sqrt(mean(e^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"\\nRMSE for ARIMA(0,1,1)(0,1,1) is: \", RMSE1)\n\n\nRMSE for ARIMA(0,1,1)(0,1,1) is:  7.428068\n\nfarima2 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(1,1,1),seasonal=c(0,1,1)), h=h)}\ne <- tsCV(monthly_attacks_ts, farima2, h=1)\n\nMAE2 <-abs(mean(e,na.rm=TRUE))\ncat(\"\\nMAE for ARIMA(1,1,1)(0,1,1) is: \", MAE2)\n\n\nMAE for ARIMA(1,1,1)(0,1,1) is:  2.092574\n\nRMSE2=sqrt(mean(e^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"\\nRMSE for ARIMA(1,1,1)(0,1,1) is: \", RMSE2)\n\n\nRMSE for ARIMA(1,1,1)(0,1,1) is:  7.410171\n\n\nBoth MAE and RMSE metrics agree that ARIMA(1,1,1)(0,1,1) is the best model by a slight margin. However, the BIC metric does not agree with this result as it outputted ARIMA(0,1,1)(0,1,1) as the model with lowest BIC. AIC and AICc metrics, however, do agree with the MAE and RMSE metrics generated from Seasonal Cross Validation using 1 step ahead forecasts. Let’s see whether this is the case when forecasting 12 steps ahead.\n\n\nSeasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 12 steps (seasonal period) ahead forecasts\n\nk <- 75 # minimum data length for fitting a model \nn <- length(monthly_attacks_ts)\nn-k # rest of the observations\n\n[1] 537\n\nset.seed(133)\n\nfarima1 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(0,1,1),seasonal=c(0,1,1)), h=h)}\n\n# Compute cross-validated errors for up to 12 steps ahead\ne <- tsCV(monthly_attacks_ts, forecastfunction = farima1, h = 12)\n\nmse1 <- colMeans(e^2, na.rm = TRUE)\n\nfarima2 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(1,1,1),seasonal=c(0,1,1)), h=h)}\n# Compute cross-validated errors for up to 12 steps ahead\ne <- tsCV(monthly_attacks_ts, forecastfunction = farima2, h = 12)\n\n# Compute the MSE values and remove missing values\nmse2 <- colMeans(e^2, na.rm = TRUE)\n\n# Plot the MSE values against the forecast horizon\ndata.frame(h = 1:12, MSE1 = mse1, MSE2 = mse2) %>%\n  ggplot() + geom_point(aes(y=MSE1,x= h)) + geom_point(aes(y=MSE2,x= h)) +\n           geom_line(aes(y=MSE1,x= h,colour=\"MSE for ARIMA(0,1,1)(0,1,1)\")) + \n           geom_line(aes(y=MSE2,x= h,colour=\"MSE for ARIMA(1,1,1)(0,1,1)\"))+\n  theme_minimal()\n\n\n\n\nThis plot gives cross-validation statistics up to horizon 12. The procedure for seasonal cross validation using 12 steps ahead is very similar to seasonal cross validation using 1 step ahead. We need to change the “h” parameter to the desired the number of time horizons we want to forecast for. The farima() function manually written by us helps us call our desired SARIMA model with the number of horizons. Then, farima() function is called inside the tsCV() function, which helps us store the cross-validated errors for up to 12 steps ahead. Then, because we get forecasts for each time horizon, we need to take the mean of the squared column using colMeans to obtain MSE.\nAlthough we observed that the MSE and RMSE of ARIMA(1,1,1)(0,1,1) when forecasting 1 step ahead was lower than that of ARIMA(0,1,1)(0,1,1), from the above plot it can be seen that the cross-validated MSEs get lower or better as the number of forecasting steps increases. Both models’ MSE performance follow a very similar pattern, with ARIMA(0,1,1)(0,1,1), picked by lowest BIC, having a lower MSE across all forecasting steps, except for step 1. Therefore, ARIMA(0,1,1)(0,1,1) is the better SARIMA model!"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html",
    "href": "ARIMAX-SARIMAX-VAR.html",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "",
    "text": "In the previous ARIMA/SARIMA modeling section, we analyzed a univariate time series of monthly terrorist attacks in the US that occurred from 1970 to 2020. Although the SARIMA model performed better than the ARIMA model, due to the added seasonal Moving Average term, we can gauge our understanding of the monthly terrorist attacks better by including endogenous variables! Endogenous variables are those that are determined within the system being studied and are influenced by other variables in the system. These variables are typically modeled as being interdependent and are affected by changes in the values of other variables. In the case of terrorist attacks and casualties suffered from them, potential endogenous variables could include USA military expenditure, non-immigrant admissions data, and the performance of major weapons contracts, including Lockheed Martin, Boeing, and Raytheon Technologies. With the help of a literature review, it can be reinforced thoroughly and plausibly that the aforementioned endogenous variables have, in fact, not only been employed but also found to have effects related to terrorism in prior research.\nCode for this section can be found here"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#global-terrorism-database-arima-modeling",
    "href": "ARIMAX-SARIMAX-VAR.html#global-terrorism-database-arima-modeling",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Global Terrorism Database ARIMA Modeling",
    "text": "Global Terrorism Database ARIMA Modeling"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#Lit",
    "href": "ARIMAX-SARIMAX-VAR.html#Lit",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Literature Review",
    "text": "Literature Review\nThe Stimson Study Group’s Report on Counterterrorism Spending (Counterterrorism Spending and Center 2018) in the post-9/11 era provides valuable insights into the amount of resources the United States devotes to counterterrorism efforts. The report found that the US government spent over USD2.8 trillion on counterterrorism efforts from 2002 to 2017, which represents a significant portion of the country’s overall military budget during that period. Specifically, the report notes that counterterrorism spending accounted for 17% to 23% of the US defense budget each year between 2002 and 2017. Hartung (2021) (Hartung 2021) found that the “Global War on Terror”, which emerged in the early 2000s as a result of the 9/11 attacks, had a significant impact on the political environment, resulting in a surge in the Pentagon’s budget, the largest component of the US military budget. This increased funding was largely directed towards military contractors, Lockheed Martin, Boeing, General Dynamics, Raytheon Technologies, and Northrop Grumman, who were enlisted to aid in the efforts. Since Fiscal Year 2001, the total expenditures of the Pentagon for all purposes have surpassed USD14.1 trillion (measured in 2021 dollars). Out of this sum, USD4.4 trillion was used for weapons procurement and research and development (R&D), which mainly benefited corporate contractors. The rest of the funds were utilized for paying and providing benefits to military and civilian personnel and other expenses, necessary for operating and maintaining the United States military. Congressional Research Service (CRS) estimates that in FY2020, the spending for contractors grew to $420 billion - well over half of the total Pentagon budget. Therefore, the biggest financial beneficiaries of the post-9/11 military spending surge have been the aforementioned weapons contractors.\n\nCounterterrorism Spending, Stimson Study Group on, and Henry L. Stimson Center. 2018. Counterterroism Spending: Protecting America While Promoting Efficiencies and Accountability. Stimson. https://books.google.com/books?id=GQRCzgEACAAJ.\n\nHartung, William D. 2021. “Profits of War: Corporate Beneficiaries of the Post-9/11 Pentagon Spending Surge.” Costs of War. Watson Institute for International; Public Affairs, Brown University. https://watson.brown.edu/costsofwar/files/cow/imce/papers/2021/Profits%20of%20War_Hartung_Costs%20of%20War_Sept%2013%2C%202021.pdf.\n\nLi, Quan, and Drew Schaub. 2004. “Economic Globalization and Transnational Terrorism: A Pooled Time-Series Analysis.” The Journal of Conflict Resolution 48 (2): 230–58. http://www.jstor.org/stable/3176252.\n\nGaibulloev, Khusrav, Todd Sandler, and Donggyu Sul. 2014. “Dynamic Panel Analysis Under Cross-Sectional Dependence.” Political Analysis 22 (2): 258–73. https://doi.org/10.1093/pan/mpt029.\nFurthermore, several papers have discussed and analyzed the relation between military spending or counterterrorism efforts with transnational terrorism prior to the 9/11 attacks. Li and Schaub (2004) (Li and Schaub 2004) employed GOVCAPABILITY, a control variable in their Pooled Time-Series Analysis , that comprised military manpower and military expenditures for 112 countries from 1975 to 1997. Because the variable captured state military and economic strength, it represented a proxy that the government could use for combating terrorism. Gaibulloev, K., Sandler, T., & Sul, D. (2014) (Gaibulloev, Sandler, and Sul 2014) challenged extant literature about terrorism and its impact on economic growth that suffered from Nickell Bias, a type of bias that arises in statistical models when the independent variable is measured with error, and cross-sectional dependence, a statistical issue that arises in panel data analysis when the individual units (e.g., countries or firms) in the panel are not completely independent of one another. They mentioned that cross-sectional dependence is apt to affect other variables, such as democracy, threat, military spending, and financial measures. However, when Nickell bias and cross-sectional dependence are addressed, terrorism has no influence whatsoever on economic growth.\nTherefore, the perused literature about counterterrorism and military spending underscores the importance of counterterrorism efforts, including funding weapons contractors, in shaping the country’s military spending priorities, particularly in the wake of the 9/11 terrorist attacks. By highlighting the amount of resources devoted to counterterrorism, these reports and papers help us understand how the overall US budget and military budget are allocated and the policy decisions that drive those allocations. However, it might also possible that during the VAR model building phase of this section, we find that military spending may not be a significant indicator of the number of casualties stemming from terrorist attacks in the Global Terrorism Database™ (GTD) (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.).\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\n\nNowrasteh, Alex. 2019. “Terrorists by Immigration Status and Nationality: A Risk Analysis, 1975–2017.” Cato.org. Cato Institute. https://www.cato.org/publications/policy-analysis/terrorists-immigration-status-nationality-risk-analysis-1975-2017#foreign-born-terrorism-risk-for-visas-issued-by-category.\nSecondly, Nowrasteh (2019) (Nowrasteh 2019) found, by carefully analyzing the GTD, that the chance of being murdered by a tourist on a B visa, the most common tourist visa, is about 1 in 4.1 million per year. Compared to foreign‐born terrorists, the chance of being murdered by a native‐born terrorist is about 1 in 28 million per year. Moreover, there were 192 foreign‐born terrorists, relative to the 788 native-born terrorists, who planned, attempted, or carried out attacks on U.S. soil from 1975 through 2017. Through a cost-benefit risk analysis, it was also found that the combined human, property, business, and economic costs of terrorism from 1975 through 2017 are estimated at USD216.58 billion. Spread over 43 years, the average annual cost of terrorism is USD5.04 billion, which is about one‐hundredth the minimum estimated yearly benefit of USD553.9 billion from immigration and tourism. Therefore, foreign‐born terrorism on U.S. soil is a low‐probability event that imposes high costs on its victims, despite relatively small risks."
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#var-model-justification",
    "href": "ARIMAX-SARIMAX-VAR.html#var-model-justification",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "VAR Model Justification",
    "text": "VAR Model Justification\nUsing a VAR model over an ARIMAX model for this research has a multitude of benefits, including:\n\nSimultaneous modeling of multivariate time series: VAR allows for the simultaneous modeling of multiple endogenous variables, whereas ARIMAX (Autoregressive Integrated Moving Average with Explanatory Variables) can only model one dependent variable at a time. This means that VAR can capture the complex relationships between multiple variables that may be influencing each other.\nBetter handling of lags: VAR can handle multiple lags in the data more efficiently than ARIMAX. This is important in the case of studying the impact of terrorist attacks, as the effects of a single attack may persist over a longer period of time and may have delayed impacts on different variables.\nMore robust to missing data: VAR can handle missing data more effectively than ARIMAX, as it does not require the same level of complete data in order to estimate the model parameters. This is particularly relevant in the case of studying the impact of terrorist attacks, as data may be missing or incomplete for certain variables in certain time periods.\nBetter captures dynamic relationships: VAR is better suited for capturing the dynamic relationships between variables over time, whereas ARIMAX can only capture the static relationships between variables at a particular point in time. This is important in the case of studying the impact of terrorist attacks, as the relationships between variables may change over time due to factors such as changes in government policies or public opinion.\nNo clear seasonality: Another reason why the VAR model is justified is that there may not be a clear seasonality pattern in the data related to terrorist attacks. This means that traditional time-series models may not be effective in capturing the complex relationships between the variables. The VAR model, on the other hand, does not rely on a specific seasonal pattern and can account for the complex relationships between variables without requiring seasonal adjustments. Moreover, the data that will be analyzed is aggregated yearly from 1970 to 2020, which makes it more difficult to identify and capture seasonal patterns. Yearly data may also be influenced by other factors that are not related to seasonality, such as long-term trends or cyclical patterns, that occur over longer periods of time. This can make it more challenging to distinguish between seasonal effects and other underlying factors that may be driving the data.\nNon-linearity: The relationships between variables in the case of terrorist attacks may not be linear, and traditional linear models may not be able to capture the non-linear effects. The VAR model is capable of modeling non-linear relationships between variables and can account for the complex interactions that may exist between them."
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#building-the-var-model",
    "href": "ARIMAX-SARIMAX-VAR.html#building-the-var-model",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Building the VAR Model",
    "text": "Building the VAR Model\n\nTime Series Plots\n\n\nCode\nplot.ts(var_ts , main = \"\", xlab = \"\")\n\n\n\n\n\n\n\nPairs Plot\n\n\nCode\n# create scatterplot matrix using plotly\nfig <- plot_ly(\n  data = gtd_dhs_sipri_rtx, \n  type = \"splom\",\n  diagonal = list(visible = FALSE),\n  dimensions = list(\n    list(label = \"# Casualties\", values = ~num_fatal),\n    list(label = \"# Attacks\", values = ~num_attacks),\n    list(label = \"Tourists DHS\", values = ~Pleasure),\n    list(label = \"Business DHS\", values = ~Business),\n    list(label = \"Students DHS\", values = ~Students),\n    list(label = \"RTX\", values = ~RTX)\n  )\n) %>%\n  layout(hovermode = \"x\")\n\n\n\n# customize layout\nfig <- fig %>% \n  layout(\n    title = \"Scatterplot Matrix of VAR Model Variables\",\n    xaxis = list(title = \"\"),\n    yaxis = list(title = \"\")\n  )\n\n# display plot\nfig\n\n\n\n\n\n\n\n\nCode\ngtd_dhs_sipri_rtx <- subset(gtd_dhs_sipri_rtx, select=-c(Business, Pleasure, Students, RTX, num_attacks))\n\n# convert df back to matrix\n\nts_matrix <- as.matrix(gtd_dhs_sipri_rtx[, 2:3])\n\n# convert the matrix to a time series object with a yearly frequency\nvar_ts <- ts(ts_matrix, frequency = 1,\n                 start = 1970)\n\n# split into train and test sets\n\nset.seed(29830)\ntrain_idx <- sample(nrow(var_ts), 0.9 * nrow(var_ts))\ntrain <- var_ts[train_idx, ]\ntest <- var_ts[-train_idx, ]\n\n# Fit Lasso regression model with cross-validation\n# cv_fit <- cv.glmnet(train[, 2], train[, 1], alpha = 1)\n# \n# # Extract selected variables\n# cv_fits <- as.data.frame(as.matrix(coef(cv_fit)))\n# to_include <- rownames(cv_fits)[cv_fits$s1 != 0]\n\n\n\n\nFitting VAR Model\nHere we use the VARselect() function to find the best p to fit VAR(p). We will choose a maximum lag of 10 and check which p value returns lowest AIC.\n\n\nCode\n(var_result <- VARselect(var_ts, lag.max = 10, type = \"both\"))\n\n\n$selection\nAIC(n)  HQ(n)  SC(n) FPE(n) \n     2      1      1      2 \n\n$criteria\n              1        2        3        4        5        6        7        8\nAIC(n) 1.091791 1.045844 1.204512 1.335694 1.440519 1.577721 1.728764 1.829026\nHQ(n)  1.213545 1.228475 1.448020 1.640078 1.805780 2.003859 2.215779 2.376919\nSC(n)  1.426146 1.547377 1.873223 2.171582 2.443585 2.747965 3.066186 3.333626\nFPE(n) 2.983318 2.857871 3.369113 3.879711 4.374444 5.128738 6.148074 7.078170\n              9       10\nAIC(n) 1.974601 1.548992\nHQ(n)  2.583371 2.218638\nSC(n)  3.646379 3.387947\nFPE(n) 8.637254 6.049901\n\n\nNow, we will fit VAR(1), VAR(2), and VAR(3):\nVAR(1) output:\n\n\nCode\nsummary(fit <- VAR(var_ts, p=1, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_fatal, milexp.gdp \nDeterministic variables: both \nSample size: 50 \nLog Likelihood: -156.054 \nRoots of the characteristic polynomial:\n0.8623 0.08703\nCall:\nVAR(y = var_ts, p = 1, type = \"both\")\n\n\nEstimation results for equation num_fatal: \n========================================== \nnum_fatal = num_fatal.l1 + milexp.gdp.l1 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)  \nnum_fatal.l1  -9.631e-02  1.465e-01  -0.657   0.5143  \nmilexp.gdp.l1 -1.401e+04  7.687e+03  -1.823   0.0749 .\nconst          9.409e+02  5.176e+02   1.818   0.0756 .\ntrend         -6.862e+00  6.433e+00  -1.067   0.2916  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 422.1 on 46 degrees of freedom\nMultiple R-Squared: 0.07287,    Adjusted R-squared: 0.01241 \nF-statistic: 1.205 on 3 and 46 DF,  p-value: 0.3185 \n\n\nEstimation results for equation milexp.gdp: \n=========================================== \nmilexp.gdp = num_fatal.l1 + milexp.gdp.l1 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)    \nnum_fatal.l1   6.347e-07  1.189e-06   0.534    0.596    \nmilexp.gdp.l1  8.716e-01  6.238e-02  13.971   <2e-16 ***\nconst          6.091e-03  4.200e-03   1.450    0.154    \ntrend         -3.141e-05  5.221e-05  -0.602    0.550    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.003425 on 46 degrees of freedom\nMultiple R-Squared: 0.9185, Adjusted R-squared: 0.9132 \nF-statistic: 172.9 on 3 and 46 DF,  p-value: < 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n            num_fatal milexp.gdp\nnum_fatal   1.781e+05 -9.236e-02\nmilexp.gdp -9.236e-02  1.173e-05\n\nCorrelation matrix of residuals:\n           num_fatal milexp.gdp\nnum_fatal    1.00000   -0.06388\nmilexp.gdp  -0.06388    1.00000\n\n\nVAR(2) output:\n\n\nCode\nsummary(fit <- VAR(var_ts, p=2, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_fatal, milexp.gdp \nDeterministic variables: both \nSample size: 49 \nLog Likelihood: -145.735 \nRoots of the characteristic polynomial:\n0.7139 0.5935 0.3244 0.3244\nCall:\nVAR(y = var_ts, p = 2, type = \"both\")\n\n\nEstimation results for equation num_fatal: \n========================================== \nnum_fatal = num_fatal.l1 + milexp.gdp.l1 + num_fatal.l2 + milexp.gdp.l2 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)  \nnum_fatal.l1     -0.1154     0.1512  -0.763   0.4495  \nmilexp.gdp.l1 -7542.4239 18769.9771  -0.402   0.6898  \nnum_fatal.l2     -0.1020     0.1511  -0.675   0.5031  \nmilexp.gdp.l2 -9590.1881 18131.7059  -0.529   0.5996  \nconst          1143.1762   569.6714   2.007   0.0511 .\ntrend            -8.3498     6.8180  -1.225   0.2274  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 431.8 on 43 degrees of freedom\nMultiple R-Squared: 0.09241,    Adjusted R-squared: -0.01312 \nF-statistic: 0.8757 on 5 and 43 DF,  p-value: 0.5054 \n\n\nEstimation results for equation milexp.gdp: \n=========================================== \nmilexp.gdp = num_fatal.l1 + milexp.gdp.l1 + num_fatal.l2 + milexp.gdp.l2 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)    \nnum_fatal.l1   7.472e-07  1.061e-06   0.704  0.48517    \nmilexp.gdp.l1  1.274e+00  1.317e-01   9.673 2.35e-12 ***\nnum_fatal.l2   6.724e-07  1.060e-06   0.634  0.52932    \nmilexp.gdp.l2 -3.739e-01  1.272e-01  -2.938  0.00529 ** \nconst          5.674e-03  3.998e-03   1.419  0.16305    \ntrend         -5.050e-05  4.785e-05  -1.055  0.29711    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.00303 on 43 degrees of freedom\nMultiple R-Squared: 0.9355, Adjusted R-squared: 0.928 \nF-statistic: 124.7 on 5 and 43 DF,  p-value: < 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n            num_fatal milexp.gdp\nnum_fatal   1.865e+05 -8.394e-02\nmilexp.gdp -8.394e-02  9.183e-06\n\nCorrelation matrix of residuals:\n           num_fatal milexp.gdp\nnum_fatal    1.00000   -0.06415\nmilexp.gdp  -0.06415    1.00000\n\n\nVAR(3) output:\n\n\nCode\nsummary(fit <- VAR(var_ts, p=3, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_fatal, milexp.gdp \nDeterministic variables: both \nSample size: 48 \nLog Likelihood: -142.005 \nRoots of the characteristic polynomial:\n0.7981 0.7981 0.4925 0.4925 0.4315 0.3136\nCall:\nVAR(y = var_ts, p = 3, type = \"both\")\n\n\nEstimation results for equation num_fatal: \n========================================== \nnum_fatal = num_fatal.l1 + milexp.gdp.l1 + num_fatal.l2 + milexp.gdp.l2 + num_fatal.l3 + milexp.gdp.l3 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)  \nnum_fatal.l1  -1.331e-01  1.571e-01  -0.848   0.4017  \nmilexp.gdp.l1 -3.862e+03  2.260e+04  -0.171   0.8652  \nnum_fatal.l2  -1.239e-01  1.573e-01  -0.787   0.4357  \nmilexp.gdp.l2 -1.181e+04  3.451e+04  -0.342   0.7341  \nnum_fatal.l3  -1.095e-01  1.569e-01  -0.698   0.4892  \nmilexp.gdp.l3 -4.098e+03  2.051e+04  -0.200   0.8427  \nconst          1.310e+03  6.349e+02   2.064   0.0456 *\ntrend         -9.324e+00  7.342e+00  -1.270   0.2114  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 443.6 on 40 degrees of freedom\nMultiple R-Squared: 0.1086, Adjusted R-squared: -0.04738 \nF-statistic: 0.6963 on 7 and 40 DF,  p-value: 0.6747 \n\n\nEstimation results for equation milexp.gdp: \n=========================================== \nmilexp.gdp = num_fatal.l1 + milexp.gdp.l1 + num_fatal.l2 + milexp.gdp.l2 + num_fatal.l3 + milexp.gdp.l3 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)    \nnum_fatal.l1   5.676e-07  1.084e-06   0.524   0.6034    \nmilexp.gdp.l1  1.205e+00  1.559e-01   7.725 1.87e-09 ***\nnum_fatal.l2   5.849e-07  1.086e-06   0.539   0.5931    \nmilexp.gdp.l2 -1.376e-01  2.382e-01  -0.578   0.5668    \nnum_fatal.l3  -1.487e-07  1.083e-06  -0.137   0.8915    \nmilexp.gdp.l3 -1.966e-01  1.416e-01  -1.388   0.1727    \nconst          7.824e-03  4.381e-03   1.786   0.0817 .  \ntrend         -7.158e-05  5.067e-05  -1.413   0.1654    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.003061 on 40 degrees of freedom\nMultiple R-Squared: 0.9351, Adjusted R-squared: 0.9237 \nF-statistic: 82.28 on 7 and 40 DF,  p-value: < 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n            num_fatal milexp.gdp\nnum_fatal   1.968e+05 -1.064e-01\nmilexp.gdp -1.064e-01  9.371e-06\n\nCorrelation matrix of residuals:\n           num_fatal milexp.gdp\nnum_fatal    1.00000   -0.07837\nmilexp.gdp  -0.07837    1.00000\n\n\n\n\nK-Fold Cross Validation and Model Diagnostics\n\n\nCode\n# Define the number of folds for cross-validation\nk <- 5\n\n# Define the p values to test\np_values <- c(1, 2, 3)\n\n# Split the data into k folds\ncv_folds <- cut(seq(1, nrow(var_ts)), breaks = k, labels = FALSE)\n\n# Initialize vectors to store RMSE and AIC values for each p value\nrmse_vec <- numeric(length(p_values))\naic_vec <- numeric(length(p_values))\n\n# Loop over p values and perform cross-validation\nfor (i in seq_along(p_values)) {\n  p <- p_values[i]\n  rmse_cv <- numeric(k)\n  aic_cv <- numeric(k)\n  for (j in 1:k) {\n    # Split the data into training and testing sets\n    train <- var_ts[cv_folds != j, ]\n    test <- var_ts[cv_folds == j, ]\n    \n    # Fit the VAR model with the current p value\n    var_fit <- VAR(train, p = p)\n    \n    # Make predictions for the testing set\n    pred <- predict(var_fit, n.ahead = nrow(test))$fcst\n    \n    # Calculate RMSE and AIC for the current fold\n    rmse_cv[j] <- sqrt(mean((pred$num_fatal - test[,1])^2))\n    aic_cv[j] <- AIC(var_fit)\n  }\n  # Calculate the mean RMSE and AIC across all folds for the current p value\n  rmse_vec[i] <- mean(rmse_cv)\n  aic_vec[i] <- mean(aic_cv)\n}\n\n# Create a table of RMSE and AIC values for each p value\nresults_table <- tibble(p_values, rmse_vec, aic_vec)\n\n# Print the results table\nkable(results_table, format = \"markdown\", \n        col.names = c(\"P Values\", \"RMSE\", \"AIC\"), align = \"c\", digits = 2\n        )\n\n\n\n\n\nP Values\nRMSE\nAIC\n\n\n\n\n1\n842.84\n226.09\n\n\n2\n869.69\n216.43\n\n\n3\n900.83\n216.98\n\n\n\n\n\nLowest Test RMSE is given by p=1; however, it also has highest AIC score on the train set. Because test set performance is best and it is the simplest model, we shall choose this.\n\n\nForecasting Chosen Model (p=1)\n\n\nCode\nfinal_var <- VAR(var_ts, p = 1)\n\n(fit.pr = predict(final_var, n.ahead = 5, ci = 0.95)) # 4 weeks ahead \n\n\n$num_fatal\n         fcst     lower    upper       CI\n[1,] 167.6021 -660.8578 996.0621 828.4600\n[2,] 154.4513 -677.8052 986.7077 832.2565\n[3,] 153.3720 -679.9722 986.7162 833.3442\n[4,] 151.6575 -682.5675 985.8825 834.2250\n[5,] 150.1764 -684.7512 985.1041 834.9277\n\n$milexp.gdp\n           fcst      lower      upper          CI\n[1,] 0.03735113 0.03068326 0.04401900 0.006667872\n[2,] 0.03761949 0.02864728 0.04659170 0.008972207\n[3,] 0.03785150 0.02739770 0.04830531 0.010453805\n[4,] 0.03805958 0.02655696 0.04956221 0.011502626\n[5,] 0.03824566 0.02596832 0.05052299 0.012277336\n\n\nCode\nfanchart(fit.pr) # plot prediction + error"
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#references",
    "href": "ARMA-ARIMA-SARIMA.html#references",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "References",
    "text": "References\n“Codebook Methodology Inclusion Criteria and Ariables - UMD.” Codebook Methodology Inclusion criteria and variables - UMD. University of Maryland. Accessed February 1, 2023. https://www.start.umd.edu/gtd/downloads/Codebook.pdf."
  },
  {
    "objectID": "Financial-Models.html",
    "href": "Financial-Models.html",
    "title": "Financial Time Series Models",
    "section": "",
    "text": "In the previous parts of this study, the focus was on utilizing models that capture the conditional mean structure of time series data. However, for financial time series, the conditional variance structure can be modeled using ARCH and GARCH models. Typically, periods of high volatility, a statistical measure of the dispersion of returns, for a given security or market index are followed by higher conditional variance compared to stable periods. This is known as volatility clustering. ARCH/GARCH models are designed to capture the time-varying variance of returns or to predict the conditional variance of a time series, which help us forecast the volatility of future returns.\nAutoregressive Conditional Heteroscedasticity (ARCH) refers to a model that applies an autoregressive component to the variance of a univariate time series. Although an ARCH model could possibly be used to describe a gradually increasing variance over time, most often it is used in situations in which there may be short periods of increased variation. Specifically, the ARCH(p) model models the returns as:\n\\(r_t = log(x_t) − log(x_{t−1})\\)\n\\(r_t = \\sigma_t \\epsilon_t\\)\n\\(\\sigma^2_t = Var(r_t|r_{t-1}) = a_0 + a_1r_{t-1}^2 + ... + a_pr_{t-p}^2\\), where \\(\\epsilon_t\\) is standard Gaussian white noise.\nGeneralized Autoregressive Conditional Heteroskedasticity (GARCH) is an extension of the ARCH model that incorporates a moving average component together with the autoregressive component. The introduction of a moving average component allows the model to both model the conditional change in variance over time as well as changes in the time-dependent variance. Just like ARCH(p) is AR(p) applied to the variance of a time series, GARCH(p, q) is an ARMA(p,q) model applied to the variance of a time series. Specifically, the GARCH(p,q) model models the returns as:\n\\(r_t = \\sigma_t \\epsilon_t\\)\n\\(\\begin{equation}\\sigma_t^2 = a_0 + \\sum_{j=1}^{p} \\alpha_j r_{t-j}^2 + \\sum_{j=1}^{q} \\beta_j \\sigma_{t-j}^2\\end{equation}\\), where \\(\\epsilon_t\\) is standard Gaussian white noise, \\(\\alpha_j\\) and \\(\\beta_j\\) are the coefficients for the lagged squared residuals and lagged conditional variances, respectively. The model is called a GARCH(p,q) model if it includes \\(p\\) lags of the squared residuals and \\(q\\) lags of the conditional variances.\nIn financial time series analysis, it is common practice to fit an ARMA model to the data to capture the conditional mean structure, followed by the application of an ARCH or GARCH model to model the conditional variance. The upcoming section will apply this approach to model 3 financial time series, including Lockheed Martin, Raytheon Technologies, and Dow Jones U.S. Travel & Tourism Index, using a combination of ARMA and GARCH models.\nCode for this section can be found here"
  },
  {
    "objectID": "Financial-Models.html#visualizing-financial-time-series",
    "href": "Financial-Models.html#visualizing-financial-time-series",
    "title": "Financial Time Series Models",
    "section": "Visualizing Financial Time Series",
    "text": "Visualizing Financial Time Series\n\n\n\n\n\n\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones U.S. Travel & Tourism Index (DJUSTT)\n\n\n\n\nCode\nlmt$SMA_50 <- as.numeric(SMA(Cl(lmt),n=50))\nlmt$SMA_200 <- as.numeric(SMA(Cl(lmt),n=200))\n\nfig <- lmt %>% plot_ly(x = ~Date, type=\"candlestick\",\n          open = ~LMT.Open, close = ~LMT.Close,\n          high = ~LMT.High, low = ~LMT.Low, name = \"Candlestick\") %>% \n  add_trace(type = 'scatter', mode = 'lines', y=~SMA_50, \n            name=\"SMA_50\", line = list(color = 'blue')) %>% \n  add_trace(type = 'scatter', mode = 'lines', y=~SMA_200, \n            name=\"SMA_200\",line = list(color = 'orange')) \nfig <- fig %>%\n  layout(title = \"LMT Candlestick Chart with 50 And 200 Day Simple Moving-Average\") %>% \n  layout(hovermode = \"x\") %>%\n  layout(paper_bgcolor = \"black\",\n         plot_bgcolor = \"black\",\n         font = list(color = \"white\"),\n         yaxis = list(linecolor = \"#6b6b6b\",\n                      zerolinecolor = \"#6b6b6b\",\n                      gridcolor= \"#444444\"),\n         xaxis = list(linecolor = \"#6b6b6b\",\n                      zerolinecolor = \"#6b6b6b\",\n                      gridcolor= \"#444444\"))\n\nfig\n\n\n\n\n\n\n\n\n\n\nCode\nrtx$SMA_50 <- as.numeric(SMA(Cl(rtx),n=50))\nrtx$SMA_200 <- as.numeric(SMA(Cl(rtx),n=200))\n\nfig <- rtx %>% plot_ly(x = ~Date, type=\"candlestick\",\n          open = ~RTX.Open, close = ~RTX.Close,\n          high = ~RTX.High, low = ~RTX.Low, name = \"Candlestick\") %>% \n  add_trace(type = 'scatter', mode = 'lines', y=~SMA_50, \n            name=\"SMA_50\", line = list(color = 'blue')) %>% \n  add_trace(type = 'scatter', mode = 'lines', y=~SMA_200, \n            name=\"SMA_200\",line = list(color = 'orange')) \nfig <- fig %>%\n  layout(title = \"RTX Candlestick Chart with 50 And 200 Day Simple Moving-Average\") %>% \n  layout(hovermode = \"x\") %>%\n  layout(paper_bgcolor = \"black\",\n         plot_bgcolor = \"black\",\n         font = list(color = \"white\"),\n         yaxis = list(linecolor = \"#6b6b6b\",\n                      zerolinecolor = \"#6b6b6b\",\n                      gridcolor= \"#444444\"),\n         xaxis = list(linecolor = \"#6b6b6b\",\n                      zerolinecolor = \"#6b6b6b\",\n                      gridcolor= \"#444444\"))\n\nfig\n\n\n\n\n\n\n\n\n\n\nCode\ndow$SMA_50 <- as.numeric(SMA(Cl(dow),n=50))\ndow$SMA_200 <- as.numeric(SMA(Cl(dow),n=200))\n\nfig <- dow %>% plot_ly(x = ~Date, type=\"candlestick\",\n          open = ~DJUSTT.Open, close = ~DJUSTT.Close,\n          high = ~DJUSTT.High, low = ~DJUSTT.Low, name = \"Candlestick\") %>% \n  add_trace(type = 'scatter', mode = 'lines', y=~SMA_50, \n            name=\"SMA_50\", line = list(color = 'blue')) %>% \n  add_trace(type = 'scatter', mode = 'lines', y=~SMA_200, \n            name=\"SMA_200\",line = list(color = 'orange')) \nfig <- fig %>%\n  layout(title = \"DJUSTT Candlestick Chart with 50 And 200 Day Simple Moving-Average\") %>% \n  layout(hovermode = \"x\") %>%\n  layout(paper_bgcolor = \"black\",\n         plot_bgcolor = \"black\",\n         font = list(color = \"white\"),\n         yaxis = list(linecolor = \"#6b6b6b\",\n                      zerolinecolor = \"#6b6b6b\",\n                      gridcolor= \"#444444\"),\n         xaxis = list(linecolor = \"#6b6b6b\",\n                      zerolinecolor = \"#6b6b6b\",\n                      gridcolor= \"#444444\"))\n\nfig"
  },
  {
    "objectID": "Financial-Models.html#visualizing-returns-of-financial-time-series",
    "href": "Financial-Models.html#visualizing-returns-of-financial-time-series",
    "title": "Financial Time Series Models",
    "section": "Visualizing Returns of Financial Time Series",
    "text": "Visualizing Returns of Financial Time Series\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones U.S. Travel & Tourism Index (DJUSTT)\n\n\n\n\nCode\ngetSymbols(\"LMT\", from = \"1995-03-17\",\n            to = \"2023-01-30\", src=\"yahoo\")\n\n\n[1] \"LMT\"\n\n\nCode\nlmt.close<- Ad(LMT)\nreturns_LMT = diff(log(lmt.close))\nchartSeries(returns_LMT)\n\n\n\n\n\n\n\n\n\nCode\ngetSymbols(\"RTX\", from = \"1983-03-04\",\n           to = \"2023-01-30\", src=\"yahoo\")\n\n\n[1] \"RTX\"\n\n\nCode\nrtx.close<- Ad(RTX)\nreturns_RTX = diff(log(rtx.close))\nchartSeries(returns_RTX)\n\n\n\n\n\n\n\n\n\nCode\ngetSymbols(\"^DJUSTT\", from = \"2008-12-01\",\n           to = \"2023-01-30\", src=\"yahoo\")\n\n\n[1] \"^DJUSTT\"\n\n\nCode\ndjustt.close<- Ad(DJUSTT)\nreturns_DJUSTT = diff(log(djustt.close))\nchartSeries(returns_DJUSTT)\n\n\n\n\n\n\n\n\nLockheed Martin (LMT): The candlestick chart for LMT shows a predominantly bullish trend, with a series of higher highs and higher lows over the course of the time period. There are a few instances of short-term bearish reversals, but overall the stock appears to be in an upward trend. The shadows of the candlesticks are generally small, indicating relatively little price volatility, but there are a few instances of longer shadows, which may be a sign of increased uncertainty or volatility.\nLMT’s returns does support the findings from the candlestick chart. We see evidence of volatility clustering during three distinct periods: around 1998-2000, the beginning of 2009-2010, and the beginning of 2020 to the end of 2021. This clustering of volatility is consistent with the findings of many financial studies, and can have important implications for trading strategies and risk management. One approach to modeling volatility clustering is to use ARCH/GARCH models, which are specifically designed to capture the time-varying volatility of financial time series data.\nIn the case of LMT, we can use the candlestick chart to gain additional insights into these periods of volatility clustering. For example, during the period from 1998-2000, we can see that there are several long shadows and a few bearish engulfing patterns, which may have contributed to the increased volatility during that time period. Similarly, during the beginning of 2009-2010 and the beginning of 2020 to the end of 2021, we can see that the candlestick chart shows increased uncertainty and volatility, with larger and more frequent bullish and bearish candlesticks.\nBy using ARCH/GARCH models to model the time-varying volatility of LMT returns, we can gain a more accurate understanding of the underlying dynamics of the stock’s behavior, and potentially identify trading opportunities or develop more effective risk management strategies.\nRaytheon Technologies (RTX): The candlestick chart for RTX shows a more mixed trend, with periods of both bullish and bearish behavior over the time period. There are several instances of long shadows, indicating significant price volatility, particularly in the early part of the time period. The candlesticks also show several instances of short-term reversals, with a few examples of bearish engulfing patterns, which may be a cause for concern for investors. Although RTX also shows evidence of volatility clustering during three distinct periods - January 1998, December 2000, and January 2019 - it is far less volatile compared to LMT. The candlestick chart for RTX reveals that during these periods, there were some large bullish and bearish candlesticks but not as frequent or as large as in the case of LMT.\nThe low volatility of RTX may suggest that it could be a more stable investment option compared to LMT, but it is important to note that low volatility can also lead to lower returns. Additionally, the volatility clustering observed in RTX may still pose a risk for investors who are not adequately prepared to manage the potential impact of unexpected market events.\nThe use of ARCH/GARCH models may help us understand the underlying dynamics of RTX’s returns, despite its low volatility. By modeling the time-varying volatility of RTX returns, we can potentially identify periods of heightened risk and better manage our investment strategy accordingly.\nThe candlestick chart can also provide additional insights into these periods of volatility clustering. For instance, during Jan 1998 and December 2000, we can see that there were several long shadows and a few bearish engulfing patterns, indicating a shift in sentiment towards selling. Similarly, in January 2019, we can see some long bullish candlesticks, which suggest a bullish sentiment among investors. These patterns can be useful for developing trading strategies and for understanding market sentiment.\nDow Jones Travel and Tourism Index (DJUSTT): The candlestick chart for the DJTTRX shows a predominantly bullish trend, with a steady increase in price over the course of the time period. There are a few instances of short-term bearish reversals, but overall the trend is upward. The shadows of the candlesticks are generally small, indicating relatively little price volatility, but there are a few instances of longer shadows, which may be a sign of increased uncertainty or volatility. It’s also worth noting that the trend appears to be accelerating in the latter part of the time period, with more frequent and larger bullish candlesticks.\nThe candlestick analysis of DJUSTT reveals a consistent pattern of volatility clustering, which is also evident in its returns. The ARCH/GARCH models can be used to capture the clustering of volatility in DJUSTT’s returns. The clusters of high volatility are reflected in the candlestick chart as long candlesticks, indicating large price movements. The GARCH model can help identify periods of high volatility and provide insight into the potential future volatility of DJUSTT. The presence of volatility clustering in DJUSTT’s returns suggests that market participants may be reacting to significant news or events, leading to heightened uncertainty and increased volatility. The ARCH/GARCH models can be useful tools for understanding the sources and potential impacts of such market developments, helping investors and analysts to make more informed decisions."
  },
  {
    "objectID": "Financial-Models.html#acf-and-pacf-of-returns",
    "href": "Financial-Models.html#acf-and-pacf-of-returns",
    "title": "Financial Time Series Models",
    "section": "ACF and PACF of Returns",
    "text": "ACF and PACF of Returns\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones Travel and Tourism Index (DJUSTT)\n\n\n\n\nCode\nreturns_LMT %>% ggtsdisplay() \n\n\n\n\n\nBoth ACF and PACF plots of LMT’s returns (raw) since its incorporation show high correlation, which means the series is not stationary. This may also suggest that there is strong persistence or momentum in the returns. Such patterns can be captured by ARMA models and can help to inform the selection of appropriate lag lengths for ARCH/GARCH models.\n\n\n\n\nCode\nreturns_RTX %>% ggtsdisplay() \n\n\n\n\n\nLike LMT’s returns, RTX’s ACF and PACF plots show high correlation, which means the series is not stationary. An AR or ARMA model might be required to fit the series before fitting the ARCH/GARCH model.\n\n\n\n\nCode\nreturns_DJUSTT %>% ggtsdisplay() \n\n\n\n\n\n\n\n\nThe ACF and PACF plots of DJUSTT returns suggest that there may be some autocorrelation present in the data. Specifically, lags 1 to 5 do not appear to be significantly correlated, but there is significant autocorrelation from lag 6 onwards. This pattern of autocorrelation may be indicative of a GARCH effect, where the volatility of the series is changing over time. The presence of significant autocorrelation at higher lags may suggest that the returns exhibit a degree of persistence or momentum, where positive (or negative) returns tend to be followed by further positive (or negative) returns. Such patterns can be captured by ARMA models and can help to inform the selection of appropriate lag lengths for ARCH/GARCH models."
  },
  {
    "objectID": "Financial-Models.html#acf-and-pacf-of-squared-returns",
    "href": "Financial-Models.html#acf-and-pacf-of-squared-returns",
    "title": "Financial Time Series Models",
    "section": "ACF and PACF of Squared Returns",
    "text": "ACF and PACF of Squared Returns\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones Travel and Tourism Index (DJUSTT)\n\n\n\n\nCode\nreturns_LMT^2 %>% ggtsdisplay() \n\n\n\n\n\n\n\n\n\nCode\nreturns_RTX^2 %>% ggtsdisplay() \n\n\n\n\n\n\n\n\n\nCode\nreturns_DJUSTT^2 %>% ggtsdisplay()"
  },
  {
    "objectID": "Financial-Models.html#acf-and-pacf-of-absolute-returns",
    "href": "Financial-Models.html#acf-and-pacf-of-absolute-returns",
    "title": "Financial Time Series Models",
    "section": "ACF and PACF of Absolute Returns",
    "text": "ACF and PACF of Absolute Returns\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones Travel and Tourism Index (DJUSTT)\n\n\n\n\nCode\nabs(returns_LMT) %>% ggtsdisplay() \n\n\n\n\n\n\n\n\n\nCode\nabs(returns_RTX) %>% ggtsdisplay() \n\n\n\n\n\n\n\n\n\nCode\nabs(returns_DJUSTT) %>% ggtsdisplay() \n\n\n\n\n\n\n\n\nAfter transforming the returns, clear correlation is discerned in both ACF and PACF plots for all three financial series when we examine their absolute and squared returns. It is likely that there is some non-linear dependence present in the data, which could be attributed to volatility clustering, signifying periods of high volatility tend to be followed by periods of high volatility, and periods of low volatility tend to be followed by periods of low volatility. This pattern can be captured by ARCH/GARCH models, which allow for the conditional variance of the series to depend on past squared returns. The decreasing significance of the ACF and PACF at higher lags may indicate that the effects of past volatility on current volatility decay over time, which can be modeled by including lagged terms of the conditional variance in the ARCH/GARCH models. Overall, the ACF and PACF plots of squared returns can provide useful information about the structure of the data and can guide the development of appropriate time series models for capturing the volatility clustering.\nTherefore, just fitting an ARCH model to each series is not enough! An ARCH model, which is designed to capture volatility clustering or autocorrelation in the squared returns, could be a good starting point. However, an ARCH model only models the conditional variance of the data and assumes that the conditional mean is constant over time. Since there is also autocorrelation in the returns themselves, then an ARMA or ARIMA model may be necessary to model the conditional mean. Therefore, we should fit an ARMA or ARIMA model first to the stocks and then fit an ARCH to the residuals of the ARMA or ARIMA model."
  },
  {
    "objectID": "Financial-Models.html#fitting-arima-model",
    "href": "Financial-Models.html#fitting-arima-model",
    "title": "Financial Time Series Models",
    "section": "Fitting ARIMA Model",
    "text": "Fitting ARIMA Model\n\nACF and PACF of Lockheed Martin (LMT) Stock’s Transformations (Log, Difference, Differenced Log)\n\nLog TransformationDifferenced TransformationDifferenced Log Transformation\n\n\n\n\nCode\nlog.lmt=log(lmt.close)\n\nlog.lmt %>% ggtsdisplay()\n\n\n\n\n\n\n\n\n\nCode\ndiff.lmt=diff(lmt.close)\n\ndiff.lmt %>% ggtsdisplay()\n\n\n\n\n\n\n\n\n\nCode\nlogdiff.lmt=diff(log(lmt.close))\n\nlogdiff.lmt %>% ggtsdisplay()\n\n\n\n\n\n\n\n\nOnly when LMT is transformed by both differencing and taking the log of its stock price, we obtain a weakly stationary series, not otherwise. The model for “differenced log LMT” series is a white noise, and the “original model” resembles random walk model ARIMA(0,1,0). Therefore, we shall fit an ARIMA(p,1,d) model to its log price.\n\n\nACF and PACF of Raytheon Technologies (RTX) Stock’s Transformations (Log, Difference, Differenced Log)\n\nLog TransformationDifferenced TransformationDifferenced Log Transformation\n\n\n\n\nCode\nlog.rtx=log(rtx.close)\n\nlog.rtx %>% ggtsdisplay()\n\n\n\n\n\n\n\n\n\nCode\ndiff.rtx=diff(rtx.close)\n\ndiff.rtx %>% ggtsdisplay()\n\n\n\n\n\n\n\n\n\nCode\ndifflog.rtx=diff(log(rtx.close))\n\ndifflog.rtx %>% ggtsdisplay()\n\n\n\n\n\n\n\n\nThe same is true for RTX’s stock price, both differencing and taking the log of its stock price gives us a weakly stationary series.\n\n\nACF and PACF of Dow Jones Travel and Tourism Index’s (DJUSTT) Transformations (Log, Difference, Differenced Log)\n\nLog TransformationDifferenced TransformationDifferenced Log Transformation\n\n\n\n\nCode\nlog.djustt=log(djustt.close)\n\nlog.djustt %>% ggtsdisplay()\n\n\n\n\n\n\n\n\n\nCode\ndiff.djustt=diff(djustt.close)\n\ndiff.djustt %>% ggtsdisplay()\n\n\n\n\n\n\n\n\n\nCode\nlogdiff.djustt=log(diff(djustt.close))\n\nlogdiff.djustt %>% ggtsdisplay()\n\n\n\n\n\n\n\n\nDifferencing and taking the log of the index leads to a stationary series, unlike the weakly stationary series obtained from both stocks.\n\n\nChecking for different ARIMA(p,q,d) Combinations: Lockheed Martin (LMT)\n\n\nCode\n######################## Check for different combinations ########\n\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*32),nrow=32) # roughly nrow = 3x4x2\n\n\nfor (p in 1:4)# p=1,2,3\n{\n  for(q in 1:4)# q=1,2,3\n  {\n    for(d in 0:1)\n    {\n      \n      if(p-1+d+q-1<=8)\n      {\n        \n        model<- Arima(log.lmt,order=c(p-1,d,q-1),include.drift=TRUE) \n        ls[i,]= c(p-1,d,q-1,model$aic,model$bic,model$aicc)\n        i=i+1\n        #print(i)\n        \n      }\n      \n    }\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n\n\n\n\np\nd\nq\nAIC\nBIC\nAICc\n\n\n\n\n0\n0\n0\n3286.409\n3306.977\n3286.412\n\n\n0\n1\n0\n-37587.576\n-37573.865\n-37587.575\n\n\n0\n0\n1\n-5825.115\n-5797.692\n-5825.110\n\n\n0\n1\n1\n-37612.096\n-37591.529\n-37612.093\n\n\n0\n0\n2\n-13119.175\n-13084.895\n-13119.166\n\n\n0\n1\n2\n-37615.377\n-37587.953\n-37615.371\n\n\n0\n0\n3\n-18328.546\n-18287.410\n-18328.534\n\n\n0\n1\n3\n-37613.515\n-37579.236\n-37613.506\n\n\n1\n0\n0\n-37589.004\n-37561.580\n-37588.998\n\n\n1\n1\n0\n-37610.565\n-37589.998\n-37610.562\n\n\n1\n0\n1\n-37612.876\n-37578.596\n-37612.867\n\n\n1\n1\n1\n-37615.038\n-37587.614\n-37615.032\n\n\n1\n0\n2\n-37615.907\n-37574.771\n-37615.895\n\n\n1\n1\n2\n-37613.320\n-37579.041\n-37613.312\n\n\n1\n0\n3\n-37614.013\n-37566.021\n-37613.997\n\n\n1\n1\n3\n-37611.508\n-37570.373\n-37611.496\n\n\n2\n0\n0\n-37611.413\n-37577.133\n-37611.404\n\n\n2\n1\n0\n-37614.994\n-37587.570\n-37614.988\n\n\n2\n0\n1\n-37615.253\n-37574.117\n-37615.241\n\n\n2\n1\n1\n-37613.101\n-37578.822\n-37613.093\n\n\n2\n0\n2\n-37614.874\n-37566.882\n-37614.858\n\n\n2\n1\n2\n-37611.496\n-37570.362\n-37611.484\n\n\n2\n0\n3\n-37611.909\n-37557.061\n-37611.888\n\n\n2\n1\n3\n-37609.501\n-37561.510\n-37609.485\n\n\n3\n0\n0\n-37615.575\n-37574.439\n-37615.563\n\n\n3\n1\n0\n-37613.488\n-37579.209\n-37613.480\n\n\n3\n0\n1\n-37612.074\n-37564.083\n-37612.058\n\n\n3\n1\n1\n-37611.512\n-37570.377\n-37611.500\n\n\n3\n0\n2\n-37611.986\n-37557.138\n-37611.965\n\n\n3\n1\n2\n-37609.521\n-37561.530\n-37609.505\n\n\n3\n0\n3\n-37610.044\n-37548.340\n-37610.018\n\n\n3\n1\n3\n-37607.513\n-37552.666\n-37607.492\n\n\n\n\n\n\n\nCode\ncat(\"Lowest AIC model: \\n\")\n\n\nLowest AIC model: \n\n\nCode\ntemp[which.min(temp$AIC),] # 0,1,0\n\n\n   p d q       AIC       BIC     AICc\n13 1 0 2 -37615.91 -37574.77 -37615.9\n\n\nCode\ncat(\"\\nLowest BIC model: \\n\")\n\n\n\nLowest BIC model: \n\n\nCode\ntemp[which.min(temp$BIC),] # 0,1,1\n\n\n  p d q      AIC       BIC      AICc\n4 0 1 1 -37612.1 -37591.53 -37612.09\n\n\nCode\ncat(\"\\nLowest AICc model: \\n\")\n\n\n\nLowest AICc model: \n\n\nCode\ntemp[which.min(temp$AICc),] # 0,1,0\n\n\n   p d q       AIC       BIC     AICc\n13 1 0 2 -37615.91 -37574.77 -37615.9\n\n\nWe shall choose ARIMA(0,1,1) as the best model for LMT, given it has the lowest BIC, its AIC is fairly close to other, more complex ARIMA model, ARIMA(1,0,2) or ARMA(1,2), and we shall be abiding by the principle of parsimony. Moreover, an ARMA model only captures the conditional mean, whereas an ARIMA model captures both the conditional mean and conditional variance.\n\n\nChecking for different ARIMA(p,q,d) Combinations: Raytheon Technologies (RTX)\n\n\nCode\n######################## Check for different combinations ########\n\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*32),nrow=32) # roughly nrow = 3x4x2\n\n\nfor (p in 1:4)# p=1,2,3\n{\n  for(q in 1:4)# q=1,2,3\n  {\n    for(d in 0:1)\n    {\n      \n      if(p-1+d+q-1<=8)\n      {\n        \n        model<- Arima(log.rtx,order=c(p-1,d,q-1),include.drift=TRUE) \n        ls[i,]= c(p-1,d,q-1,model$aic,model$bic,model$aicc)\n        i=i+1\n        #print(i)\n        \n      }\n      \n    }\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n\n\n\n\np\nd\nq\nAIC\nBIC\nAICc\n\n\n\n\n0\n0\n0\n2907.649\n2929.297\n2907.651\n\n\n0\n1\n0\n-53301.073\n-53286.640\n-53301.071\n\n\n0\n0\n1\n-10229.369\n-10200.504\n-10229.365\n\n\n0\n1\n1\n-53299.750\n-53278.102\n-53299.748\n\n\n0\n0\n2\n-20271.790\n-20235.709\n-20271.784\n\n\n0\n1\n2\n-53299.490\n-53270.625\n-53299.486\n\n\n0\n0\n3\n-27788.087\n-27744.790\n-27788.079\n\n\n0\n1\n3\n-53297.801\n-53261.720\n-53297.795\n\n\n1\n0\n0\n-53306.304\n-53277.439\n-53306.300\n\n\n1\n1\n0\n-53299.733\n-53278.084\n-53299.730\n\n\n1\n0\n1\n-53304.834\n-53268.753\n-53304.828\n\n\n1\n1\n1\n-53297.742\n-53268.878\n-53297.738\n\n\n1\n0\n2\n-53304.331\n-53261.034\n-53304.323\n\n\n1\n1\n2\n-53297.496\n-53261.415\n-53297.490\n\n\n1\n0\n3\n-53302.772\n-53252.258\n-53302.761\n\n\n1\n1\n3\n-53295.819\n-53252.522\n-53295.810\n\n\n2\n0\n0\n-53304.821\n-53268.740\n-53304.815\n\n\n2\n1\n0\n-53299.392\n-53270.527\n-53299.388\n\n\n2\n0\n1\n-53309.017\n-53265.720\n-53309.009\n\n\n2\n1\n1\n-53297.386\n-53261.305\n-53297.380\n\n\n2\n0\n2\n-53313.395\n-53262.881\n-53313.384\n\n\n2\n1\n2\n-53309.644\n-53266.347\n-53309.635\n\n\n2\n0\n3\n-53312.554\n-53254.824\n-53312.540\n\n\n2\n1\n3\n-53307.984\n-53257.472\n-53307.973\n\n\n3\n0\n0\n-53304.251\n-53260.954\n-53304.243\n\n\n3\n1\n0\n-53297.753\n-53261.672\n-53297.747\n\n\n3\n0\n1\n-53313.558\n-53263.045\n-53313.547\n\n\n3\n1\n1\n-53295.738\n-53252.441\n-53295.730\n\n\n3\n0\n2\n-53310.690\n-53252.960\n-53310.676\n\n\n3\n1\n2\n-53309.200\n-53258.687\n-53309.189\n\n\n3\n0\n3\n-53310.154\n-53245.208\n-53310.136\n\n\n3\n1\n3\n-53323.311\n-53265.582\n-53323.296\n\n\n\n\n\n\n\nCode\ncat(\"Lowest AIC model: \\n\")\n\n\nLowest AIC model: \n\n\nCode\ntemp[which.min(temp$AIC),] # 3,1,3\n\n\n   p d q       AIC       BIC     AICc\n32 3 1 3 -53323.31 -53265.58 -53323.3\n\n\nCode\ncat(\"\\nLowest BIC model: \\n\")\n\n\n\nLowest BIC model: \n\n\nCode\ntemp[which.min(temp$BIC),] # 0,1,0\n\n\n  p d q       AIC       BIC      AICc\n2 0 1 0 -53301.07 -53286.64 -53301.07\n\n\nCode\ncat(\"\\nLowest AICc model: \\n\")\n\n\n\nLowest AICc model: \n\n\nCode\ntemp[which.min(temp$AICc),] # 3,1,3\n\n\n   p d q       AIC       BIC     AICc\n32 3 1 3 -53323.31 -53265.58 -53323.3\n\n\nWe shall choose ARIMA(0,1,0), a random walk, as the best model for RTX, given it has the lowest BIC, its AIC is fairly close to other, more complex ARIMA model, ARIMA(3,1,3), and we shall be abiding by the principle of parsimony.\n\n\nChecking for different ARIMA(p,q,d) Combinations: Dow Jones Travel and Tourism Index (DJUSTT)\n\n\nCode\n######################## Check for different combinations ########\n\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*32),nrow=32) # roughly nrow = 3x4x2\n\n\nfor (p in 1:4)# p=1,2,3\n{\n  for(q in 1:4)# q=1,2,3\n  {\n    for(d in 0:1)\n    {\n      \n      if(p-1+d+q-1<=8)\n      {\n        \n        model<- Arima(djustt.close,order=c(p-1,d,q-1),include.drift=TRUE) # taking log gives NA error (dont want to use CSS Method that is based conditional likelihood and does not produce same likelihood value which unconditional likelihood function produces when it is optimized for the same parameters.)\n        ls[i,]= c(p-1,d,q-1,model$aic,model$bic,model$aicc)\n        i=i+1\n        #print(i)\n        \n      }\n      \n    }\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n\n\n\n\np\nd\nq\nAIC\nBIC\nAICc\n\n\n\n\n0\n0\n0\n43372.81\n43391.35\n43372.82\n\n\n0\n1\n0\n26850.31\n26862.66\n26850.31\n\n\n0\n0\n1\n38867.13\n38891.84\n38867.14\n\n\n0\n1\n1\n26848.82\n26867.36\n26848.83\n\n\n0\n0\n2\n35671.58\n35702.47\n35671.60\n\n\n0\n1\n2\n26847.63\n26872.35\n26847.64\n\n\n0\n0\n3\n33390.42\n33427.49\n33390.44\n\n\n0\n1\n3\n26848.56\n26879.45\n26848.58\n\n\n1\n0\n0\n26858.82\n26883.53\n26858.83\n\n\n1\n1\n0\n26848.62\n26867.16\n26848.63\n\n\n1\n0\n1\n26856.78\n26887.67\n26856.80\n\n\n1\n1\n1\n26849.44\n26874.15\n26849.45\n\n\n1\n0\n2\n26854.98\n26892.06\n26855.01\n\n\n1\n1\n2\n26849.13\n26880.02\n26849.15\n\n\n1\n0\n3\n26856.24\n26899.49\n26856.27\n\n\n1\n1\n3\n26850.55\n26887.62\n26850.58\n\n\n2\n0\n0\n26856.53\n26887.42\n26856.54\n\n\n2\n1\n0\n26847.90\n26872.61\n26847.91\n\n\n2\n0\n1\n26854.56\n26891.63\n26854.58\n\n\n2\n1\n1\n26849.43\n26880.32\n26849.44\n\n\n2\n0\n2\n26855.55\n26898.80\n26855.58\n\n\n2\n1\n2\n26848.54\n26885.61\n26848.57\n\n\n2\n0\n3\n26858.38\n26907.80\n26858.42\n\n\n2\n1\n3\n26852.44\n26895.69\n26852.48\n\n\n3\n0\n0\n26855.24\n26892.31\n26855.26\n\n\n3\n1\n0\n26848.79\n26879.68\n26848.81\n\n\n3\n0\n1\n26856.80\n26900.05\n26856.83\n\n\n3\n1\n1\n26850.81\n26887.88\n26850.83\n\n\n3\n0\n2\n26856.88\n26906.31\n26856.92\n\n\n3\n1\n2\n26852.56\n26895.81\n26852.59\n\n\n3\n0\n3\n26822.98\n26878.59\n26823.03\n\n\n3\n1\n3\n26850.58\n26900.01\n26850.63\n\n\n\n\n\n\n\nCode\ncat(\"Lowest AIC model: \\n\")\n\n\nLowest AIC model: \n\n\nCode\ntemp[which.min(temp$AIC),] # 3,0,3\n\n\n   p d q      AIC      BIC     AICc\n31 3 0 3 26822.98 26878.59 26823.03\n\n\nCode\ncat(\"\\nLowest BIC model: \\n\")\n\n\n\nLowest BIC model: \n\n\nCode\ntemp[which.min(temp$BIC),] # 0,1,0\n\n\n  p d q      AIC      BIC     AICc\n2 0 1 0 26850.31 26862.66 26850.31\n\n\nCode\ncat(\"\\nLowest AICc model: \\n\")\n\n\n\nLowest AICc model: \n\n\nCode\ntemp[which.min(temp$AICc),] # 3,0,3\n\n\n   p d q      AIC      BIC     AICc\n31 3 0 3 26822.98 26878.59 26823.03\n\n\nWe shall choose ARIMA(0,1,0), a random walk, as the best model for DJUSTT, given it has the lowest BIC, its AIC is fairly close to other, more complex ARIMA model, ARIMA(3,0,3), and we shall be abiding by the principle of parsimony."
  },
  {
    "objectID": "Financial-Models.html#model-diagnostics",
    "href": "Financial-Models.html#model-diagnostics",
    "title": "Financial Time Series Models",
    "section": "Model Diagnostics",
    "text": "Model Diagnostics\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones Travel and Tourism Index (DJUSTT)\n\n\n\n\nCode\narima.lmt=sarima(log.lmt,0,1,1)\n\n\n\n\n\nCode\nsummary(arima.lmt)\n\n\n\n\n\n\nCode\narima.rtx=sarima(log.rtx,0,1,0)\n\n\n\n\n\nCode\nsummary(arima.rtx)\n\n\n\n\n\n\nCode\narima.djustt=sarima(djustt.close,0,1,0)\n\n\n\n\n\nCode\nsummary(arima.djustt)\n\n\n\n\n\nLockheed Martin (LMT):\nThe plot of standardized residuals should have a mean around 0 and a variance of approximately 1. The plot for LMT generally meets the criterion for the mean but has higher variance with clusters, indicating the need for an ARCH/GARCH model for the errors. The absence of significant lags in the ACF plot of residuals is an encouraging sign. The qq-plot indicates some signs of normality with slight skew at the tails. In addition, the p-values for the Ljung-Box test are above 0.05 for many lags, suggesting a well-fitted model. Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent. Overall, while the variance of the standardized residuals suggests the need for an ARCH/GARCH model, the other diagnostic plots indicate a good fit for the ARIMA model.\nRaytheon Technologies (RTX):\nThe plot of standardized residuals for RTX is also centered around 0 and has significantly lower number of clusters. Moreover, the variance within those few clusters is not as high as those in LMT’s plot of standardized residuals. In addition, the p-values for the Ljung-Box test are above 0.05 for the first few lags and the absence of significant lags in the ACF plot of residuals is an encouraging sign. The qq-plot indicates some signs of normality with slight skew at the tails.\nDow Jones Travel and Tourism Index (DJUSTT):\nThe plot of standardized residuals for RTX is also centered around 0 and has significantly lower number of clusters. Moreover, the variance within those few clusters is not as high as those in LMT’s plot of standardized residuals. Although none of the p-values for the Ljung-Box test are above 0.05, signifying that the residuals might not be independently distributed or that they exhibit serial correlation, a random walk model can be expected to show these outputs. Regardless, the absence of significant lags in the ACF plot of residuals is an encouraging sign. The qq-plot indicates some signs of normality with slight skew at the tails."
  },
  {
    "objectID": "Financial-Models.html#plotting-squared-residuals-of-chosen-models-and-their-acfs-and-pacfs",
    "href": "Financial-Models.html#plotting-squared-residuals-of-chosen-models-and-their-acfs-and-pacfs",
    "title": "Financial Time Series Models",
    "section": "Plotting Squared Residuals of Chosen Models and their ACFs and PACFs",
    "text": "Plotting Squared Residuals of Chosen Models and their ACFs and PACFs\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones Travel and Tourism Index (DJUSTT)\n\n\n\n\nCode\narima.lmt=Arima(log.lmt,order=c(0,1,1))\nres.arima.lmt=arima.lmt$res\nsq.res.arima.lmt=res.arima.lmt^2\n\nsq.res.arima.lmt %>% ggtsdisplay()\n\n\n\n\n\n\n\n\n\nCode\narima.rtx=Arima(log.rtx,order=c(0,1,0))\nres.arima.rtx=arima.rtx$res\nsq.res.arima.rtx=res.arima.rtx^2\n\nsq.res.arima.rtx %>% ggtsdisplay()\n\n\n\n\n\n\n\n\n\nCode\narima.djustt=Arima(djustt.close,order=c(0,1,0))\nres.arima.djustt=arima.djustt$res\nsq.res.arima.djustt=res.arima.djustt^2\n\nsq.res.arima.djustt %>% ggtsdisplay()\n\n\n\n\n\n\n\n\nAll the squared residuals plots show signs of volatility clustering. After conducting the model diagnostics and perusing the ACF and PACF of the squared residuals, a GARCH(p,q) model is suitable for all financial series."
  },
  {
    "objectID": "Financial-Models.html#fitting-garchpq-models-to-residuals",
    "href": "Financial-Models.html#fitting-garchpq-models-to-residuals",
    "title": "Financial Time Series Models",
    "section": "Fitting GARCH(p,q) Models to Residuals",
    "text": "Fitting GARCH(p,q) Models to Residuals\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones Travel and Tourism Index (DJUSTT)\n\n\n\n\nCode\nmodel <- list() ## set counter\ncc <- 1\nfor (p in 1:10) {\n  for (q in 1:10) {\n  \nmodel[[cc]] <- garch(res.arima.lmt,order=c(q,p),trace=F)\ncc <- cc + 1\n}\n} \n\n## get AIC values for model evaluation\nGARCH_AIC <- sapply(model, AIC) \n\nmodel[[which(GARCH_AIC == min(GARCH_AIC))]] ## model with lowest AIC is the best and output model summary\n\n\n\nCall:\ngarch(x = res.arima.lmt, order = c(q, p), trace = F)\n\nCoefficient(s):\n       a0         a1         b1  \n3.503e-06  6.444e-02  9.227e-01  \n\n\n\n\n\n\nCode\nmodel <- list() ## set counter\ncc <- 1\nfor (p in 1:10) {\n  for (q in 1:10) {\n  \nmodel[[cc]] <- garch(res.arima.rtx,order=c(q,p),trace=F)\ncc <- cc + 1\n}\n} \n\n## get AIC values for model evaluation\nGARCH_AIC <- sapply(model, AIC) \n\nmodel[[which(GARCH_AIC == min(GARCH_AIC))]] ## model with lowest AIC is the best and output model summary\n\n\n\nCall:\ngarch(x = res.arima.rtx, order = c(q, p), trace = F)\n\nCoefficient(s):\n       a0         a1         a2         b1         b2         b3         b4  \n1.118e-05  1.060e-01  1.075e-01  3.155e-01  2.127e-02  3.311e-02  1.054e-01  \n       b5         b6  \n1.657e-08  2.780e-01  \n\n\n\n\n\n\nCode\nmodel <- list() ## set counter\ncc <- 1\nfor (p in 1:20) {\n  for (q in 1:20) {\n  \nmodel[[cc]] <- garch(res.arima.djustt,order=c(q,p),trace=F)\ncc <- cc + 1\n}\n} \n\n## get AIC values for model evaluation\nGARCH_AIC <- sapply(model, AIC) \n\nmodel[[which(GARCH_AIC == min(GARCH_AIC))]] ## model with lowest AIC is the best and output model summary\n\n\n\nCall:\ngarch(x = res.arima.djustt, order = c(q, p), trace = F)\n\nCoefficient(s):\n       a0         a1         a2         a3         a4         a5         a6  \n5.574e-03  5.902e-02  7.799e-02  1.116e-01  7.665e-02  5.615e-02  4.856e-02  \n       a7         a8         a9        a10        a11        a12        a13  \n1.679e-01  6.062e-02  1.043e-02  5.722e-02  4.919e-02  5.030e-02  8.140e-15  \n      a14        a15        a16        a17         b1         b2         b3  \n7.457e-02  2.864e-02  1.605e-01  1.063e-01  3.581e-02  3.671e-02  3.425e-02  \n\n\n\n\n\nLockheed Martin (LMT):\nThe outputted model is GARCH(1,1). Therefore, the final model is ARIMA(0,1,1) + GARCH(1,1)\nRaytheon Technologies (RTX):\nThe outputted model is GARCH(2,6). Therefore, the final model is ARIMA(0,1,0) + GARCH(2,6)\nDow Jones Travel and Tourism Index (DJUSTT):\nThe outputted model is GARCH(17,3). Therefore, the final model is ARIMA(0,1,0) + GARCH(17,3)"
  },
  {
    "objectID": "Financial-Models.html#fitting-arima-garch-final-model-and-conducting-box-ljung-test-on-residuals",
    "href": "Financial-Models.html#fitting-arima-garch-final-model-and-conducting-box-ljung-test-on-residuals",
    "title": "Financial Time Series Models",
    "section": "Fitting ARIMA + GARCH (final model) and Conducting Box-Ljung Test on Residuals",
    "text": "Fitting ARIMA + GARCH (final model) and Conducting Box-Ljung Test on Residuals\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones Travel and Tourism Index (DJUSTT)\n\n\n\n\nCode\nspec <- ugarchspec(variance.model = list(model = \"sGARCH\", garchOrder = c(1,1)), \n                   mean.model = list(armaOrder = c(0,1)), \n                   distribution.model = \"std\")\n\nfit.lmt <- ugarchfit(spec, data = res.arima.lmt, solver = \"hybrid\")\n\n\n# Perform Box-Ljung test on residuals\ncat(\"Box-Ljung Test on Residuals based on lag = 1: \\n\")\n\n\nBox-Ljung Test on Residuals based on lag = 1: \n\n\nCode\nBox.test(fit.lmt@fit$residuals, type=\"Ljung-Box\")\n\n\n\n    Box-Ljung test\n\ndata:  fit.lmt@fit$residuals\nX-squared = 1.4263, df = 1, p-value = 0.2324\n\n\nCode\ncat(\"\\nBox-Ljung Test on Residuals based on lag = 10: \\n\")\n\n\n\nBox-Ljung Test on Residuals based on lag = 10: \n\n\nCode\nBox.test(fit.lmt@fit$residuals, type=\"Ljung-Box\", lag=10) # not signif after lag = 11 \n\n\n\n    Box-Ljung test\n\ndata:  fit.lmt@fit$residuals\nX-squared = 11.588, df = 10, p-value = 0.3135\n\n\n\n\n\n\nCode\nspec <- ugarchspec(variance.model = list(model = \"sGARCH\", garchOrder = c(2,6)), \n                   mean.model = list(armaOrder = c(0,1,0)), \n                   distribution.model = \"std\")\n\nfit.rtx <- ugarchfit(spec, data = res.arima.rtx, solver = \"hybrid\")\n\n\n# Perform Box-Ljung test (lag=1 and lag=10) on residuals\ncat(\"Box-Ljung Test on Residuals based on lag = 1: \\n\")\n\n\nBox-Ljung Test on Residuals based on lag = 1: \n\n\nCode\nBox.test(fit.rtx@fit$residuals, type=\"Ljung-Box\")\n\n\n\n    Box-Ljung test\n\ndata:  fit.rtx@fit$residuals\nX-squared = 0.0035734, df = 1, p-value = 0.9523\n\n\nCode\ncat(\"\\nBox-Ljung Test on Residuals based on lag = 5: \\n\")\n\n\n\nBox-Ljung Test on Residuals based on lag = 5: \n\n\nCode\nBox.test(fit.rtx@fit$residuals, type=\"Ljung-Box\", lag=5) # not signif after lag = 3\n\n\n\n    Box-Ljung test\n\ndata:  fit.rtx@fit$residuals\nX-squared = 15.563, df = 5, p-value = 0.008208\n\n\n\n\n\n\nCode\nspec <- ugarchspec(variance.model = list(model = \"sGARCH\", garchOrder = c(3,9)), \n                   mean.model = list(armaOrder = c(0,1,0)), \n                   distribution.model = \"std\")\n\nfit.djustt <- ugarchfit(spec, data = res.arima.djustt, solver = \"hybrid\")\n\n\n# Perform Box-Ljung test (lag=1 and lag=10) on residuals\ncat(\"Box-Ljung Test on Residuals based on lag = 1: \\n\")\n\n\nBox-Ljung Test on Residuals based on lag = 1: \n\n\nCode\nBox.test(fit.djustt@fit$residuals, type=\"Ljung-Box\")\n\n\n\n    Box-Ljung test\n\ndata:  fit.djustt@fit$residuals\nX-squared = 0.011276, df = 1, p-value = 0.9154\n\n\nCode\ncat(\"\\nBox-Ljung Test on Residuals based on lag = 5: \\n\")\n\n\n\nBox-Ljung Test on Residuals based on lag = 5: \n\n\nCode\nBox.test(fit.djustt@fit$residuals, type=\"Ljung-Box\", lag=5) # not signif after lag = 5\n\n\n\n    Box-Ljung test\n\ndata:  fit.djustt@fit$residuals\nX-squared = 5.5925, df = 5, p-value = 0.3479\n\n\n\n\n\nLockheed Martin (LMT):\nThe Box-Ljung Test outputs a p-value > 0.05 for all lags up until 10, which signifies that the ARIMA(0,1,1) + GARCH(1,1), fitted on LMT, captures the autocorrelation structure in the data until lag 10. This indicates that the model is robust is forecasting the volatility of future returns of LMT.\nRaytheon Technologies (RTX):\nThe Box-Ljung Test outputs a p-value > 0.05 for all lags up until 3, which signifies that the ARIMA(0,1,0) + GARCH(2,6), fitted on RTX, captures the autocorrelation structure in the data until lag 3. The model can still be employed to forecast the volatility of future returns of RTX and is a good indication that the model is capturing the important dynamics in the data.\nDow Jones Travel and Tourism Index (DJUSTT):\nThe Box-Ljung Test outputs a p-value > 0.05 for all lags up until 5, which signifies that the ARIMA(0,1,0) + GARCH(17,3), fitted on DJUSTT, captures the autocorrelation structure in the data until lag 3. The AR component of the GARCH model is significantly more complex than that of the other models because it has a much higher number of GARCH terms (17) relative to the other models.\nGenerally, a model with more parameters is considered more complex because it has more degrees of freedom to fit the data, which can lead to overfitting and poor out-of-sample performance. However, a more complex model may be necessary to adequately capture the dynamics of the DJUSTT, which has a relatively more complex and highly volatile time series. This can also be seen in its returns plot in the previous section."
  },
  {
    "objectID": "Financial-Models.html#model-equations",
    "href": "Financial-Models.html#model-equations",
    "title": "Financial Time Series Models",
    "section": "Model Equations",
    "text": "Model Equations\nLockheed Martin (LMT):\nARIMA(0,1,1) + GARCH(1,1):\n\\(r_t = \\phi r_{t-1} + \\epsilon_t + \\theta \\epsilon_{t-1}\\), where \\(\\phi\\) and \\(\\theta\\) are the autoregressive and moving average parameters, respectively, for the conditional mean of the time series, and \\(\\epsilon_t\\) is a standardized white noise process with mean 0 and variance 1.\nThe conditional variance of the time series, \\(\\sigma_t^2\\), is modeled as a GARCH(1,1) process as:\n\\(\\sigma_t^2 = a_0 + \\alpha_1 \\epsilon_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2\\), where \\(\\alpha_1\\) and \\(\\beta_1\\) are the autoregressive and moving average parameters, respectively, for the squared residuals \\(r_{t-1}^2\\) and the conditional variances \\(\\sigma_{t-1}^2\\). The parameter \\(a_0\\) represents the constant variance term.\nRaytheon Technologies (RTX):\nARIMA(0,1,0) + GARCH(2,6): \\(r_t = \\phi r_{t-1} + \\epsilon_t\\), where \\(\\phi\\) and \\(\\theta\\) are the autoregressive and moving average parameters, respectively, for the conditional mean of the time series, and \\(\\epsilon_t\\) is a standardized white noise process with mean 0 and variance 1.\nThe conditional variance of the time series, \\(\\sigma_t^2\\), is still modeled as a GARCH(2,6) process as:\n\\(\\sigma_t^2 = a_0 + \\alpha_1 \\epsilon_{t-1}^2 + \\alpha_2 \\epsilon_{t-2}^2 + \\beta_1 \\sigma_{t-1}^2 + \\beta_2 \\sigma_{t-2}^2 + \\beta_3 \\sigma_{t-3}^2 + \\beta_4 \\sigma_{t-4}^2 + \\beta_5 \\sigma_{t-5}^2 + \\beta_6 \\sigma_{t-6}^2\\) , where \\(\\alpha\\) and \\(\\beta\\) are the autoregressive and moving average parameters, respectively, for the squared residuals \\(r_{t-j}^2\\) and the conditional variances \\(\\sigma_{t-j}^2\\). The parameter \\(a_0\\) represents the constant variance term.\nDow Jones Travel and Tourism Index (DJUSTT):\nARIMA(0,1,0) + GARCH(17,3):\n\\(r_t = \\phi r_{t-1} + \\epsilon_t\\), where \\(\\phi\\) is the autoregressive parameter for the conditional mean of the time series, and \\(\\epsilon_t\\) is a standardized white noise process with mean 0 and variance \\(\\sigma_t^2\\).\nThe conditional variance of the time series, \\(\\sigma_t^2\\), is modeled as a GARCH(17,3) process as:\n\\(\\sigma_t^2 = a_0 + \\sum_{i=1}^{17} \\alpha_i \\epsilon_{t-i}^2 + \\sum_{j=1}^{3} \\beta_j \\sigma_{t-j}^2\\), where \\(\\alpha_i\\) and \\(\\beta_j\\) are the autoregressive and moving average parameters, respectively, for the squared residuals \\(r_{t-i}^2\\) and the conditional variances \\(\\sigma_{t-j}^2\\). The parameter \\(a_0\\) represents the constant variance term."
  },
  {
    "objectID": "Deep-Learning.html",
    "href": "Deep-Learning.html",
    "title": "Deep Learning for Time Series",
    "section": "",
    "text": "After fitting several time-series models to both monthly as well as yearly aggregated terrorist attacks data and financial data in the previous sections, we will now focus on the efficacy of Deep Learning models in helping us predict the monthly number of terrorist attacks, the same univariate time-series data employed in the ARMA/ARIMA/SARIMA section. We shall employ popular Recurrent Neural Networks (RNNs), including a Dense RNN, a Gated Recurrent Unit (GRU), and a Long Short-Term Memory Network (LSTM), with and without L2 regularization, a method to curb overfitting by forcing the weights of the parameters to decay towards zero, to predict the number number of terrorist attacks per month in the future. Doing so will help us compare not only the performance of the three RNNs, but also the performance of the three RNNs to that of the traditional univariate time-series models, ARIMA and SARIMA. Lastly, we shall discuss the effect of regularization on the results of our RNNs, assess how far into the future the RNNs can accurately predict the future, and compare the results of the trained deep learning models to the traditional single-variable time-series ARMA/ARIMA models.\nTo train these models, we use Python’s Keras library, a wrapper for Tensorflow and take inspiration from Francois Chollet’s Deep Learning in Python, Second Edition, Book (Chollet 2021). Visualizations of the architecture of a simple RNN and LSTM are shown below:\n\n\nA simple RNN, unrolled over time\n\n\n \n\n\nAnatomy of an LSTM\n\n\n \nCode for this section can be found here"
  },
  {
    "objectID": "Deep-Learning.html#model-and-training-parameters",
    "href": "Deep-Learning.html#model-and-training-parameters",
    "title": "Deep Learning for Time Series",
    "section": "Model and Training Parameters",
    "text": "Model and Training Parameters\nThe input to the model is a 3D tensor with shape (batch_size, timesteps, input_dim). The output of the RNN layer is fed into a Dense layer with a single output unit, which is used to generate a scalar output.\n\n\nCode\n#USER PARAM\nrecurrent_hidden_units=3\nepochs=100\nf_batch=0.2    #fraction used for batch size\noptimizer=\"RMSprop\"\nvalidation_split=0.2"
  },
  {
    "objectID": "Deep-Learning.html#create-simple-rnn-model",
    "href": "Deep-Learning.html#create-simple-rnn-model",
    "title": "Deep Learning for Time Series",
    "section": "Create Simple RNN Model",
    "text": "Create Simple RNN Model\n\n\nCode\n#CREATE MODEL\nmodel = Sequential()\nmodel.add(SimpleRNN(\nrecurrent_hidden_units,\nreturn_sequences=False,\ninput_shape=(trainX.shape[1],trainX.shape[2]), \nactivation='tanh')\n          ) \n     \n#NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR \nmodel.add(Dense(units=1, activation='linear'))\n\n# COMPILE THE MODEL \nmodel.compile(loss='MeanSquaredError', optimizer=optimizer)\nmodel.summary()\n\n\nMetal device set to: Apple M1 Pro\n\n\nModel: \"sequential\"\n\n\n_________________________________________________________________\n\n\n Layer (type)                Output Shape              Param #   \n\n\n=================================================================\n\n\n simple_rnn (SimpleRNN)      (None, 3)                 15        \n\n\n                                                                 \n\n\n dense (Dense)               (None, 1)                 4         \n\n\n                                                                 \n\n\n=================================================================\n\n\nTotal params: 19\n\n\nTrainable params: 19\n\n\nNon-trainable params: 0\n\n\n_________________________________________________________________\n\n\n2023-05-03 18:12:51.533384: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n2023-05-03 18:12:51.533717: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)"
  },
  {
    "objectID": "Deep-Learning.html#train-model",
    "href": "Deep-Learning.html#train-model",
    "title": "Deep Learning for Time Series",
    "section": "Train Model",
    "text": "Train Model\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\nverbose=0) #suppress messages\n\n\n2023-04-29 01:05:32.527588: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n\n\n2023-04-29 01:05:33.064947: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:05:34.163074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 33ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 33ms/step\n\n\nTrain MSE = 0.00143 RMSE = 0.03783\nTest MSE = 0.06770 RMSE = 0.26018\n\n\n\n                                                \n\n\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\n\n\nFrom the above plots,"
  },
  {
    "objectID": "Deep-Learning.html#model-and-training-parameters-1",
    "href": "Deep-Learning.html#model-and-training-parameters-1",
    "title": "Deep Learning for Time Series",
    "section": "Model and Training Parameters",
    "text": "Model and Training Parameters\n\n\nCode\n#USER PARAM\nrecurrent_hidden_units=3\nepochs=100 \nf_batch=0.2    #fraction used for batch size\noptimizer=\"RMSprop\"\nvalidation_split=0.2"
  },
  {
    "objectID": "Deep-Learning.html#create-simple-rnn-model-with-l2-regularization",
    "href": "Deep-Learning.html#create-simple-rnn-model-with-l2-regularization",
    "title": "Deep Learning for Time Series",
    "section": "Create Simple RNN Model With L2 Regularization",
    "text": "Create Simple RNN Model With L2 Regularization\n\n\nCode\n#CREATE MODEL\nmodel = Sequential()\nmodel.add(SimpleRNN(\nrecurrent_hidden_units,\nreturn_sequences=False,\ninput_shape=(trainX.shape[1],trainX.shape[2]), \nrecurrent_regularizer=regularizers.L2(1e-2),\nactivation='tanh')\n          ) \n     \n#NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR \nmodel.add(Dense(units=1, activation='linear'))\n\n# COMPILE THE MODEL \nmodel.compile(loss='MeanSquaredError', optimizer=optimizer)\nmodel.summary()\n\n\nModel: \"sequential_1\"\n\n\n_________________________________________________________________\n\n\n Layer (type)                Output Shape              Param #   \n\n\n=================================================================\n\n\n simple_rnn_1 (SimpleRNN)    (None, 3)                 15        \n\n\n                                                                 \n\n\n dense_1 (Dense)             (None, 1)                 4         \n\n\n                                                                 \n\n\n=================================================================\n\n\nTotal params: 19\n\n\nTrainable params: 19\n\n\nNon-trainable params: 0\n\n\n_________________________________________________________________"
  },
  {
    "objectID": "Deep-Learning.html#train-model-1",
    "href": "Deep-Learning.html#train-model-1",
    "title": "Deep Learning for Time Series",
    "section": "Train Model",
    "text": "Train Model\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\nverbose=0) #suppress messages\n\n\n2023-04-29 01:07:02.311132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:07:03.198802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 23ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 28ms/step\n\n\nTrain MSE = 0.00228 RMSE = 0.04777\nTest MSE = 0.06801 RMSE = 0.26079\n\n\n\n                                                \n\n\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\n\n\nkkk"
  },
  {
    "objectID": "Deep-Learning.html#model-and-training-parameters-2",
    "href": "Deep-Learning.html#model-and-training-parameters-2",
    "title": "Deep Learning for Time Series",
    "section": "Model and Training Parameters",
    "text": "Model and Training Parameters\n\n\nCode\n#USER PARAM\nrecurrent_hidden_units=3\nepochs=100\nf_batch=0.2    #fraction used for batch size\noptimizer=\"RMSprop\"\nvalidation_split=0.2"
  },
  {
    "objectID": "Deep-Learning.html#create-gru-model-with-l2-regularization",
    "href": "Deep-Learning.html#create-gru-model-with-l2-regularization",
    "title": "Deep Learning for Time Series",
    "section": "Create GRU Model With L2 Regularization",
    "text": "Create GRU Model With L2 Regularization\n\n\nCode\n#CREATE MODEL\nmodel = Sequential()\nmodel.add(GRU(\nrecurrent_hidden_units,\nreturn_sequences=False,\ninput_shape=(trainX.shape[1],trainX.shape[2]), \nrecurrent_regularizer=regularizers.L2(1e-2),\nactivation='tanh')\n          ) \n     \n#NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR \nmodel.add(Dense(units=1, activation='linear'))\n\n# COMPILE THE MODEL \nmodel.compile(loss='MeanSquaredError', optimizer=optimizer)\nmodel.summary()\n\n\nModel: \"sequential_2\"\n\n\n_________________________________________________________________\n\n\n Layer (type)                Output Shape              Param #   \n\n\n=================================================================\n\n\n gru (GRU)                   (None, 3)                 54        \n\n\n                                                                 \n\n\n dense_2 (Dense)             (None, 1)                 4         \n\n\n                                                                 \n\n\n=================================================================\n\n\nTotal params: 58\n\n\nTrainable params: 58\n\n\nNon-trainable params: 0\n\n\n_________________________________________________________________"
  },
  {
    "objectID": "Deep-Learning.html#train-model-2",
    "href": "Deep-Learning.html#train-model-2",
    "title": "Deep Learning for Time Series",
    "section": "Train Model",
    "text": "Train Model\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\nverbose=0) #suppress messages\n\n\n2023-04-29 01:08:30.283755: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:08:30.405896: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:08:30.540543: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:08:31.110711: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:08:31.163493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 24ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 32ms/step\n\n\nTrain MSE = 0.00179 RMSE = 0.04227\nTest MSE = 0.04004 RMSE = 0.20010\n\n\n\n                                                \n\n\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\n\n\nkkk"
  },
  {
    "objectID": "Deep-Learning.html#model-and-training-parameters-3",
    "href": "Deep-Learning.html#model-and-training-parameters-3",
    "title": "Deep Learning for Time Series",
    "section": "Model and Training Parameters",
    "text": "Model and Training Parameters\n\n\nCode\n#USER PARAM\nrecurrent_hidden_units=3\nepochs=100\nf_batch=0.2    #fraction used for batch size\noptimizer=\"RMSprop\"\nvalidation_split=0.2"
  },
  {
    "objectID": "Deep-Learning.html#create-bidirectional-gru",
    "href": "Deep-Learning.html#create-bidirectional-gru",
    "title": "Deep Learning for Time Series",
    "section": "Create Bidirectional GRU",
    "text": "Create Bidirectional GRU\n\n\nCode\n#CREATE MODEL\nmodel = Sequential()\nmodel.add(Bidirectional(GRU(\nrecurrent_hidden_units,\nreturn_sequences=False,\ninput_shape=(trainX.shape[1],trainX.shape[2]), \nactivation='tanh')\n          )) \n     \n#NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR \nmodel.add(Dense(units=1, activation='linear'))\n\n# BUILD THE MODEL \nmodel.build(input_shape=(None, trainX.shape[1], trainX.shape[2]))\n\n# COMPILE THE MODEL \nmodel.compile(loss='MeanSquaredError', optimizer=optimizer)\nmodel.summary()\n\n\nModel: \"sequential_3\"\n\n\n_________________________________________________________________\n\n\n Layer (type)                Output Shape              Param #   \n\n\n=================================================================\n\n\n bidirectional (Bidirectiona  (None, 6)                108       \n\n\n l)                                                              \n\n\n                                                                 \n\n\n dense_3 (Dense)             (None, 1)                 7         \n\n\n                                                                 \n\n\n=================================================================\n\n\nTotal params: 115\n\n\nTrainable params: 115\n\n\nNon-trainable params: 0\n\n\n_________________________________________________________________"
  },
  {
    "objectID": "Deep-Learning.html#train-model-3",
    "href": "Deep-Learning.html#train-model-3",
    "title": "Deep Learning for Time Series",
    "section": "Train Model",
    "text": "Train Model\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\nverbose=0) #suppress messages\n\n\n2023-04-29 01:08:52.662933: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:08:52.847101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:08:52.857050: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:08:52.973231: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:08:52.985143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:08:53.799103: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:08:53.881631: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:08:53.892330: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 1s 46ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 49ms/step\n\n\nTrain MSE = 0.00167 RMSE = 0.04084\nTest MSE = 0.06657 RMSE = 0.25801\n\n\n\n                                                \n\n\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\n\n\nklkkk"
  },
  {
    "objectID": "Deep-Learning.html#model-and-training-parameters-4",
    "href": "Deep-Learning.html#model-and-training-parameters-4",
    "title": "Deep Learning for Time Series",
    "section": "Model and Training Parameters",
    "text": "Model and Training Parameters\n\n\nCode\n#USER PARAM\nrecurrent_hidden_units=3\nepochs=100 \nf_batch=0.2    #fraction used for batch size\noptimizer=\"RMSprop\"\nvalidation_split=0.2\ncallback = EarlyStopping(monitor='loss', patience=3) # This callback will stop the training when there is no improvement in the loss for three consecutive epochs"
  },
  {
    "objectID": "Deep-Learning.html#create-stacked-bidirectional-gru-with-l2-regularization",
    "href": "Deep-Learning.html#create-stacked-bidirectional-gru-with-l2-regularization",
    "title": "Deep Learning for Time Series",
    "section": "Create Stacked Bidirectional GRU with L2 Regularization",
    "text": "Create Stacked Bidirectional GRU with L2 Regularization\n\n\nCode\nmodel = Sequential()\nmodel.add(Bidirectional(GRU(\nrecurrent_hidden_units, \nreturn_sequences=True,\ninput_shape=(trainX.shape[1],trainX.shape[2]))\n          )) \nmodel.add(Bidirectional(GRU(\nrecurrent_hidden_units,\nrecurrent_regularizer=regularizers.L2(1e-2),\nactivation='relu')\n          )) \n     \n#NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR \nmodel.add(Dense(units=1, activation='linear'))\n\n# BUILD THE MODEL \nmodel.build(input_shape=(None, trainX.shape[1], trainX.shape[2]))\n\n# COMPILE THE MODEL \nmodel.compile(loss='MeanSquaredError', optimizer=optimizer)\nmodel.summary()\n\n\nWARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n\n\nWARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n\n\nWARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n\n\nModel: \"sequential_4\"\n\n\n_________________________________________________________________\n\n\n Layer (type)                Output Shape              Param #   \n\n\n=================================================================\n\n\n bidirectional_1 (Bidirectio  (None, 9, 6)             108       \n\n\n nal)                                                            \n\n\n                                                                 \n\n\n bidirectional_2 (Bidirectio  (None, 6)                198       \n\n\n nal)                                                            \n\n\n                                                                 \n\n\n dense_4 (Dense)             (None, 1)                 7         \n\n\n                                                                 \n\n\n=================================================================\n\n\nTotal params: 313\n\n\nTrainable params: 313\n\n\nNon-trainable params: 0\n\n\n_________________________________________________________________"
  },
  {
    "objectID": "Deep-Learning.html#train-model-4",
    "href": "Deep-Learning.html#train-model-4",
    "title": "Deep Learning for Time Series",
    "section": "Train Model",
    "text": "Train Model\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\ncallbacks=[callback], #early stopping\nverbose=0) #suppress messages\n\n\n2023-04-29 01:09:25.049523: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:09:25.505172: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:09:25.513546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:09:26.321540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:09:26.335986: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:09:29.113138: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:09:29.215449: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:09:29.222568: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\nWARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2dccf77f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 1s 242ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 249ms/step\n\n\nTrain MSE = 0.00166 RMSE = 0.04073\nTest MSE = 0.06188 RMSE = 0.24876"
  },
  {
    "objectID": "Deep-Learning.html#model-and-training-parameters-5",
    "href": "Deep-Learning.html#model-and-training-parameters-5",
    "title": "Deep Learning for Time Series",
    "section": "Model and Training Parameters",
    "text": "Model and Training Parameters\n\n\nCode\n#USER PARAM\nrecurrent_hidden_units=3\nepochs=100 \nf_batch=0.2    #fraction used for batch size\noptimizer=\"RMSprop\"\nvalidation_split=0.2\ncallback = EarlyStopping(monitor='loss', patience=3) # This callback will stop the training when there is no improvement in the loss for three consecutive epochs"
  },
  {
    "objectID": "Deep-Learning.html#create-bidirectional-lstm",
    "href": "Deep-Learning.html#create-bidirectional-lstm",
    "title": "Deep Learning for Time Series",
    "section": "Create Bidirectional LSTM",
    "text": "Create Bidirectional LSTM\n\n\nCode\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(\nrecurrent_hidden_units,\nreturn_sequences=False,\ninput_shape=(trainX.shape[1],trainX.shape[2]),\nactivation='tanh')\n          )) \n     \n#NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR \nmodel.add(Dense(units=1, activation='linear'))\n\n# BUILD THE MODEL \nmodel.build(input_shape=(None, trainX.shape[1], trainX.shape[2]))\n\n# COMPILE THE MODEL \nmodel.compile(loss='MeanSquaredError', optimizer=optimizer)\nmodel.summary()\n\n\nModel: \"sequential_5\"\n\n\n_________________________________________________________________\n\n\n Layer (type)                Output Shape              Param #   \n\n\n=================================================================\n\n\n bidirectional_3 (Bidirectio  (None, 6)                120       \n\n\n nal)                                                            \n\n\n                                                                 \n\n\n dense_5 (Dense)             (None, 1)                 7         \n\n\n                                                                 \n\n\n=================================================================\n\n\nTotal params: 127\n\n\nTrainable params: 127\n\n\nNon-trainable params: 0\n\n\n_________________________________________________________________"
  },
  {
    "objectID": "Deep-Learning.html#train-model-5",
    "href": "Deep-Learning.html#train-model-5",
    "title": "Deep Learning for Time Series",
    "section": "Train Model",
    "text": "Train Model\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\ncallbacks=[callback], #early stopping\nverbose=0) #suppress messages\n\n\n2023-04-29 01:13:58.590820: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:13:58.859376: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:13:58.871475: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:13:59.098657: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:13:59.116359: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:14:00.159858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:14:00.243505: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:14:00.256488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\nWARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x29273e5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 46ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 54ms/step\n\n\nTrain MSE = 0.00164 RMSE = 0.04055\nTest MSE = 0.04403 RMSE = 0.20984\n\n\n\n                                                \n\n\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\n\n\nlll"
  },
  {
    "objectID": "Deep-Learning.html#model-and-training-parameters-6",
    "href": "Deep-Learning.html#model-and-training-parameters-6",
    "title": "Deep Learning for Time Series",
    "section": "Model and Training Parameters",
    "text": "Model and Training Parameters\n\n\nCode\n#USER PARAM\nrecurrent_hidden_units=3\nepochs=100\nf_batch=0.2    #fraction used for batch size\noptimizer=\"RMSprop\"\nvalidation_split=0.2\ncallback = EarlyStopping(monitor='loss', patience=3) # This callback will stop the training when there is no improvement in the loss for three consecutive epochs"
  },
  {
    "objectID": "Deep-Learning.html#create-bidirectional-lstm-with-l2-regularization",
    "href": "Deep-Learning.html#create-bidirectional-lstm-with-l2-regularization",
    "title": "Deep Learning for Time Series",
    "section": "Create Bidirectional LSTM with L2 Regularization",
    "text": "Create Bidirectional LSTM with L2 Regularization\n\n\nCode\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(\nrecurrent_hidden_units,\nreturn_sequences=False,\ninput_shape=(trainX.shape[1],trainX.shape[2]),\nrecurrent_regularizer=regularizers.L2(1e-2),\nactivation='tanh')\n          )) \n     \n#NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR \nmodel.add(Dense(units=1, activation='linear'))\n\n# BUILD THE MODEL \nmodel.build(input_shape=(None, trainX.shape[1], trainX.shape[2]))\n\n# COMPILE THE MODEL \nmodel.compile(loss='MeanSquaredError', optimizer=optimizer)\nmodel.summary()\n\n\nModel: \"sequential_6\"\n\n\n_________________________________________________________________\n\n\n Layer (type)                Output Shape              Param #   \n\n\n=================================================================\n\n\n bidirectional_4 (Bidirectio  (None, 6)                120       \n\n\n nal)                                                            \n\n\n                                                                 \n\n\n dense_6 (Dense)             (None, 1)                 7         \n\n\n                                                                 \n\n\n=================================================================\n\n\nTotal params: 127\n\n\nTrainable params: 127\n\n\nNon-trainable params: 0\n\n\n_________________________________________________________________"
  },
  {
    "objectID": "Deep-Learning.html#train-model-6",
    "href": "Deep-Learning.html#train-model-6",
    "title": "Deep Learning for Time Series",
    "section": "Train Model",
    "text": "Train Model\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\ncallbacks=[callback], #early stopping\nverbose=0) #suppress messages\n\n\n2023-04-29 01:14:08.507925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:14:08.788759: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:14:08.800523: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:14:08.973462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:14:08.988282: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-04-29 01:14:09.959212: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:14:10.042867: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-04-29 01:14:10.050114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n:::panel-tabset ## Visualize Fitting History\n\n\n1/2 [==============>...............] - ETA: 1s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 1s 56ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 85ms/step\n\n\nTrain MSE = 0.00161 RMSE = 0.04013\nTest MSE = 0.05390 RMSE = 0.23216"
  },
  {
    "objectID": "Deep-Learning.html#visualize-parity-plot-unnormalized-data-6",
    "href": "Deep-Learning.html#visualize-parity-plot-unnormalized-data-6",
    "title": "Deep Learning for Time Series",
    "section": "Visualize Parity Plot (Unnormalized Data)",
    "text": "Visualize Parity Plot (Unnormalized Data)"
  },
  {
    "objectID": "Deep-Learning.html#visualize-predictions-unnormalized-data-6",
    "href": "Deep-Learning.html#visualize-predictions-unnormalized-data-6",
    "title": "Deep Learning for Time Series",
    "section": "Visualize Predictions (Unnormalized Data)",
    "text": "Visualize Predictions (Unnormalized Data)"
  },
  {
    "objectID": "Deep-Learning.html#simple-rnn-with-l2-regularization",
    "href": "Deep-Learning.html#simple-rnn-with-l2-regularization",
    "title": "Deep Learning for Time Series",
    "section": "Simple RNN with L2 Regularization",
    "text": "Simple RNN with L2 Regularization\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 35ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 40ms/step\n\n\nTrain MSE = 0.00251 RMSE = 0.05008\nTest MSE = 0.02910 RMSE = 0.17059"
  },
  {
    "objectID": "Deep-Learning.html#gru-with-l2-regularization",
    "href": "Deep-Learning.html#gru-with-l2-regularization",
    "title": "Deep Learning for Time Series",
    "section": "GRU with L2 Regularization",
    "text": "GRU with L2 Regularization\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 28ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 34ms/step\n\n\nTrain MSE = 0.00189 RMSE = 0.04344\nTest MSE = 0.02336 RMSE = 0.15284"
  },
  {
    "objectID": "Deep-Learning.html#bidirectional-lstm-no-regularization",
    "href": "Deep-Learning.html#bidirectional-lstm-no-regularization",
    "title": "Deep Learning for Time Series",
    "section": "Bidirectional LSTM (no regularization)",
    "text": "Bidirectional LSTM (no regularization)\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 48ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 54ms/step\n\n\nTrain MSE = 0.00160 RMSE = 0.04003\nTest MSE = 0.02046 RMSE = 0.14302"
  },
  {
    "objectID": "Deep-Learning.html#train-model-and-visualize-performance",
    "href": "Deep-Learning.html#train-model-and-visualize-performance",
    "title": "Deep Learning for Time Series",
    "section": "Train Model and Visualize Performance",
    "text": "Train Model and Visualize Performance\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\nverbose=0) #suppress messages\n\n\n2023-05-03 18:12:51.761030: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n\n\n2023-05-03 18:12:52.095006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:12:52.741862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 26ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 25ms/step\n\n\nTrain MSE = 0.00169 RMSE = 0.04109\nTest MSE = 0.06436 RMSE = 0.25369"
  },
  {
    "objectID": "Deep-Learning.html#discussion",
    "href": "Deep-Learning.html#discussion",
    "title": "Deep Learning for Time Series",
    "section": "Discussion",
    "text": "Discussion\n\n\nThe train RMSE (Root Mean Squared Error) outputted by the Simple RNN model is 0.04 and test RMSE is 0.25\n\n\nThe parity plot provides further evidence of the model’s accuracy and suggests that the model’s performance is better for smaller Y values, as the deviation from the line increases for larger Y values. This is likely due to the fact that the model is trained on a larger number of smaller Y values (the data contains a lot of 0 values), and thus is better at predicting smaller Y values. The Visualize Predictions plot shows that the model is able to predict the general trend of the data, and is able to predict the peaks and valleys of the data. The model does, to an extent, capture the seasonality of the data but not completely, implying overfitting! Let’s see if we can improve the model’s performance by adding L2 regularization."
  },
  {
    "objectID": "Deep-Learning.html#train-model-and-visualize-performance-1",
    "href": "Deep-Learning.html#train-model-and-visualize-performance-1",
    "title": "Deep Learning for Time Series",
    "section": "Train Model and Visualize Performance",
    "text": "Train Model and Visualize Performance\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\nverbose=0) #suppress messages\n\n\n2023-05-03 18:13:24.805020: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:13:25.377454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 18ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 25ms/step\n\n\nTrain MSE = 0.00238 RMSE = 0.04882\nTest MSE = 0.05282 RMSE = 0.22982"
  },
  {
    "objectID": "Deep-Learning.html#discussion-1",
    "href": "Deep-Learning.html#discussion-1",
    "title": "Deep Learning for Time Series",
    "section": "Discussion",
    "text": "Discussion\n\n\nWith L2 Regularization (lambda = 0.01) added to the Simple RNN model, the Train RMSE remained constant at 0.04 but test RMSE decreased from 0.25 to 0.23.\n\n\nI experimented with the number of epochs, trying 50 first, before arriving at 100. It seems that the regularization penalty was too strong relative to the capacity of the model, resulting in a higher RMSE when using the same number of epochs as before. However, when the number of epochs is reduced, the model had less time to overfit to the training data, and the regularization penalty was able to help the model generalize better."
  },
  {
    "objectID": "Deep-Learning.html#train-model-and-visualize-performance-2",
    "href": "Deep-Learning.html#train-model-and-visualize-performance-2",
    "title": "Deep Learning for Time Series",
    "section": "Train Model and Visualize Performance",
    "text": "Train Model and Visualize Performance\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\nverbose=0) #suppress messages\n\n\n2023-05-03 18:13:58.081772: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:13:58.206355: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:13:58.295841: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:13:58.679619: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:13:58.719279: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 24ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 29ms/step\n\n\nTrain MSE = 0.00182 RMSE = 0.04269\nTest MSE = 0.03059 RMSE = 0.17491"
  },
  {
    "objectID": "Deep-Learning.html#discussion-2",
    "href": "Deep-Learning.html#discussion-2",
    "title": "Deep Learning for Time Series",
    "section": "Discussion",
    "text": "Discussion\n\n\nThe GRU with L2 Regularization performs better, as observed by its Train RMSE of 0.04 and test RMSE of 0.17, a slight drop from that of the Simple RNN models.\n\n\nAlthough this is a good sign that a more complex model performs better, the prediction plot remains fairly similar compared to those of the RNN models. Let’s try a Bidirectional GRU model, keeping the same number of epochs (100), to see if we can further improve the model’s performance."
  },
  {
    "objectID": "Deep-Learning.html#train-model-and-visualize-performance-3",
    "href": "Deep-Learning.html#train-model-and-visualize-performance-3",
    "title": "Deep Learning for Time Series",
    "section": "Train Model and Visualize Performance",
    "text": "Train Model and Visualize Performance\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\nverbose=0) #suppress messages\n\n\n2023-05-03 18:14:08.311311: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:14:08.504119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:14:08.512589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:14:08.606044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:14:08.617886: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:14:09.199066: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:14:09.252337: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:14:09.258568: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 1s 43ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 47ms/step\n\n\nTrain MSE = 0.00165 RMSE = 0.04068\nTest MSE = 0.05309 RMSE = 0.23042"
  },
  {
    "objectID": "Deep-Learning.html#discussion-3",
    "href": "Deep-Learning.html#discussion-3",
    "title": "Deep Learning for Time Series",
    "section": "Discussion",
    "text": "Discussion\n\n\nThe Bidirectional GRU with no regularization performs worse than not only the GRU with L2 Regularization but also the Simple RNN models! Its Train RMSE of 0.04 and test RMSE of 0.23 are worse than the previous 3 models tested. This is likely due to the fact that the Bidirectional GRU is a more complex model and thus requires more regularization to prevent overfitting. Let’s introduce regularization again, but this time with a Stacked Bidirectional GRU."
  },
  {
    "objectID": "Deep-Learning.html#train-model-and-visualize-performance-4",
    "href": "Deep-Learning.html#train-model-and-visualize-performance-4",
    "title": "Deep Learning for Time Series",
    "section": "Train Model and Visualize Performance",
    "text": "Train Model and Visualize Performance\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\ncallbacks=[callback], #early stopping\nverbose=0) #suppress messages\n\n\n2023-05-03 18:14:23.890053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:14:24.361796: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:14:24.369915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:14:25.084621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:14:25.097027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:14:27.592685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:14:27.685334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:14:27.691929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\nWARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2c7662dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 1s 162ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 166ms/step\n\n\nTrain MSE = 0.00170 RMSE = 0.04123\nTest MSE = 0.06706 RMSE = 0.25895"
  },
  {
    "objectID": "Deep-Learning.html#discussion-4",
    "href": "Deep-Learning.html#discussion-4",
    "title": "Deep Learning for Time Series",
    "section": "Discussion",
    "text": "Discussion\nWhen using the Stacked Bidirectional GRU, it is imperative to add return_sequences=True to stack recurrent layers on top of each other in Keras. All intermediate layers should return their full sequence of outputs (a rank-3 tensor) rather than their output at the last timestep.\n\n\nThe output of this model is the worst out of all models so far, given its train RMSE of 0.04 and test RMSE of 0.26. Therefore, the best GRU model for predicting number of terorrist attacks in the US is the GRU model with L2 Regularization."
  },
  {
    "objectID": "Deep-Learning.html#train-model-and-visualize-performance-5",
    "href": "Deep-Learning.html#train-model-and-visualize-performance-5",
    "title": "Deep Learning for Time Series",
    "section": "Train Model and Visualize Performance",
    "text": "Train Model and Visualize Performance\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\ncallbacks=[callback], #early stopping\nverbose=0) #suppress messages\n\n\n2023-05-03 18:18:02.139537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:02.314481: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:02.324645: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:18:02.476672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:02.489670: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:18:03.315915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:03.375805: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:03.382717: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\nWARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x291b80280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 0s 47ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 47ms/step\n\n\nTrain MSE = 0.00166 RMSE = 0.04079\nTest MSE = 0.04501 RMSE = 0.21216"
  },
  {
    "objectID": "Deep-Learning.html#discussion-5",
    "href": "Deep-Learning.html#discussion-5",
    "title": "Deep Learning for Time Series",
    "section": "Discussion",
    "text": "Discussion\n\n\nThe Bidirectional LSTM with no regularization performs better than the Stacked GRU with L2 regularization, but worse than both the Bidirectional GRU and the GRU with L2 regularization. The train RMSE of this Bidirectional LSTM is 0.04 and test RMSE is 0.21. The LSTM model, which is more complex than the GRU, is likely overfitting the data. The GRU model with L2 regularization is the best model so far. Let’s see if we can improve the performance of the Bidirectional LSTM with L2 regularization by tuning the hyperparameters."
  },
  {
    "objectID": "Deep-Learning.html#train-model-and-visualize-performance-6",
    "href": "Deep-Learning.html#train-model-and-visualize-performance-6",
    "title": "Deep Learning for Time Series",
    "section": "Train Model and Visualize Performance",
    "text": "Train Model and Visualize Performance\n\n\nCode\n#TRAIN MODEL\nhistory = model.fit(\ntrainX, trainY, \nepochs=epochs, # how many times to go through the entire dataset\nbatch_size=int(f_batch*trainX.shape[0]), # 20% of training data as batch size\nvalidation_split=validation_split,  #use 20% of training data for validation\ncallbacks=[callback], #early stopping\nverbose=0) #suppress messages\n\n\n2023-05-03 18:18:10.156304: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:18:10.374416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:10.385925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:10.509926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:10.522608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n2023-05-03 18:18:11.327493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:11.396413: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n2023-05-03 18:18:11.404123: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n\n\n\nVisualize Fitting HistoryVisualize Parity Plot (Unnormalized Data)Visualize Predictions (Unnormalized Data)\n\n\n\n\n1/2 [==============>...............] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2/2 [==============================] - 1s 46ms/step\n\n\n1/1 [==============================] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 47ms/step\n\n\nTrain MSE = 0.00169 RMSE = 0.04113\nTest MSE = 0.05292 RMSE = 0.23004"
  },
  {
    "objectID": "Deep-Learning.html#discussion-6",
    "href": "Deep-Learning.html#discussion-6",
    "title": "Deep Learning for Time Series",
    "section": "Discussion",
    "text": "Discussion\n\n\nThe Bidirectional LSTM with L2 Regularization outputted a train RMSE of 0.04 and test RMSE is 0.23. It performs worse than Bidirectional LSTM without L2 Regularization and significantly worse than the Simple RNN with L2 Regularization and the GRU with L2 Regularization. Now, we can conclude that the GRU with L2 Regularization is the best performing model. But, will it be the best when predicting the number of attacks for the next 5 years instead of 2 years as seen above? Let’s find out."
  },
  {
    "objectID": "Deep-Learning.html#discussion-7",
    "href": "Deep-Learning.html#discussion-7",
    "title": "Deep Learning for Time Series",
    "section": "Discussion",
    "text": "Discussion\nWow, the LSTM model outputs the lowest RMSE when the size of the test set is increased! This is a very interesting result, and it is likely due to the fact that the LSTM model is better able to capture the seasonality of the data when testing for number of attacks after 2016. Therefore, when predicting more time steps in the future, the LSTM model is better able to generalize to unseen data and could be recommended for future use."
  },
  {
    "objectID": "Financial-Models.html#volatility-plots-for-arima-garch-models",
    "href": "Financial-Models.html#volatility-plots-for-arima-garch-models",
    "title": "Financial Time Series Models",
    "section": "Volatility Plots for ARIMA + GARCH Models",
    "text": "Volatility Plots for ARIMA + GARCH Models\nThese plots represent the estimated conditional variances of the ARIMA residuals obtained from the fitted sGARCH model. The y-axis shows the values of the estimated variances, while the x-axis represents the time period for which the variances were estimated.\n\nLockheed Martin (LMT)Raytheon Technologies (RTX)Dow Jones Travel and Tourism Index (DJUSTT)\n\n\n\n\nCode\nhhat <- (fit.lmt@fit$sigma^2)\nplot.ts(hhat, col=\"#005BAD\")\n\n\n\n\n\n\n\n\n\nCode\nhhat <- (fit.rtx@fit$sigma^2)\nplot.ts(hhat, col=\"#E61231\")\n\n\n\n\n\n\n\n\n\nCode\nhhat <- (fit.djustt@fit$sigma^2)\nplot.ts(hhat)\n\n\n\n\n\n\n\n\nLockheed Martin (LMT):\nThe volatility plot provides evidence that LMT’s stock price experienced relatively higher volatility in the following periods: end of 1998 to beginning of 2003, the beginning of the 2008 financial crisis, and the onset of the COVID-19 pandemic.\nRaytheon Technologies (RTX):\nThe volatility plot provides evidence that RTX’s stock price experienced relatively higher volatility in the following periods: end of 1987 to beginning of 1988 (signifying that the Black Monday stock market crash catalyzed RTX’s lowest stock price until 2019), quickly after the 9/11 attacks, the beginning of the 2008 financial crisis, and the onset of the COVID-19 pandemic. A key finding here is that military targets were highest in 1986 due to The Macheteros, a clandestine militant and insurgent organization based in Puerto Rico, claiming responsibility for bombing U.S. armed forces facilities. Coupled with this attack and Black Monday, the 1983 Kuwait bombings could also provide some explanation to RTX’s stock being high volatility around 1987 as their employees were targeted but none injured due to failed bombings.\nDow Jones Travel and Tourism Index (DJUSTT):\nThe volatility plot provides evidence that RTX’s stock price experienced relatively higher volatility in the following periods: President Trump’s Travel Ban in October 2017 and the onset of the COVID-19 pandemic. The index is fairly new new compared to the other 2 stocks and, hence, its higher volatility is warranted, especially due to the COVID-19 pandemic."
  },
  {
    "objectID": "Data-Sources.html#references",
    "href": "Data-Sources.html#references",
    "title": "Data Sources",
    "section": "References",
    "text": "References\n“Download the Global Terrorism Database.” Global Terrorism Database, 2001. https://www.start.umd.edu/gtd/contact/download.\n“SIPRI Military Expenditure Database.” SIPRI MILEX. STOCKHOLM INTERNATIONAL PEACE RESEARCH INSTITUTE, 1966. https://milex.sipri.org/sipri.\n“Nonimmigrant Admissions.” Nonimmigrant Admissions | Homeland Security. Department of Homeland Security, n.d. https://www.dhs.gov/immigration-statistics/nonimmigrant."
  },
  {
    "objectID": "Conclusion.html",
    "href": "Conclusion.html",
    "title": "Conclusions",
    "section": "",
    "text": "Data and its Complexity\nThe analysis relied on the Global Terrorism Database™ (GTD) (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.), a comprehensive dataset with over 136 fields. To ensure a thorough analysis, it was crucial to limit the data to a certain geographic location. There was no particular reason as to why the United States was chosen, even though a lot more attacks have taken place in other countries in the Middle East and Africa. Moreover, the GTD does not differentiate between domestic and international terrorism, which have different causes and characteristics, but for this project, both types were included under a single umbrella term: “terrorism”.\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\nTo use the GTD for time-series modeling, it had to be grouped into time periods, including months or years to count the number of attacks that occurred. However, this method led to many months where there were no attacks, and these “zero counts” made it harder to extract useful patterns in the data. However, there are specialized time-series models designed to handle this type of data.\nAnother challenge was that there was no information for the year 1993 in the GTD, but since the data was grouped into months or years, it was easier to fill in the missing information by using nearby data points. Furthermore, the auxilary datasets used in the analysis, like Raytheon Technologies’ stock price and Non-Immigrant Entrants, did not have information for the early 1970s and 1980s, which required filling in missing values to create more accurate multivariate models.\nThe GTD, admirably, also provides information about the type of attack, the type of weapon used by the perpetrator(s), and the type of victim affected by the attack. Although more data is desired for projects, it can be overwhelming trying to incorporate them to make the analysis as multi-faceted as possible. There exist multifarious combinations of models, differing by the aforementioned categorical variables, location, etc., that no one model can be the “ultimate” in explaining all these facets. Therefore, building as many models as possible would get us closer in extracting patterns and trends in the number of yearly attacks, but it can also be a double-edged sword. Essentially, the goal should be to create a parsimonious and interpretable model. This may require a trade-off between model complexity and predictive accuracy, but careful model selection and evaluation can help to strike a balance between these competing objectives.\nLastly, another key variable that could have been discussed alongside the number of attacks is the number of casualties resulting from the attacks. Again, this data, when aggregated, produced even more zero counts because nearly 80% of all terrorist attacks involved no casualties between 1970 and 2013 (“Terrorist Attacks in the u.s Between 1970 and 2013: Data from the ... - DHS,” n.d.). Initially, this variable was supposed to be the key target variable for multivariate analysis; however, upon conducting the literature review it was better to predict number of attacks, instead.\n\n“Terrorist Attacks in the u.s Between 1970 and 2013: Data from the ... - DHS.” n.d. Terrorist Attacks in the U.S Between 1970 and 2013: Data from the Global Terrorism Database (GTD). START Consortium at the University of Maryland. https://www.dhs.gov/sites/default/files/publications/OPSR_TP_TEVUS_Terrorist-Attacks-US_1970-2013_Overview-508.pdf.\n\n\nResults and Future Work\nIt was found that the SARIMA model and Deep Recurrent Neural Networks performed best in predicting the monthly number of terrorist attacks in the US. Yearly aggregated terrorist attacks were analyzed for the VAR and ARIMAX models because the auxiliary data did not have figures at the monthly level. For such models, especially Recurrent Neural Networks, it is best to input big data to obtain even more plausible predictions. Nonetheless, it was found through the how far can we predict with Recurrent Neural Networks section that the simpler the task, the simpler the model should be.\nAs mentioned in the above section that a major chunk of the monthly aggregated data contained zero’s, models such as Zero-Inflated Poisson Regression could be employed for future analysis. If this model yields more accurate predictions than the Recurrent Neural Networks, the popular saying by George Box, “All models are wrong, but some are useful”, would be a testament to the importance of using models that are directly related to the domain and question being addressed, rather than simply feeding the data into a neural network and hoping for the best.\n\n\nAll Cited Works (Alphabetical Order)\nBaker , David. “The Effects of Terrorism on the Travel and Tourism Industry .” Technological University Dublin. International Journal of Religious Tourism and Pilgrimage. Accessed February 1, 2023. https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1052&context=ijrtp.\n“Codebook Methodology Inclusion Criteria and Ariables - UMD.” Codebook Methodology Inclusion criteria and variables - UMD. University of Maryland. Accessed February 1, 2023. https://www.start.umd.edu/gtd/downloads/Codebook.pdf. “Download the Global Terrorism Database.” Global Terrorism Database. University of Maryland, National Consortium for the Study of Terrorism and Responses to Terrorism, 2001. https://www.start.umd.edu/gtd/contact/download.\nHartung, William D. “Profits of War: Corporate Beneficiaries of the Post-9/11 Pentagon Spending Surge.” Costs of War. Watson Institute for International and Public Affairs, Brown University, September 13, 2021. https://watson.brown.edu/costsofwar/files/cow/imce/papers/2021/Profits%20of%20War_Hartung_ Costs%20of%20War_Sept%2013%2C%202021.pdf.\n“Nonimmigrant Admissions.” Nonimmigrant Admissions | Homeland Security. Department of Homeland Security, n.d. https://www.dhs.gov/immigration-statistics/nonimmigrant.\nNowrasteh, Alex. “Terrorists by Immigration Status and Nationality: A Risk Analysis, 1975–2017.” Cato.org. Cato Institute, May 27, 2019. https://www.cato.org/publications/policy-analysis/terrorists-immigration-status-nationality-risk-analysis-1975-2017#foreign-born-terrorism-risk-for-visas-issued-by-category.\nRosenau, William. “Leftist Terrorism in the United States.” Taylor & Francis. The Journal of Strategic Studies (2013). Accessed February 12, 2023. https://www.tandfonline.com/journals/fjss20.\nSerrano, Richard A. “The 1970s Bombing Spree.” Los Angeles Times. May 19, 2008.\n“SIPRI Military Expenditure Database.” SIPRI MILEX. STOCKHOLM INTERNATIONAL PEACE RESEARCH INSTITUTE, 1966. https://milex.sipri.org/sipri.\n“Terrorist Attacks in the U.S between 1970 and 2013: Data from the … - DHS.” Terrorist Attacks in the U.S Between 1970 and 2013: Data from the Global Terrorism Database (GTD). START Consortium at the University of Maryland. Accessed February 12, 2023. https://www.dhs.gov/sites/default/files/publications/OPSR_TP_TEVUS_Terrorist-Attacks-US_1970-2013_Overview-508.pdf.\n“World Tourism Organization.” UNWTO. Accessed February 1, 2023. https://www.unwto.org/."
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#methodology",
    "href": "ARIMAX-SARIMAX-VAR.html#methodology",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Methodology",
    "text": "Methodology\nGiven the discussed Literature Review above, we shall divide our analysis into two segments, with VAR and ARIMAX models applied to both. The first segment shall forecast the number of terrorist attacks in the US using all the data available, from 1970-2020, and the second segment shall forecast the number of terrorist attacks in the US using only Post-9/11 attacks data, from 2001-2020. The reason 2001 is included is to ensure that the analysis captures the full impact of the 9/11 attacks, immediately before and after it, on terrorist activity in the US.\nAnother important differentiator between both VAR models and ARIMAX models is that only the ARIMAX models shall account for all variables collected for the project, including Non-Immigrant Entrants data from the Department of Homeland Security. This is because, as per the literature review, tourism, which is generalized to foreign-born terrorists in this analysis, does not seem to have a significant impact on the likelihood of terrorist attacks on U.S. soil, compared to overall US Military Expenditure. Therefore, this section will help us prove whether the non-immigration variables have a significant effect on the yearly number of terrorist attacks in the US.\nFollowing graphs shall help make sense of the roadmap that follows in this analysis:\n\n\n \n\nMultivariate Analysis (VAR and ARIMAX) Segment 1 Flow Chart\n\n\n \n\n\n \n\nMultivariate Analysis (VAR and ARIMAX) Segment 2 Flow Chart"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#building-the-var-model-1970-2020-pre-and-post-911-attacks",
    "href": "ARIMAX-SARIMAX-VAR.html#building-the-var-model-1970-2020-pre-and-post-911-attacks",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Building the VAR Model (1970-2020: Pre and Post-9/11 Attacks)",
    "text": "Building the VAR Model (1970-2020: Pre and Post-9/11 Attacks)\n\nTime Series Plots\n\n\nCode\nplot.ts(var_ts , main = \"\", xlab = \"\")\n\n\n\n\n\n\n\nPair Plots\n\n\nCode\n# create scatterplot matrix using plotly\nfig <- plot_ly(\n  data = as.data.frame(var_ts),\n  type = \"splom\",\n  diagonal = list(visible = FALSE),\n  dimensions = list(\n    list(label = \"# Attacks\", values = ~num_attacks),\n    list(label = \"B-2 Visa\", values = ~Pleasure),\n    list(label = \"B-1 Visa\", values = ~Business),\n    list(label = \"F-1 Visa\", values = ~Students),\n    list(label = \"Military Exp\", values = ~milexp.gdp),\n    list(label = \"RTX\", values = ~RTX)\n  )\n) %>%\n  layout(hovermode = \"x\")\n\n\n\n# customize layout\nfig <- fig %>% \n  layout(\n    title = \"Scatterplot Matrix of VAR Model Variables (Pre and Post-9/11)\",\n    xaxis = list(title = \"\"),\n    yaxis = list(title = \"\")\n  )\n\n# display plot\nfig\n\n\n\n\n\n\n\n\nCode\n#gtd_dhs_sipri_rtx <- subset(gtd_dhs_sipri_rtx, select=-c(Business, Pleasure, Students))\n\n# convert df back to matrix\n\nts_matrix <- as.matrix(gtd_dhs_sipri_rtx[, 3:5])\n\n# convert the matrix to a time series object with a yearly frequency\nvar_ts <- ts(ts_matrix, frequency = 1,\n                 start = 1970)\n\n# split into train and test sets\n\nset.seed(29830)\ntrain_idx <- sample(nrow(var_ts), 0.9 * nrow(var_ts))\ntrain <- var_ts[train_idx, ]\ntest <- var_ts[-train_idx, ]\n\n# Fit Lasso regression model with cross-validation\n# cv_fit <- cv.glmnet(train[, 2], train[, 1], alpha = 1)\n# \n# # Extract selected variables\n# cv_fits <- as.data.frame(as.matrix(coef(cv_fit)))\n# to_include <- rownames(cv_fits)[cv_fits$s1 != 0]\n\n\n\n\nFitting VAR Model\nHere we use the VARselect() function to find the best p to fit VAR(p). We will choose a maximum lag of 10 and check which p value returns lowest AIC.\n\n\nCode\n(var_result <- VARselect(var_ts, lag.max = 10, type = \"both\"))\n\n\n$selection\nAIC(n)  HQ(n)  SC(n) FPE(n) \n    10     10      1     10 \n\n$criteria\n                  1            2            3            4            5\nAIC(n) 6.218555e+01 6.221758e+01 6.247328e+01 6.263055e+01 6.268341e+01\nHQ(n)  6.241384e+01 6.258284e+01 6.297552e+01 6.326976e+01 6.345959e+01\nSC(n)  6.281247e+01 6.322065e+01 6.385250e+01 6.438592e+01 6.481493e+01\nFPE(n) 1.019603e+27 1.065015e+27 1.410394e+27 1.727137e+27 1.960066e+27\n                  6            7            8            9           10\nAIC(n) 6.243987e+01 6.271077e+01 6.289237e+01 6.233062e+01 6.031548e+01\nHQ(n)  6.335303e+01 6.376089e+01 6.407947e+01 6.365469e+01 6.177652e+01\nSC(n)  6.494754e+01 6.559458e+01 6.615234e+01 6.596673e+01 6.432774e+01\nFPE(n) 1.719961e+27 2.666183e+27 4.086231e+27 3.345728e+27 7.729491e+26\n\n\nNow, we will fit VAR(1), VAR(2), and VAR(3):\nVAR(1) output:\n\n\nCode\nsummary(fit <- VAR(var_ts, p=1, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_attacks, Pleasure, Business \nDeterministic variables: both \nSample size: 50 \nLog Likelihood: -1772.497 \nRoots of the characteristic polynomial:\n0.8827 0.5279 0.2543\nCall:\nVAR(y = var_ts, p = 1, type = \"both\")\n\n\nEstimation results for equation num_attacks: \n============================================ \nnum_attacks = num_attacks.l1 + Pleasure.l1 + Business.l1 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)    \nnum_attacks.l1  3.087e-01  5.832e-02   5.294 3.44e-06 ***\nPleasure.l1     8.347e-07  5.901e-07   1.415 0.164038    \nBusiness.l1     1.238e-05  7.894e-06   1.568 0.123817    \nconst           6.014e+01  1.069e+01   5.625 1.12e-06 ***\ntrend          -3.400e+00  9.520e-01  -3.571 0.000861 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 20.62 on 45 degrees of freedom\nMultiple R-Squared: 0.7746, Adjusted R-squared: 0.7545 \nF-statistic: 38.66 on 4 and 45 DF,  p-value: 5.101e-14 \n\n\nEstimation results for equation Pleasure: \n========================================= \nPleasure = num_attacks.l1 + Pleasure.l1 + Business.l1 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)    \nnum_attacks.l1  7.069e+03  1.681e+04   0.421   0.6760    \nPleasure.l1     1.027e+00  1.700e-01   6.039 2.73e-07 ***\nBusiness.l1    -3.886e+00  2.275e+00  -1.708   0.0945 .  \nconst          -1.624e+06  3.081e+06  -0.527   0.6007    \ntrend           5.757e+05  2.744e+05   2.098   0.0415 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 5941000 on 45 degrees of freedom\nMultiple R-Squared: 0.8944, Adjusted R-squared: 0.885 \nF-statistic: 95.26 on 4 and 45 DF,  p-value: < 2.2e-16 \n\n\nEstimation results for equation Business: \n========================================= \nBusiness = num_attacks.l1 + Pleasure.l1 + Business.l1 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)  \nnum_attacks.l1  7.075e+02  2.103e+03   0.336   0.7381  \nPleasure.l1     2.125e-02  2.128e-02   0.999   0.3232  \nBusiness.l1     3.292e-01  2.847e-01   1.157   0.2535  \nconst          -8.672e+04  3.855e+05  -0.225   0.8230  \ntrend           7.894e+04  3.433e+04   2.299   0.0262 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 743400 on 45 degrees of freedom\nMultiple R-Squared: 0.9077, Adjusted R-squared: 0.8995 \nF-statistic: 110.6 on 4 and 45 DF,  p-value: < 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n            num_attacks   Pleasure   Business\nnum_attacks         425 -1.755e+07 -2.952e+06\nPleasure      -17552819  3.530e+13  3.916e+12\nBusiness       -2952322  3.916e+12  5.527e+11\n\nCorrelation matrix of residuals:\n            num_attacks Pleasure Business\nnum_attacks      1.0000  -0.1433  -0.1926\nPleasure        -0.1433   1.0000   0.8865\nBusiness        -0.1926   0.8865   1.0000\n\n\nVAR(2) output:\n\n\nCode\nsummary(fit <- VAR(var_ts, p=2, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_attacks, Pleasure, Business \nDeterministic variables: both \nSample size: 49 \nLog Likelihood: -1719.76 \nRoots of the characteristic polynomial:\n0.8629 0.7233 0.7233 0.4716 0.4716 0.03415\nCall:\nVAR(y = var_ts, p = 2, type = \"both\")\n\n\nEstimation results for equation num_attacks: \n============================================ \nnum_attacks = num_attacks.l1 + Pleasure.l1 + Business.l1 + num_attacks.l2 + Pleasure.l2 + Business.l2 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)    \nnum_attacks.l1  2.669e-01  1.141e-01   2.338 0.024333 *  \nPleasure.l1     1.513e-07  8.588e-07   0.176 0.861004    \nBusiness.l1     6.099e-06  8.841e-06   0.690 0.494203    \nnum_attacks.l2 -2.348e-01  5.596e-02  -4.196 0.000142 ***\nPleasure.l2     1.114e-06  9.178e-07   1.214 0.231616    \nBusiness.l2     1.446e-05  8.930e-06   1.619 0.113127    \nconst           9.813e+01  1.136e+01   8.642 8.86e-11 ***\ntrend          -5.585e+00  8.663e-01  -6.447 1.00e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 15.33 on 41 degrees of freedom\nMultiple R-Squared: 0.7942, Adjusted R-squared: 0.7591 \nF-statistic:  22.6 on 7 and 41 DF,  p-value: 3.428e-12 \n\n\nEstimation results for equation Pleasure: \n========================================= \nPleasure = num_attacks.l1 + Pleasure.l1 + Business.l1 + num_attacks.l2 + Pleasure.l2 + Business.l2 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)   \nnum_attacks.l1 -1.154e+04  4.545e+04  -0.254  0.80090   \nPleasure.l1     1.086e+00  3.419e-01   3.175  0.00284 **\nBusiness.l1    -1.374e+00  3.520e+00  -0.390  0.69825   \nnum_attacks.l2  1.184e+04  2.228e+04   0.531  0.59808   \nPleasure.l2    -5.633e-02  3.654e-01  -0.154  0.87827   \nBusiness.l2    -2.950e+00  3.556e+00  -0.830  0.41156   \nconst          -1.615e+06  4.521e+06  -0.357  0.72284   \ntrend           6.223e+05  3.449e+05   1.804  0.07856 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 6103000 on 41 degrees of freedom\nMultiple R-Squared: 0.8972, Adjusted R-squared: 0.8797 \nF-statistic: 51.13 on 7 and 41 DF,  p-value: < 2.2e-16 \n\n\nEstimation results for equation Business: \n========================================= \nBusiness = num_attacks.l1 + Pleasure.l1 + Business.l1 + num_attacks.l2 + Pleasure.l2 + Business.l2 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)  \nnum_attacks.l1 -4.733e+02  5.638e+03  -0.084   0.9335  \nPleasure.l1     2.071e-02  4.242e-02   0.488   0.6279  \nBusiness.l1     7.792e-01  4.367e-01   1.784   0.0818 .\nnum_attacks.l2  1.007e+03  2.764e+03   0.364   0.7175  \nPleasure.l2     1.762e-03  4.534e-02   0.039   0.9692  \nBusiness.l2    -5.502e-01  4.411e-01  -1.247   0.2194  \nconst          -1.522e+05  5.609e+05  -0.271   0.7875  \ntrend           9.085e+04  4.279e+04   2.123   0.0398 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 757100 on 41 degrees of freedom\nMultiple R-Squared: 0.9105, Adjusted R-squared: 0.8952 \nF-statistic: 59.57 on 7 and 41 DF,  p-value: < 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n            num_attacks   Pleasure   Business\nnum_attacks   2.349e+02 -1.161e+07 -2.274e+06\nPleasure     -1.161e+07  3.725e+13  4.082e+12\nBusiness     -2.274e+06  4.082e+12  5.732e+11\n\nCorrelation matrix of residuals:\n            num_attacks Pleasure Business\nnum_attacks      1.0000  -0.1242  -0.1960\nPleasure        -0.1242   1.0000   0.8834\nBusiness        -0.1960   0.8834   1.0000\n\n\nVAR(3) output:\n\n\nCode\nsummary(fit <- VAR(var_ts, p=3, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_attacks, Pleasure, Business \nDeterministic variables: both \nSample size: 48 \nLog Likelihood: -1677.209 \nRoots of the characteristic polynomial:\n0.9075 0.8361 0.8361 0.6494 0.5669 0.5669 0.4691 0.4691 0.1478\nCall:\nVAR(y = var_ts, p = 3, type = \"both\")\n\n\nEstimation results for equation num_attacks: \n============================================ \nnum_attacks = num_attacks.l1 + Pleasure.l1 + Business.l1 + num_attacks.l2 + Pleasure.l2 + Business.l2 + num_attacks.l3 + Pleasure.l3 + Business.l3 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)    \nnum_attacks.l1  3.398e-02  1.467e-01   0.232   0.8181    \nPleasure.l1     5.179e-07  7.826e-07   0.662   0.5122    \nBusiness.l1     7.377e-06  8.045e-06   0.917   0.3651    \nnum_attacks.l2  8.679e-02  1.103e-01   0.787   0.4364    \nPleasure.l2     5.680e-07  1.068e-06   0.532   0.5979    \nBusiness.l2     1.079e-05  1.039e-05   1.038   0.3060    \nnum_attacks.l3 -2.066e-01  6.179e-02  -3.343   0.0019 ** \nPleasure.l3     2.518e-07  8.479e-07   0.297   0.7682    \nBusiness.l3     1.001e-05  8.376e-06   1.195   0.2396    \nconst           1.190e+02  1.888e+01   6.302 2.45e-07 ***\ntrend          -7.099e+00  1.179e+00  -6.020 5.91e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 13.74 on 37 degrees of freedom\nMultiple R-Squared:  0.85,  Adjusted R-squared: 0.8094 \nF-statistic: 20.96 on 10 and 37 DF,  p-value: 2.511e-12 \n\n\nEstimation results for equation Pleasure: \n========================================= \nPleasure = num_attacks.l1 + Pleasure.l1 + Business.l1 + num_attacks.l2 + Pleasure.l2 + Business.l2 + num_attacks.l3 + Pleasure.l3 + Business.l3 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)   \nnum_attacks.l1 -3.438e+04  6.741e+04  -0.510  0.61304   \nPleasure.l1     1.084e+00  3.595e-01   3.014  0.00464 **\nBusiness.l1    -1.803e+00  3.696e+00  -0.488  0.62850   \nnum_attacks.l2 -1.503e+04  5.067e+04  -0.297  0.76846   \nPleasure.l2    -2.556e-01  4.904e-01  -0.521  0.60541   \nBusiness.l2    -2.352e+00  4.773e+00  -0.493  0.62507   \nnum_attacks.l3  4.440e+03  2.839e+04   0.156  0.87656   \nPleasure.l3     3.296e-01  3.895e-01   0.846  0.40291   \nBusiness.l3    -3.226e-01  3.848e+00  -0.084  0.93364   \nconst           2.443e+06  8.674e+06   0.282  0.77980   \ntrend           4.864e+05  5.418e+05   0.898  0.37513   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 6311000 on 37 degrees of freedom\nMultiple R-Squared: 0.8995, Adjusted R-squared: 0.8724 \nF-statistic: 33.12 on 10 and 37 DF,  p-value: 1.864e-15 \n\n\nEstimation results for equation Business: \n========================================= \nBusiness = num_attacks.l1 + Pleasure.l1 + Business.l1 + num_attacks.l2 + Pleasure.l2 + Business.l2 + num_attacks.l3 + Pleasure.l3 + Business.l3 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)\nnum_attacks.l1 -7.995e+02  8.425e+03  -0.095    0.925\nPleasure.l1     1.900e-02  4.493e-02   0.423    0.675\nBusiness.l1     7.341e-01  4.618e-01   1.590    0.120\nnum_attacks.l2 -2.755e+03  6.332e+03  -0.435    0.666\nPleasure.l2    -1.137e-02  6.129e-02  -0.186    0.854\nBusiness.l2    -4.329e-01  5.965e-01  -0.726    0.473\nnum_attacks.l3  1.477e+03  3.548e+03   0.416    0.680\nPleasure.l3     2.425e-02  4.868e-02   0.498    0.621\nBusiness.l3    -1.421e-01  4.809e-01  -0.296    0.769\nconst           1.754e+04  1.084e+06   0.016    0.987\ntrend           9.116e+04  6.771e+04   1.346    0.186\n\n\nResidual standard error: 788700 on 37 degrees of freedom\nMultiple R-Squared: 0.9098, Adjusted R-squared: 0.8855 \nF-statistic: 37.34 on 10 and 37 DF,  p-value: 2.617e-16 \n\n\n\nCovariance matrix of residuals:\n            num_attacks   Pleasure   Business\nnum_attacks   1.887e+02 -1.040e+07 -1.886e+06\nPleasure     -1.040e+07  3.983e+13  4.403e+12\nBusiness     -1.886e+06  4.403e+12  6.221e+11\n\nCorrelation matrix of residuals:\n            num_attacks Pleasure Business\nnum_attacks      1.0000  -0.1199  -0.1741\nPleasure        -0.1199   1.0000   0.8845\nBusiness        -0.1741   0.8845   1.0000\n\n\n\n\nK-Fold Cross Validation and Model Diagnostics\n\n\nCode\n# Define the number of folds for cross-validation\nk <- 5\n\n# Define the p values to test\np_values <- c(1, 2, 3)\n\n# Split the data into k folds\ncv_folds <- cut(seq(1, nrow(var_ts)), breaks = k, labels = FALSE)\n\n# Initialize vectors to store RMSE and AIC values for each p value\nrmse_vec <- numeric(length(p_values))\naic_vec <- numeric(length(p_values))\n\n# Loop over p values and perform cross-validation\nfor (i in seq_along(p_values)) {\n  p <- p_values[i]\n  rmse_cv <- numeric(k)\n  aic_cv <- numeric(k)\n  for (j in 1:k) {\n    # Split the data into training and testing sets\n    train <- var_ts[cv_folds != j, ]\n    test <- var_ts[cv_folds == j, ]\n    \n    # Fit the VAR model with the current p value\n    var_fit <- VAR(train, p = p)\n    \n    # Make predictions for the testing set\n    pred <- predict(var_fit, n.ahead = nrow(test))$fcst\n    \n    # Calculate RMSE and AIC for the current fold\n    rmse_cv[j] <- sqrt(mean((pred$num_attacks - test[,1])^2))\n    aic_cv[j] <- AIC(var_fit)\n  }\n  # Calculate the mean RMSE and AIC across all folds for the current p value\n  rmse_vec[i] <- mean(rmse_cv)\n  aic_vec[i] <- mean(aic_cv)\n}\n\n# Create a table of RMSE and AIC values for each p value\nresults_table <- tibble(p_values, rmse_vec, aic_vec)\n\n# Print the results table\nkable(results_table, format = \"markdown\", \n        col.names = c(\"P Values\", \"Mean RMSE (5 Folds)\", \"Mean AIC (5 Folds)\"), align = \"c\", digits = 2\n        )\n\n\n\n\n\nP Values\nMean RMSE (5 Folds)\nMean AIC (5 Folds)\n\n\n\n\n1\n69.41\n2839.88\n\n\n2\n95.77\n2768.59\n\n\n3\n90.21\n2702.07\n\n\n\n\n\nThe VAR(1) model outputs the lowest Mean RMSE of 69.405026 attacks from the 5-fold cross validation. However, it has the highest AIC score. Because test set performance is best and it is the simplest model, we shall choose the VAR(1) model as the best option.\n\n\nForecasting Chosen Model (p=1)\n\n\nCode\nfinal_var <- VAR(var_ts, p = 1)\n\n(fit.pr = predict(final_var, n.ahead = 5, ci = 0.95)) # 5 years ahead \n\n\n$num_attacks\n         fcst      lower    upper       CI\n[1,] 74.99198 29.7166120 120.2674 45.27537\n[2,] 62.51771 12.3013333 112.7341 50.21637\n[3,] 56.71276  4.5370981 108.8884 52.17566\n[4,] 53.80558  0.3106907 107.3005 53.49489\n[5,] 52.18705 -2.3286201 106.7027 54.51567\n\n$Pleasure\n         fcst    lower    upper       CI\n[1,] 28008600 15940797 40076403 12067803\n[2,] 27732679 11205503 44259856 16527177\n[3,] 27655150  8102498 47207803 19552652\n[4,] 27668361  5880296 49456426 21788065\n[5,] 27724860  4218078 51231642 23506782\n\n$Business\n        fcst   lower   upper      CI\n[1,] 4142849 2619394 5666304 1523455\n[2,] 4141639 2055830 6227448 2085809\n[3,] 4166222 1698565 6633879 2467657\n[4,] 4200017 1450247 6949786 2749770\n[5,] 4236079 1269647 7202511 2966432\n\n\nCode\nfanchart(fit.pr) # plot prediction + error\n\n\n\n\n\nThe above plot showcases the forecasts for each variable present in the VAR(1) model, Number of Yearly Attacks, US Military Expenditure as a % of US GDP, and Closing Price of Raytheon Technologies Stock. The predicted forecast, from the years 2021 to 2025, for Number of Yearly Attacks is a good sign for the US due to the decreasing and plateauing trend, although the actual observations from 2015 onward suggest an increasing trend. The same forecast trend is discerned for US Military Expenditure as a % of US GDP, with Raytheon Technologies Stock being the only variable with a predicted increasing trend.\nLet us visualize more closely the forecasts for the Number of Yearly Attacks from 2021 to 2025, corresponding to the VAR(1) model fitted on all years (1970-2020):\n\n\nCode\n# create df of attack forecasts\ndf_fvar_attack <- as.data.frame(fit.pr$fcst$num_attacks)\n# add year column\ndf_fvar_attack$Year <- c(\"2021\", \"2022\", \"2023\", \"2024\", \"2025\")\n(var_plot <- ggplot(data=df_fvar_attack, aes(x=Year, y=fcst, group = 1)) +\n    geom_line(aes(color=\"Forecast\"), linewidth=1) +\n    geom_ribbon(aes(ymin=lower, ymax=upper, fill=\"Confidence Interval\"), alpha=0.1) +\n    labs(title=\"VAR(1) Forecasts for Number of Yearly Attacks from 2021 to 2025\",\n         y=\"Number of Terrorist Attacks\",\n         color=\"\", fill=\"\",\n         caption=\"Data Sources: Global Terrorism Database, SIPRI Military Expenditure Database, Yahoo Finance\") +\n    scale_color_manual(values = c(\"Forecast\"=\"red\")) +\n    scale_fill_manual(values = c(\"95% Confidence Interval\"=\"steelblue\")) +\n    theme_minimal() + \n  theme(plot.caption.position = \"plot\"))\n\n\n\n\n\nCode\n#ggplotly(var_plot)"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#building-the-var-model-2001-2020-post-911-attacks",
    "href": "ARIMAX-SARIMAX-VAR.html#building-the-var-model-2001-2020-post-911-attacks",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Building the VAR Model (2001-2020: Post-9/11 Attacks)",
    "text": "Building the VAR Model (2001-2020: Post-9/11 Attacks)\n\nTime Series Plots\n\n\nCode\nplot.ts(var_ts , main = \"\", xlab = \"\")\n\n\n\n\n\n\n\nPair Plots\n\n\nCode\n# create scatterplot matrix using plotly\nfig <- plot_ly(\n  data = as.data.frame(var_ts), \n  type = \"splom\",\n  diagonal = list(visible = FALSE),\n  dimensions = list(\n    list(label = \"# Attacks\", values = ~num_attacks),\n    list(label = \"Military Exp\", values = ~milexp.gdp),\n    list(label = \"RTX\", values = ~RTX),\n    list(label = \"LMT\", values = ~LMT)\n  )\n) %>%\n  layout(hovermode = \"x\")\n\nfig <- fig %>% \n  layout(\n    title = \"Scatterplot Matrix of VAR Model Variables (Post-9/11)\",\n    xaxis = list(title = \"\"),\n    yaxis = list(title = \"\")\n  )\n\n# display plot\nfig\n\n\n\n\n\n\n\n\nFitting VAR Model\nHere we use the VARselect() function to find the best p to fit VAR(p). We will choose a maximum lag of 10 and check which p value returns lowest AIC.\n\n\nCode\n(var_result <- VARselect(var_ts, lag.max = 10, type = \"both\"))\n\n\n$selection\nAIC(n)  HQ(n)  SC(n) FPE(n) \n     2      2      2      3 \n\n$criteria\n                1    2    3    4    5    6    7    8    9   10\nAIC(n) -2.0240567 -Inf -Inf -Inf -Inf -Inf -Inf -Inf -Inf -Inf\nHQ(n)  -2.8207010 -Inf -Inf -Inf -Inf -Inf -Inf -Inf -Inf -Inf\nSC(n)  -1.2978525 -Inf -Inf -Inf -Inf -Inf -Inf -Inf -Inf -Inf\nFPE(n)  0.2783491  NaN    0    0    0    0    0    0    0    0\n\n\nNow, we will fit VAR(1), VAR(2), and VAR(3):\nVAR(1) output:\n\n\nCode\nsummary(fit <- VAR(var_ts, p=1, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_attacks, milexp.gdp, RTX, LMT \nDeterministic variables: both \nSample size: 19 \nLog Likelihood: -88.384 \nRoots of the characteristic polynomial:\n0.9729 0.9729 0.294 0.294\nCall:\nVAR(y = var_ts, p = 1, type = \"both\")\n\n\nEstimation results for equation num_attacks: \n============================================ \nnum_attacks = num_attacks.l1 + milexp.gdp.l1 + RTX.l1 + LMT.l1 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)   \nnum_attacks.l1  1.595e-02  2.081e-01   0.077  0.94006   \nmilexp.gdp.l1  -1.081e+03  6.258e+02  -1.728  0.10764   \nRTX.l1         -7.065e-01  4.474e-01  -1.579  0.13830   \nLMT.l1          3.208e-01  9.775e-02   3.282  0.00595 **\nconst           5.678e+01  2.649e+01   2.144  0.05155 . \ntrend           1.292e+00  1.110e+00   1.164  0.26544   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 7.386 on 13 degrees of freedom\nMultiple R-Squared: 0.9508, Adjusted R-squared: 0.9319 \nF-statistic: 50.28 on 5 and 13 DF,  p-value: 4.759e-08 \n\n\nEstimation results for equation milexp.gdp: \n=========================================== \nmilexp.gdp = num_attacks.l1 + milexp.gdp.l1 + RTX.l1 + LMT.l1 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)    \nnum_attacks.l1 -1.634e-05  4.514e-05  -0.362  0.72313    \nmilexp.gdp.l1   1.173e+00  1.357e-01   8.642 9.51e-07 ***\nRTX.l1         -2.367e-04  9.703e-05  -2.439  0.02982 *  \nLMT.l1          7.978e-05  2.120e-05   3.763  0.00237 ** \nconst           8.974e-05  5.745e-03   0.016  0.98777    \ntrend          -4.702e-04  2.407e-04  -1.953  0.07269 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.001602 on 13 degrees of freedom\nMultiple R-Squared: 0.9358, Adjusted R-squared: 0.9111 \nF-statistic: 37.88 on 5 and 13 DF,  p-value: 2.647e-07 \n\n\nEstimation results for equation RTX: \n==================================== \nRTX = num_attacks.l1 + milexp.gdp.l1 + RTX.l1 + LMT.l1 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)   \nnum_attacks.l1    0.15927    0.20253   0.786  0.44574   \nmilexp.gdp.l1  -237.75839  609.01209  -0.390  0.70256   \nRTX.l1            0.25639    0.43534   0.589  0.56599   \nLMT.l1           -0.09915    0.09512  -1.042  0.31625   \nconst             9.74921   25.77580   0.378  0.71136   \ntrend             3.40135    1.08011   3.149  0.00769 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 7.187 on 13 degrees of freedom\nMultiple R-Squared: 0.901,  Adjusted R-squared: 0.8629 \nF-statistic: 23.66 on 5 and 13 DF,  p-value: 4.196e-06 \n\n\nEstimation results for equation LMT: \n==================================== \nLMT = num_attacks.l1 + milexp.gdp.l1 + RTX.l1 + LMT.l1 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)  \nnum_attacks.l1     0.6765     0.7228   0.936   0.3664  \nmilexp.gdp.l1  -2954.0609  2173.5495  -1.359   0.1972  \nRTX.l1             0.6736     1.5537   0.434   0.6717  \nLMT.l1             0.2730     0.3395   0.804   0.4357  \nconst             71.2470    91.9932   0.774   0.4525  \ntrend              8.2020     3.8549   2.128   0.0531 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 25.65 on 13 degrees of freedom\nMultiple R-Squared: 0.9554, Adjusted R-squared: 0.9382 \nF-statistic: 55.66 on 5 and 13 DF,  p-value: 2.549e-08 \n\n\n\nCovariance matrix of residuals:\n            num_attacks milexp.gdp        RTX        LMT\nnum_attacks    54.55375 -2.410e-03 -14.602532 -62.659293\nmilexp.gdp     -0.00241  2.566e-06  -0.002115  -0.001013\nRTX           -14.60253 -2.115e-03  51.659371 167.723297\nLMT           -62.65929 -1.013e-03 167.723297 658.015878\n\nCorrelation matrix of residuals:\n            num_attacks milexp.gdp     RTX      LMT\nnum_attacks      1.0000   -0.20366 -0.2751 -0.33072\nmilexp.gdp      -0.2037    1.00000 -0.1837 -0.02465\nRTX             -0.2751   -0.18367  1.0000  0.90971\nLMT             -0.3307   -0.02465  0.9097  1.00000\n\n\nVAR(2) output:\n\n\nCode\nsummary(fit <- VAR(var_ts, p=2, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_attacks, milexp.gdp, RTX, LMT \nDeterministic variables: both \nSample size: 18 \nLog Likelihood: -53.372 \nRoots of the characteristic polynomial:\n 1.02 1.006 1.006 0.9265 0.7296 0.7296 0.7047 0.7047\nCall:\nVAR(y = var_ts, p = 2, type = \"both\")\n\n\nEstimation results for equation num_attacks: \n============================================ \nnum_attacks = num_attacks.l1 + milexp.gdp.l1 + RTX.l1 + LMT.l1 + num_attacks.l2 + milexp.gdp.l2 + RTX.l2 + LMT.l2 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)  \nnum_attacks.l1 -2.451e-01  2.616e-01  -0.937   0.3762  \nmilexp.gdp.l1  -5.577e+02  1.109e+03  -0.503   0.6287  \nRTX.l1         -1.690e+00  6.322e-01  -2.673   0.0282 *\nLMT.l1          5.662e-01  1.757e-01   3.223   0.0122 *\nnum_attacks.l2  3.234e-01  1.772e-01   1.825   0.1055  \nmilexp.gdp.l2  -1.465e+03  1.851e+03  -0.791   0.4516  \nRTX.l2          5.994e-02  5.480e-01   0.109   0.9156  \nLMT.l2         -5.252e-01  2.400e-01  -2.188   0.0601 .\nconst           8.362e+01  4.723e+01   1.770   0.1146  \ntrend           7.212e+00  3.296e+00   2.188   0.0601 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 5.75 on 8 degrees of freedom\nMultiple R-Squared: 0.9817, Adjusted R-squared: 0.961 \nF-statistic: 47.57 on 9 and 8 DF,  p-value: 5.404e-06 \n\n\nEstimation results for equation milexp.gdp: \n=========================================== \nmilexp.gdp = num_attacks.l1 + milexp.gdp.l1 + RTX.l1 + LMT.l1 + num_attacks.l2 + milexp.gdp.l2 + RTX.l2 + LMT.l2 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)    \nnum_attacks.l1 -5.792e-05  6.941e-05  -0.835 0.428209    \nmilexp.gdp.l1   1.632e+00  2.943e-01   5.546 0.000544 ***\nRTX.l1          1.623e-05  1.677e-04   0.097 0.925293    \nLMT.l1          7.586e-06  4.661e-05   0.163 0.874750    \nnum_attacks.l2 -3.381e-05  4.702e-05  -0.719 0.492631    \nmilexp.gdp.l2  -8.161e-01  4.912e-01  -1.662 0.135178    \nRTX.l2          2.335e-05  1.454e-04   0.161 0.876381    \nLMT.l2          3.700e-05  6.368e-05   0.581 0.577192    \nconst           9.377e-03  1.253e-02   0.748 0.475718    \ntrend          -4.351e-04  8.745e-04  -0.498 0.632217    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.001526 on 8 degrees of freedom\nMultiple R-Squared: 0.962,  Adjusted R-squared: 0.9193 \nF-statistic: 22.51 on 9 and 8 DF,  p-value: 9.392e-05 \n\n\nEstimation results for equation RTX: \n==================================== \nRTX = num_attacks.l1 + milexp.gdp.l1 + RTX.l1 + LMT.l1 + num_attacks.l2 + milexp.gdp.l2 + RTX.l2 + LMT.l2 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)\nnum_attacks.l1  8.974e-02  3.673e-01   0.244    0.813\nmilexp.gdp.l1  -1.526e+03  1.558e+03  -0.979    0.356\nRTX.l1         -5.968e-02  8.877e-01  -0.067    0.948\nLMT.l1         -3.363e-02  2.467e-01  -0.136    0.895\nnum_attacks.l2  1.332e-01  2.488e-01   0.535    0.607\nmilexp.gdp.l2   1.441e+03  2.599e+03   0.554    0.595\nRTX.l2         -4.760e-01  7.694e-01  -0.619    0.553\nLMT.l2         -2.567e-03  3.370e-01  -0.008    0.994\nconst           1.431e+01  6.632e+01   0.216    0.835\ntrend           4.414e+00  4.628e+00   0.954    0.368\n\n\nResidual standard error: 8.074 on 8 degrees of freedom\nMultiple R-Squared: 0.9106, Adjusted R-squared:  0.81 \nF-statistic: 9.053 on 9 and 8 DF,  p-value: 0.002481 \n\n\nEstimation results for equation LMT: \n==================================== \nLMT = num_attacks.l1 + milexp.gdp.l1 + RTX.l1 + LMT.l1 + num_attacks.l2 + milexp.gdp.l2 + RTX.l2 + LMT.l2 + const + trend \n\n                 Estimate Std. Error t value Pr(>|t|)\nnum_attacks.l1  6.302e-01  1.391e+00   0.453    0.662\nmilexp.gdp.l1  -5.311e+03  5.897e+03  -0.901    0.394\nRTX.l1          1.946e+00  3.361e+00   0.579    0.578\nLMT.l1         -1.831e-01  9.339e-01  -0.196    0.849\nnum_attacks.l2  6.553e-01  9.422e-01   0.696    0.506\nmilexp.gdp.l2   5.310e+03  9.841e+03   0.540    0.604\nRTX.l2          5.092e-02  2.913e+00   0.017    0.986\nLMT.l2          8.553e-01  1.276e+00   0.670    0.522\nconst          -3.930e+01  2.511e+02  -0.157    0.880\ntrend          -1.058e+00  1.752e+01  -0.060    0.953\n\n\nResidual standard error: 30.57 on 8 degrees of freedom\nMultiple R-Squared: 0.9592, Adjusted R-squared: 0.9134 \nF-statistic: 20.91 on 9 and 8 DF,  p-value: 0.0001238 \n\n\n\nCovariance matrix of residuals:\n            num_attacks milexp.gdp        RTX        LMT\nnum_attacks   3.306e+01 -3.772e-04 -29.554208 -90.060055\nmilexp.gdp   -3.772e-04  2.327e-06   0.000433   0.002229\nRTX          -2.955e+01  4.330e-04  65.182358 239.324786\nLMT          -9.006e+01  2.229e-03 239.324786 934.378868\n\nCorrelation matrix of residuals:\n            num_attacks milexp.gdp      RTX      LMT\nnum_attacks      1.0000   -0.04300 -0.63666 -0.51242\nmilexp.gdp      -0.0430    1.00000  0.03515  0.04781\nRTX             -0.6367    0.03515  1.00000  0.96975\nLMT             -0.5124    0.04781  0.96975  1.00000\n\n\nVAR(3) output: System is computationally singular!\n\n\nK-Fold Cross Validation and Model Diagnostics\n\n\nCode\n# Define the number of folds for cross-validation\nk <- 5\n\n# Define the p values to test\np_values <- c(1, 2)\n\n# Split the data into k folds\ncv_folds <- cut(seq(1, nrow(var_ts)), breaks = k, labels = FALSE)\n\n# Initialize vectors to store RMSE and AIC values for each p value\nrmse_vec <- numeric(length(p_values))\naic_vec <- numeric(length(p_values))\n\n# Loop over p values and perform cross-validation\nfor (i in seq_along(p_values)) {\n  p <- p_values[i]\n  rmse_cv <- numeric(k)\n  aic_cv <- numeric(k)\n  for (j in 1:k) {\n    # Split the data into training and testing sets\n    train <- var_ts[cv_folds != j, ]\n    test <- var_ts[cv_folds == j, ]\n    \n    # Fit the VAR model with the current p value\n    var_fit <- VAR(train, p = p)\n    \n    # Make predictions for the testing set\n    pred <- predict(var_fit, n.ahead = nrow(test))$fcst\n    \n    # Calculate RMSE and AIC for the current fold\n    rmse_cv[j] <- sqrt(mean((pred$num_attacks - test[,1])^2))\n    aic_cv[j] <- AIC(var_fit)\n  }\n  # Calculate the mean RMSE and AIC across all folds for the current p value\n  rmse_vec[i] <- mean(rmse_cv)\n  aic_vec[i] <- mean(aic_cv)\n}\n\n# Create a table of RMSE and AIC values for each p value\nresults_table <- tibble(p_values, rmse_vec, aic_vec)\n\n# Print the results table\nkable(results_table, format = \"markdown\", \n        col.names = c(\"P Values\", \"Mean RMSE (5 Folds)\", \"Mean AIC (5 Folds)\"), align = \"c\", digits = 2\n        )\n\n\n\n\n\nP Values\nMean RMSE (5 Folds)\nMean AIC (5 Folds)\n\n\n\n\n1\n71.52\n185.30\n\n\n2\n99.81\n146.72\n\n\n\n\n\nThe VAR(1) model outputs the lowest Mean RMSE of 71.5162242 attacks from the 5-fold cross validation. However, it has the highest AIC score. Because predictive performance is best and it is the simplest model, we shall choose the VAR(1) model as the best option.\n\n\nForecasting Chosen Model (p=1)\n\n\nCode\nfinal_var <- VAR(var_ts, p = 1)\n\n(fit.pr = predict(final_var, n.ahead = 5, ci = 0.95)) # 5 years ahead \n\n\n$num_attacks\n         fcst    lower    upper       CI\n[1,] 106.4884 91.82990 121.1468 14.65845\n[2,] 105.5359 86.41872 124.6530 19.11715\n[3,] 109.0563 81.39161 136.7209 27.66464\n[4,] 118.1089 80.57597 155.6418 37.53293\n[5,] 131.7816 85.56980 177.9934 46.21179\n\n$milexp.gdp\n           fcst      lower      upper          CI\n[1,] 0.04196276 0.03852185 0.04540368 0.003440917\n[2,] 0.04459492 0.03773271 0.05145714 0.006862216\n[3,] 0.04512609 0.03559814 0.05465404 0.009527950\n[4,] 0.04433390 0.03338255 0.05528525 0.010951349\n[5,] 0.04302182 0.03156563 0.05447801 0.011456189\n\n$RTX\n          fcst    lower     upper       CI\n[1,]  78.44562 60.42232  96.46891 18.02329\n[2,]  92.88661 69.53197 116.24126 23.35465\n[3,] 106.43252 80.56027 132.30477 25.87225\n[4,] 118.40947 90.38185 146.43709 28.02762\n[5,] 129.33401 98.88817 159.77985 30.44584\n\n$LMT\n         fcst    lower    upper        CI\n[1,] 353.1120 296.8576 409.3664  56.25439\n[2,] 388.1265 301.4406 474.8125  86.68594\n[3,] 432.9756 319.8179 546.1334 113.15777\n[4,] 485.3378 348.8491 621.8266 136.48874\n[5,] 543.6911 385.6159 701.7664 158.07525\n\n\nCode\nfanchart(fit.pr) # plot prediction + error\n\n\n\n\n\nThe above plot showcases the forecasts for each variable present in the VAR(1) model, Number of Yearly Attacks, US Military Expenditure as a % of US GDP, and Closing Price of Raytheon Technologies Stock. The predicted forecast, from the years 2021 to 2025, for Number of Yearly Attacks is a good sign for the US due to the decreasing and plateauing trend, although the latest observations from 2015 onwards suggest an increasing trend. The same forecasted trend is discerned for US Military Expenditure as a % of US GDP, with Raytheon Technologies Stock being the only variable with a predicted increasing trend.\nLet us visualize more closely the forecasts for the Number of Yearly Attacks from 2021 to 2025, corresponding to the VAR(1) model fitted on 9/11 and post-9/11 years (2001-2020):\n\n\nCode\n# create df of attack forecasts\ndf_fvar_attack <- as.data.frame(fit.pr$fcst$num_attacks)\n# add year column\ndf_fvar_attack$Year <- c(\"2021\", \"2022\", \"2023\", \"2024\", \"2025\")\n(var_plot <- ggplot(data=df_fvar_attack, aes(x=Year, y=fcst, group = 1)) +\n    geom_line(aes(color=\"Forecast\"), linewidth=1) +\n    geom_ribbon(aes(ymin=lower, ymax=upper, fill=\"Confidence Interval\"), alpha=0.1) +\n    labs(title=\"VAR(1) Forecasts for Number of Yearly Attacks from 2021 to 2025\",\n         y=\"Number of Terrorist Attacks\",\n         color=\"\", fill=\"\",\n         caption=\"Data Sources: Global Terrorism Database, SIPRI Military Expenditure Database, Yahoo Finance\") +\n    scale_color_manual(values = c(\"Forecast\"=\"red\")) +\n    scale_fill_manual(values = c(\"95% Confidence Interval\"=\"steelblue\")) +\n    theme_minimal() + \n  theme(plot.caption.position = \"plot\"))\n\n\n\n\n\nCode\n#ggplotly(var_plot)"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#manual-arimax-modeling-1970-2020-pre-and-post-911-attacks",
    "href": "ARIMAX-SARIMAX-VAR.html#manual-arimax-modeling-1970-2020-pre-and-post-911-attacks",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Manual ARIMAX Modeling (1970-2020: Pre and Post-9/11 Attacks)",
    "text": "Manual ARIMAX Modeling (1970-2020: Pre and Post-9/11 Attacks)\nThe ARIMAX model being analyzed in this section is:\n\nNumber of yearly terrorist attacks in the US ~ Number of yearly B-1 visa entrants + Number of yearly B-2 visa entrants + Number of yearly F-1 visa entrants + Yearly US Military Expenditure as Percentage of US GDP + Raytheon Technologies’ Last Yearly Closing Price\n\n\n \nIts output is as follows:\n\n\nCode\ngtd_USA_2 <- gtd %>% \n            filter(country_txt==\"United States\")\n\n# drop 33 observations from a total of 3121 observations (if taking for '70)\ngtd_USA_2 <- gtd_USA_2[complete.cases(gtd_USA_2$Date),]\n\n# impute missing values for nkill (Total Number of Fatalities: victims and attackers) as 0\n\ngtd_USA_2$nkill[is.na(gtd_USA_2$nkill)] <- 0\n\n# select desired columns for analysis (num_casualties ~ num_attacks, state, attack_type, weapon_type, victim_type, )\ngtd_USA_2 <- subset(gtd_USA_2, select=c(Date, nkill))\n\n# new dataframe for monthly number of attacks 1970-2020\ngtd_yearly_attacks_deaths <- gtd_USA_2 %>% \n              group_by(year(Date)) %>% \n                  summarise(nkill=sum(nkill),\n                            num_attacks = n())\n\ncolnames(gtd_yearly_attacks_deaths)[1] =\"Year\"\ncolnames(gtd_yearly_attacks_deaths)[2] =\"num_fatal\"\ncolnames(gtd_yearly_attacks_deaths)[3] =\"num_attacks\"\n\ngtd_yearly_attacks_deaths$Year <- as.Date(paste0(gtd_yearly_attacks_deaths$Year, \"-12-31\"))\n\n# Fill missing dates (0 attacks for those dates)\ngtd_yearly_attacks_deaths <- gtd_yearly_attacks_deaths %>% \n              complete(Year = seq.Date(min(Year), max(Year), by=\"year\")) \n\n# impute 28 ATTACKS in 1993 and 21 casualties in 1993 as per GTD\ngtd_yearly_attacks_deaths[24,2] <- 28\ngtd_yearly_attacks_deaths[24,3] <- 21\n\n# CLEAN DHS df\n## convert year to date time\ndhs$Year <- as.Date(paste(dhs$Year, \"-12-31\", sep = \"\"), format = \"%Y-%m-%d\")\n\n## subset\ndhs <- subset(dhs, select = c(Year, Temporaryvisitorsforpleasure, Temporaryvisitorsforbusiness, Students))\n\n# join with aggregated GTD df \ngtd_dhs <- merge(gtd_yearly_attacks_deaths, dhs, by = \"Year\", all.x = TRUE)\n\n# interpolate NAs in DHS columns (1970 to 1980, 1982 to 84, 86 to 88)\ngtd_dhs[,4] <- imputeTS::na.interpolation(gtd_dhs[,4])\ngtd_dhs[,5] <- imputeTS::na.interpolation(gtd_dhs[,5])\ngtd_dhs[,6] <- imputeTS::na.interpolation(gtd_dhs[,6])\n\n# join sipri dataset -> military expenditure as % of GDP\nmilexp.gdp <- sipri_gdp %>% filter(Country=='United States of America')\nmilexp.gdp <- melt(milexp.gdp, id.vars = 'Country', variable.name = 'Year', value.name = 'GDP') \nmilexp.gdp <- as.numeric(milexp.gdp[22:72, 3])\ngtd_dhs_sipri <- cbind(gtd_dhs, milexp.gdp) \n#gtd_dhs_sipri[32,2] <- 10 # subtracting 3004 number of casualties (9/11 attacks -> outlier event)\n#gtd_dhs_sipri[32,3] <- 43 # subtracting 4 attacks (9/11 attacks -> outlier event)\n\n# Collecting Raytheon Tech Stock Price (only one active since 70's)\n\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\ntickers = c(\"RTX\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"1970-01-01\",\n             to = \"2021-12-31\")}\n\nrtx <- data.frame(RTX$RTX.Adjusted)\n\nrtx <- data.frame(rtx,rownames(rtx))\ncolnames(rtx) <- append(tickers,'Dates')\n\nrtx$date<-as.Date(rtx$Dates,\"%Y-%m-%d\")\n\nrtx_yearly <- rtx %>% \n  filter(format(date, \"%m-%d\") == \"12-31\") %>% \n  group_by(Year=year(date)) %>% \n  summarise(RTX = last(RTX))\n\nrtx_yearly$Year <- as.Date(paste0(rtx_yearly$Year, \"-12-31\"))\n\n# Fill missing dates \nrtx_yearly <- rtx_yearly %>% \n              complete(Year = seq.Date(min(Year), max(Year), by=\"year\")) \n\nrtx_yearly$RTX <- imputeTS::na.interpolation(rtx_yearly$RTX)\n\n# final join to create final VAR dataset\n\ngtd_dhs_sipri_rtx <- cbind(gtd_dhs_sipri, rtx_yearly$RTX) \n\n# rename cols\n\ncolnames(gtd_dhs_sipri_rtx)[c(4, 5, 8)] <- c(\"Pleasure\", \"Business\", \"RTX\")\n\n# convert df to matrix\n\nts_matrix <- as.matrix(gtd_dhs_sipri_rtx[, 2:8])\n\n# convert the matrix to a time series object with a yearly frequency \nvar_ts <- ts(ts_matrix, frequency = 1,\n                 start = 1970)\n\n\n\nRegression Summary and Fitting ARIMA to Residuals\n\n\nCode\nfit.reg <- lm(num_attacks ~ . - num_fatal, data =var_ts)\nsummary(fit.reg)\n\n\n\nCall:\nlm(formula = num_attacks ~ . - num_fatal, data = var_ts)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-58.34 -38.63 -18.22  28.38 310.69 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)  \n(Intercept) -4.073e+01  8.203e+01  -0.497   0.6219  \nPleasure     4.791e-06  2.642e-06   1.813   0.0764 .\nBusiness    -1.831e-05  1.605e-05  -1.141   0.2599  \nStudents    -8.834e-05  6.736e-05  -1.311   0.1964  \nmilexp.gdp   2.371e+03  1.216e+03   1.950   0.0574 .\nRTX          5.734e-01  1.076e+00   0.533   0.5968  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 62.47 on 45 degrees of freedom\nMultiple R-squared:  0.299, Adjusted R-squared:  0.2211 \nF-statistic: 3.839 on 5 and 45 DF,  p-value: 0.005556\n\n\nCode\nres.fit<-ts(residuals(fit.reg),star=decimal_date(as.Date(\"1970-01-01\",format = \"%Y-%m-%d\")),frequency = 1)\n\n############## Then look at the residuals ############\nres.fit %>% ggtsdisplay() # no need to difference\n\n\n\n\n\nCode\n#q=1,3 Q=1 , p=1,2, P=1,2\n#write a funtion\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \n  temp=c()\n  d=0\n  D=0\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*44),nrow=44)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          for(d in d1:d2)\n       \n        {\n          if(p+d+q+P+D+Q<=8)\n          {\n            \n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  \n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n##q=1,3 Q=0 p=1,2 P=0 d=0\n\noutput=SARIMA.c(p1=1,p2=3,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=0,data=res.fit)\noutput\n\n\n   p d q P D Q      AIC      BIC     AICc\n1  0 0 0 0 0 0 564.0890 567.9527 564.3390\n2  0 0 0 0 0 1 564.0890 567.9527 564.3390\n3  0 0 0 1 0 0 564.0890 567.9527 564.3390\n4  0 0 0 1 0 1 564.0890 567.9527 564.3390\n5  0 0 0 2 0 0 564.0890 567.9527 564.3390\n6  0 0 0 2 0 1 564.0890 567.9527 564.3390\n7  0 0 1 0 0 0 536.4054 542.2008 536.9160\n8  0 0 1 0 0 1 536.4054 542.2008 536.9160\n9  0 0 1 1 0 0 536.4054 542.2008 536.9160\n10 0 0 1 1 0 1 536.4054 542.2008 536.9160\n11 0 0 1 2 0 0 536.4054 542.2008 536.9160\n12 0 0 1 2 0 1 536.4054 542.2008 536.9160\n13 0 0 2 0 0 0 529.5765 537.3038 530.4461\n14 0 0 2 0 0 1 529.5765 537.3038 530.4461\n15 0 0 2 1 0 0 529.5765 537.3038 530.4461\n16 0 0 2 1 0 1 529.5765 537.3038 530.4461\n17 0 0 2 2 0 0 529.5765 537.3038 530.4461\n18 0 0 3 0 0 0 525.4438 535.1029 526.7771\n19 0 0 3 0 0 1 525.4438 535.1029 526.7771\n20 0 0 3 1 0 0 525.4438 535.1029 526.7771\n21 1 0 0 0 0 0 535.4053 541.2008 535.9160\n22 1 0 0 0 0 1 535.4053 541.2008 535.9160\n23 1 0 0 1 0 0 535.4053 541.2008 535.9160\n24 1 0 0 1 0 1 535.4053 541.2008 535.9160\n25 1 0 0 2 0 0 535.4053 541.2008 535.9160\n26 1 0 0 2 0 1 535.4053 541.2008 535.9160\n27 1 0 1 0 0 0 528.7138 536.4411 529.5834\n28 1 0 1 0 0 1 528.7138 536.4411 529.5834\n29 1 0 1 1 0 0 528.7138 536.4411 529.5834\n30 1 0 1 1 0 1 528.7138 536.4411 529.5834\n31 1 0 1 2 0 0 528.7138 536.4411 529.5834\n32 1 0 2 0 0 0 525.8292 535.4883 527.1625\n33 1 0 2 0 0 1 525.8292 535.4883 527.1625\n34 1 0 2 1 0 0 525.8292 535.4883 527.1625\n35 1 0 3 0 0 0 527.4145 539.0054 529.3236\n36 2 0 0 0 0 0 525.9075 533.6348 526.7771\n37 2 0 0 0 0 1 525.9075 533.6348 526.7771\n38 2 0 0 1 0 0 525.9075 533.6348 526.7771\n39 2 0 0 1 0 1 525.9075 533.6348 526.7771\n40 2 0 0 2 0 0 525.9075 533.6348 526.7771\n41 2 0 1 0 0 0 527.8172 537.4764 529.1506\n42 2 0 1 0 0 1 527.8172 537.4764 529.1506\n43 2 0 1 1 0 0 527.8172 537.4764 529.1506\n44 2 0 2 0 0 0 527.3804 538.9713 529.2895\n\n\n\n\nARIMA(2,0,0) or AR(2) Forecasting\n\n\nCode\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC      BIC     AICc\n18 0 0 3 0 0 0 525.4438 535.1029 526.7771\n\n\nCode\noutput[which.min(output$BIC),]\n\n\n   p d q P D Q      AIC      BIC     AICc\n36 2 0 0 0 0 0 525.9075 533.6348 526.7771\n\n\nCode\noutput[which.min(output$AICc),]\n\n\n   p d q P D Q      AIC      BIC     AICc\n36 2 0 0 0 0 0 525.9075 533.6348 526.7771\n\n\nCode\nset.seed(1234)\n\nmodel_outputar2 <- capture.output(sarima(res.fit, 2,0,0, 0,0,0))\n\n\n\n\n\nCode\ncat(model_outputar2[30:62], model_outputar2[length(model_outputar2)], sep = \"\\n\")\n\n\nconverged\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    xreg = xmean, include.mean = FALSE, transform.pars = trans, fixed = fixed, \n    optim.control = list(trace = trc, REPORT = 1, reltol = tol))\n\nCoefficients:\n         ar1      ar2    xmean\n      1.3542  -0.6186  13.0780\ns.e.  0.1634   0.1684  22.8472\n\nsigma^2 estimated as 1443:  log likelihood = -258.95,  aic = 525.91\n\n$degrees_of_freedom\n[1] 48\n\n$ttable\n      Estimate      SE t.value p.value\nar1     1.3542  0.1634  8.2894  0.0000\nar2    -0.6186  0.1684 -3.6727  0.0006\nxmean  13.0780 22.8472  0.5724  0.5697\n\n$AIC\n[1] 10.31191\n\n$AICc\n[1] 10.32192\n\n$BIC\n[1] 10.46343\n\n\nCode\narimaModel_1 <- arima(res.fit, order = c(2,0,0))\nforecast1=predict(arimaModel_1, 5)\n# create df with fcast preds and +-1.96 SE for 95% CI Bands\nfarimax_df <- data.frame(\n  Year = 2021:2025,\n  fcst = as.numeric(forecast1$pred),\n  lower = as.numeric(forecast1$pred - 1.96 * forecast1$se),\n  upper = as.numeric(forecast1$pred + 1.96 * forecast1$se)\n)\n\n#plot(forecast1$pred, main = \"ARIMA(2,0,0) Forecast For 5 Years\", xlab = \"Time\", ylab = \"Values\", col = \"red\")\n(arimax_plot <- ggplot(data=farimax_df, aes(x=Year, y=fcst, group = 1)) +\n    geom_line(aes(color=\"Forecast\"), linewidth=1) +\n    geom_ribbon(aes(ymin=lower, ymax=upper, fill=\"Confidence Interval\"), alpha=0.1) +\n    labs(title=\"ARIMA(2,0,0) Forecasts for Number of Yearly Attacks from 2021 to 2025\",\n         y=\"Number of Terrorist Attacks\",\n         color=\"\", fill=\"\",\n         caption=\"Data Sources: Global Terrorism Database, Department of Homeland Security, SIPRI Military Expenditure Database, Yahoo Finance\") +\n    scale_color_manual(values = c(\"Forecast\"=\"red\")) +\n    scale_fill_manual(values = c(\"95% Confidence Interval\"=\"steelblue\")) +\n    theme_minimal() + \n  theme(plot.caption.position = \"plot\", plot.caption = element_text(size=8)))"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#manual-arimax-modeling-2001-2020-post-911-attacks",
    "href": "ARIMAX-SARIMAX-VAR.html#manual-arimax-modeling-2001-2020-post-911-attacks",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Manual ARIMAX Modeling (2001-2020: Post-9/11 Attacks)",
    "text": "Manual ARIMAX Modeling (2001-2020: Post-9/11 Attacks)\nThe ARIMAX model being analyzed in this section is:\n\nNumber of yearly terrorist attacks in the US ~ Number of yearly B-1 visa entrants + Number of yearly B-2 visa entrants + Number of yearly F-1 visa entrants + Yearly US Military Expenditure as Percentage of US GDP + Raytheon Technologies’ Last Yearly Closing Price + Lockheed Martin’s Last Yearly Closing Price\n\n\n \nIts output is as follows:\n\n\nCode\ngtd_USA_2 <- gtd %>% \n            filter(country_txt==\"United States\")\n\n# drop 33 observations from a total of 3121 observations (if taking for '70)\ngtd_USA_2 <- gtd_USA_2[complete.cases(gtd_USA_2$Date),]\n\n# impute missing values for nkill (Total Number of Fatalities: victims and attackers) as 0\n\ngtd_USA_2$nkill[is.na(gtd_USA_2$nkill)] <- 0\n\n# select desired columns for analysis (num_casualties ~ num_attacks, state, attack_type, weapon_type, victim_type, )\ngtd_USA_2 <- subset(gtd_USA_2, select=c(Date, nkill))\n\n# new dataframe for monthly number of attacks 1970-2020\ngtd_yearly_attacks_deaths <- gtd_USA_2 %>% \n              group_by(year(Date)) %>% \n                  summarise(nkill=sum(nkill),\n                            num_attacks = n())\n\ncolnames(gtd_yearly_attacks_deaths)[1] =\"Year\"\ncolnames(gtd_yearly_attacks_deaths)[2] =\"num_fatal\"\ncolnames(gtd_yearly_attacks_deaths)[3] =\"num_attacks\"\n\ngtd_yearly_attacks_deaths$Year <- as.Date(paste0(gtd_yearly_attacks_deaths$Year, \"-12-31\"))\n\n# Fill missing dates (0 attacks for those dates)\ngtd_yearly_attacks_deaths <- gtd_yearly_attacks_deaths %>% \n              complete(Year = seq.Date(min(Year), max(Year), by=\"year\")) \n\n# impute 28 ATTACKS in 1993 and 21 casualties in 1993 as per GTD\ngtd_yearly_attacks_deaths[24,2] <- 28\ngtd_yearly_attacks_deaths[24,3] <- 21\n\n# CLEAN DHS df\n## convert year to date time\ndhs$Year <- as.Date(paste(dhs$Year, \"-12-31\", sep = \"\"), format = \"%Y-%m-%d\")\n\n## subset\ndhs <- subset(dhs, select = c(Year, Temporaryvisitorsforpleasure, Temporaryvisitorsforbusiness, Students))\n\n# join with aggregated GTD df \ngtd_dhs <- merge(gtd_yearly_attacks_deaths, dhs, by = \"Year\", all.x = TRUE)\n\n# interpolate NAs in DHS columns (1970 to 1980, 1982 to 84, 86 to 88)\ngtd_dhs[,4] <- imputeTS::na.interpolation(gtd_dhs[,4])\ngtd_dhs[,5] <- imputeTS::na.interpolation(gtd_dhs[,5])\ngtd_dhs[,6] <- imputeTS::na.interpolation(gtd_dhs[,6])\n\n# join sipri dataset -> military expenditure as % of GDP\nmilexp.gdp <- sipri_gdp %>% filter(Country=='United States of America')\nmilexp.gdp <- melt(milexp.gdp, id.vars = 'Country', variable.name = 'Year', value.name = 'GDP') \nmilexp.gdp <- as.numeric(milexp.gdp[22:72, 3])\ngtd_dhs_sipri <- cbind(gtd_dhs, milexp.gdp) \n#gtd_dhs_sipri[32,2] <- 10 # subtracting 3004 number of casualties (9/11 attacks -> outlier event)\n#gtd_dhs_sipri[32,3] <- 43 # subtracting 4 attacks (9/11 attacks -> outlier event)\n\n# Collecting Raytheon Tech Stock Price (only one active since 70's)\n\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\ntickers = c(\"RTX\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"1970-01-01\",\n             to = \"2021-12-31\")}\n\nrtx <- data.frame(RTX$RTX.Adjusted)\n\nrtx <- data.frame(rtx,rownames(rtx))\ncolnames(rtx) <- append(tickers,'Dates')\n\nrtx$date<-as.Date(rtx$Dates,\"%Y-%m-%d\")\n\nrtx_yearly <- rtx %>% \n  filter(format(date, \"%m-%d\") == \"12-31\") %>% \n  group_by(Year=year(date)) %>% \n  summarise(RTX = last(RTX))\n\nrtx_yearly$Year <- as.Date(paste0(rtx_yearly$Year, \"-12-31\"))\n\n# Fill missing dates \nrtx_yearly <- rtx_yearly %>% \n              complete(Year = seq.Date(min(Year), max(Year), by=\"year\")) \n\nrtx_yearly$RTX <- imputeTS::na.interpolation(rtx_yearly$RTX)\n\n# join \n\ngtd_dhs_sipri_rtx <- cbind(gtd_dhs_sipri, rtx_yearly$RTX) \n\n# LMT \n\ntickers = c(\"LMT\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"2001-09-11\",\n             to = \"2021-12-31\")}\n\nlmt <- data.frame(LMT$LMT.Adjusted)\n\nlmt <- data.frame(lmt,rownames(lmt))\ncolnames(lmt) <- append(tickers,'Dates')\n\nlmt$date<-as.Date(lmt$Dates,\"%Y-%m-%d\")\n\nlmt_yearly <- lmt %>% \n  filter(format(date, \"%m-%d\") == \"12-31\") %>% \n  group_by(Year=year(date)) %>% \n  summarise(LMT = last(LMT))\n\nlmt_yearly$Year <- as.Date(paste0(lmt_yearly$Year, \"-12-31\"))\n\n# Fill missing dates \nlmt_yearly <- lmt_yearly %>% \n              complete(Year = seq.Date(min(Year), max(Year), by=\"year\")) \n\nlmt_yearly$LMT <- imputeTS::na.interpolation(lmt_yearly$LMT)\n\n# filter gtd_hds_sipri_rtx\n\ngtd_dhs_sipri_rtx <- gtd_dhs_sipri_rtx %>% slice(32:n())\n\n# final join to create final arimax dataset\n\ngtd_dhs_sipri_rtx_lmt <- cbind(gtd_dhs_sipri_rtx, lmt_yearly$LMT) \n\n# rename cols\n\ncolnames(gtd_dhs_sipri_rtx_lmt)[c(4, 5, 8, 9)] <- c(\"Pleasure\", \"Business\", \"RTX\", \"LMT\")\n\n# convert df to matrix\n\nts_matrix <- as.matrix(gtd_dhs_sipri_rtx_lmt[, 2:9])\n\n# convert the matrix to a time series object with a yearly frequency \nvar_ts <- ts(ts_matrix, frequency = 1,\n                 start = 2001)\n\n\n\nRegression Summary and Fitting ARIMA to Residuals\n\n\nCode\nfit.reg <- lm(num_attacks ~ . - num_fatal, data = var_ts)\n\nsummary(fit.reg)\n\n\n\nCall:\nlm(formula = num_attacks ~ . - num_fatal, data = var_ts)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.810  -5.474   1.472   4.598  12.926 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.076e+02  2.997e+01   3.591  0.00329 ** \nPleasure     1.516e-07  1.311e-06   0.116  0.90970    \nBusiness    -8.943e-06  7.019e-06  -1.274  0.22496    \nStudents     2.584e-05  1.892e-05   1.366  0.19506    \nmilexp.gdp  -1.339e+03  6.769e+02  -1.978  0.06955 .  \nRTX         -1.423e+00  5.071e-01  -2.807  0.01482 *  \nLMT          4.516e-01  7.941e-02   5.687 7.46e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.824 on 13 degrees of freedom\nMultiple R-squared:  0.9305,    Adjusted R-squared:  0.8984 \nF-statistic:    29 on 6 and 13 DF,  p-value: 8.375e-07\n\n\nCode\nres.fit<-ts(residuals(fit.reg),star=decimal_date(as.Date(\"1970-01-01\",format = \"%Y-%m-%d\")),frequency = 1)\n\n############## Then look at the residuals ############\nres.fit %>% ggtsdisplay() # no need to difference\n\n\n\n\n\nCode\n#q=1,3 Q=1 , p=1,2, P=1,2\n#write a funtion\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \n  temp=c()\n  d=0\n  D=0\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*44),nrow=44)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          for(d in d1:d2)\n       \n        {\n          if(p+d+q+P+D+Q<=8)\n          {\n            \n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  \n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n##q=1,2 Q=0 , p=1,2 P=0 d=0\n\noutput=SARIMA.c(p1=1,p2=3,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=0,data=res.fit)\noutput\n\n\n   p d q P D Q      AIC      BIC     AICc\n1  0 0 0 0 0 0 139.2404 141.2319 139.9463\n2  0 0 0 0 0 1 139.2404 141.2319 139.9463\n3  0 0 0 1 0 0 139.2404 141.2319 139.9463\n4  0 0 0 1 0 1 139.2404 141.2319 139.9463\n5  0 0 0 2 0 0 139.2404 141.2319 139.9463\n6  0 0 0 2 0 1 139.2404 141.2319 139.9463\n7  0 0 1 0 0 0 134.8792 137.8664 136.3792\n8  0 0 1 0 0 1 134.8792 137.8664 136.3792\n9  0 0 1 1 0 0 134.8792 137.8664 136.3792\n10 0 0 1 1 0 1 134.8792 137.8664 136.3792\n11 0 0 1 2 0 0 134.8792 137.8664 136.3792\n12 0 0 1 2 0 1 134.8792 137.8664 136.3792\n13 0 0 2 0 0 0 135.9981 139.9811 138.6648\n14 0 0 2 0 0 1 135.9981 139.9811 138.6648\n15 0 0 2 1 0 0 135.9981 139.9811 138.6648\n16 0 0 2 1 0 1 135.9981 139.9811 138.6648\n17 0 0 2 2 0 0 135.9981 139.9811 138.6648\n18 0 0 3 0 0 0 135.7986 140.7772 140.0843\n19 0 0 3 0 0 1 135.7986 140.7772 140.0843\n20 0 0 3 1 0 0 135.7986 140.7772 140.0843\n21 1 0 0 0 0 0 138.0040 140.9912 139.5040\n22 1 0 0 0 0 1 138.0040 140.9912 139.5040\n23 1 0 0 1 0 0 138.0040 140.9912 139.5040\n24 1 0 0 1 0 1 138.0040 140.9912 139.5040\n25 1 0 0 2 0 0 138.0040 140.9912 139.5040\n26 1 0 0 2 0 1 138.0040 140.9912 139.5040\n27 1 0 1 0 0 0 135.7758 139.7587 138.4425\n28 1 0 1 0 0 1 135.7758 139.7587 138.4425\n29 1 0 1 1 0 0 135.7758 139.7587 138.4425\n30 1 0 1 1 0 1 135.7758 139.7587 138.4425\n31 1 0 1 2 0 0 135.7758 139.7587 138.4425\n32 1 0 2 0 0 0 137.7741 142.7527 142.0598\n33 1 0 2 0 0 1 137.7741 142.7527 142.0598\n34 1 0 2 1 0 0 137.7741 142.7527 142.0598\n35 1 0 3 0 0 0 135.0720 141.0464 141.5336\n36 2 0 0 0 0 0 139.9898 143.9727 142.6564\n37 2 0 0 0 0 1 139.9898 143.9727 142.6564\n38 2 0 0 1 0 0 139.9898 143.9727 142.6564\n39 2 0 0 1 0 1 139.9898 143.9727 142.6564\n40 2 0 0 2 0 0 139.9898 143.9727 142.6564\n41 2 0 1 0 0 0 141.0728 146.0515 145.3585\n42 2 0 1 0 0 1 141.0728 146.0515 145.3585\n43 2 0 1 1 0 0 141.0728 146.0515 145.3585\n44 2 0 2 0 0 0 138.4104 144.3848 144.8719\n\n\n\n\nARIMA(0,0,1) or MA(1) Forecasting\n\n\nCode\noutput[which.min(output$AIC),] \n\n\n  p d q P D Q      AIC      BIC     AICc\n7 0 0 1 0 0 0 134.8792 137.8664 136.3792\n\n\nCode\noutput[which.min(output$BIC),]\n\n\n  p d q P D Q      AIC      BIC     AICc\n7 0 0 1 0 0 0 134.8792 137.8664 136.3792\n\n\nCode\noutput[which.min(output$AICc),]\n\n\n  p d q P D Q      AIC      BIC     AICc\n7 0 0 1 0 0 0 134.8792 137.8664 136.3792\n\n\nCode\nset.seed(1234)\n\nmodel_outputma2 <- capture.output(sarima(res.fit, 0,0,1,0,0,0))\n\n\n\n\n\nCode\ncat(model_outputma2[115:143], model_outputma2[length(model_outputar2)], sep = \"\\n\")\n\n\nconverged\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    xreg = xmean, include.mean = FALSE, transform.pars = trans, fixed = fixed, \n    optim.control = list(trace = trc, REPORT = 1, reltol = tol))\n\nCoefficients:\n          ma1    xmean\n      -1.0000  -0.2769\ns.e.   0.1542   0.2027\n\nsigma^2 estimated as 31.62:  log likelihood = -64.44,  aic = 134.88\n\n$degrees_of_freedom\n[1] 18\n\n$ttable\n      Estimate     SE t.value p.value\nma1    -1.0000 0.1542 -6.4859  0.0000\nxmean  -0.2769 0.2027 -1.3662  0.1887\n\n$AIC\n[1] 6.74396\n\n$AICc\n[1] 6.779254\n\niter  62 value 1.578776\n\n\nCode\narimaModel_1 <- arima(res.fit, order = c(0,0,1))\nforecast1=predict(arimaModel_1, 5)\n# create df with fcast preds and +-1.96 SE for 95% CI Bands\nfarimax_df <- data.frame(\n  Year = 2021:2025,\n  fcst = as.numeric(forecast1$pred),\n  lower = as.numeric(forecast1$pred - 1.96 * forecast1$se),\n  upper = as.numeric(forecast1$pred + 1.96 * forecast1$se)\n)\n\n#plot(forecast1$pred, main = \"ARIMA(2,0,0) Forecast For 5 Years\", xlab = \"Time\", ylab = \"Values\", col = \"red\")\n(arimax_plot <- ggplot(data=farimax_df, aes(x=Year, y=fcst, group = 1)) +\n    geom_line(aes(color=\"Forecast\"), linewidth=1) +\n    geom_ribbon(aes(ymin=lower, ymax=upper, fill=\"Confidence Interval\"), alpha=0.1) +\n    labs(title=\"ARIMA(0,0,1) Forecasts for Number of Yearly Attacks from 2021 to 2025\",\n         y=\"Number of Terrorist Attacks\",\n         color=\"\", fill=\"\",\n         caption=\"Data Sources: Global Terrorism Database, Department of Homeland Security, SIPRI Military Expenditure Database, Yahoo Finance\") +\n    scale_color_manual(values = c(\"Forecast\"=\"red\")) +\n    scale_fill_manual(values = c(\"95% Confidence Interval\"=\"steelblue\")) +\n    theme_minimal() + \n  theme(plot.caption.position = \"plot\", plot.caption = element_text(size=8)))"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#final-results",
    "href": "ARIMAX-SARIMAX-VAR.html#final-results",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Final Results",
    "text": "Final Results\nThe VAR(1) Model trained on Post-9/11 Attacks data is the best performing model in terms of the predicted forecast. It is the only model that took into account the latter observations in its prediction and predicted based on that increasing trend. Our hypothesis that non-immigrants do not significantly affect the number of yearly terrorist attacks in the US is, therefore, proven through the above analyses.\nThe ARIMAX model trained on all the years performed significantly worse than the ARIMAX model trained on only Post-9/11 Attacks years. In fact, when adding in Lockheed Martin’s stock price in segment 2 of the analysis (Post-9/11 Attacks), \\(Adjusted.R^2\\) increases by more than 60% from segment 1 of the analysis, which includes all years (1970-2020) and not Lockheed Martin’s stock price! Although that is the case, none of the predicted forecasts from the ARIMAX models are not as convincing as the VAR models. Moreover, in the ARIMAX models, all the non-immigration variables collected from DHS are non-significant, apart from Pleasure or B-2 Visa entrants in segment 1 (all years included) of the analysis.\nIn summary, the years prior to the 9/11 Attacks have little to no effect on the forecasts for 2021 to 2025. To gain more accurate forecasts from the VAR model, it is imperative to focus on data post-9/11. The variables that do imply high correlation (determining causation is out of scope of this analysis) to forecasting the yearly number of terrorist attacks in the US are US Military Expenditure both directly on armed forces and weapons contractors, Lockheed Martin and Raytheon Technologies."
  }
]
{
  "hash": "b64e6d444bf0d5eafefa909816c59536",
  "result": {
    "markdown": "---\ntitle: \"ARMA/ARIMA/SARIMA Models\"\nformat:\n  html:\n    page-layout: full\n    code-fold: show\n    code-copy: true\n    code-tools: true\n    code-overflow: wrap\nbibliography: bibliography.bib\n---\n\n\n## Summary\n\nAfter completing the exploratory data analysis (EDA) phase, the next step is to begin building time series models. In order to do so, one must first choose an appropriate model type, such as an ARMA (AutoRegressive Moving Average) model or one of its variations, including ARIMA (AutoRegressive Integrated Moving Average) or SARIMA (Seasonal AutoRegressive Integrated Moving Average).\n\nAn ARIMA model is generally notated as ARIMA(p,d,q) where p is the order of the AR process, d is the degree of differencing and q is the order of the MA process. The general equation of the model is given as follows:\n\n$\\phi(B)(1-B)^d x_t = \\delta + \\theta(B) w_t$, \nwhere $B$ is the backshift operator, $w_t$ is the Gaussian white noise process, $\\delta$ is the drift term and $\\phi(B)$ and $\\theta(B)$ correspond to the AR and MA parts respectively.\n\nLag plots, auto-correlation function (ACF) and partial auto-correlation function (PACF) plots, decomposing the time series, and differencing are all useful techniques that were employed during the EDA phase to help inform the choice of model type and parameters. With a solid understanding of the data and its characteristics, one can begin to develop and refine time series models that can be used for forecasting. \n\n## Global Terrorism Database ARIMA Modeling\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n### Splitting Series into Train and Test Sets for Model Validation Process\n\nAfter cleaning and aggregating the Global Terrorism Databaseâ„¢ (GTD) [@GTD] by month, we shall be splitting the aggregated monthly data set into train and test sets for model validation. I have kept 587 observations for training and the remaining 48 observations for testing or validating. Therefore, I have kept aside 2 years (48 months or 48 observations) for forecasting purposes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_series=monthly_attacks_ts[1:587] # close to 92%\ntest_series=monthly_attacks_ts[588:612] # keeping 2 years (48 months or 48 observations) to predict/forecast\n```\n:::\n\n\n### ACF and PACF Plots of Monthly Attacks {#ACF}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_series %>% \n  ggtsdisplay(main=\"ACF and PACF Plots of Monthly Attacks\")\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/pacf-1.png){width=672}\n:::\n:::\n\n\n### ADF Test of Monthly Attacks \n\n$H_0$: The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\n$H_1$: The time series is stationary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadf.test(train_series)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAugmented Dickey-Fuller Test\n\ndata:  train_series\nDickey-Fuller = -7.2458, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n```\n:::\n:::\n\n\nBecause the p-value from the ADF test is less than $\\alpha$ = 0.05, we reject the null hypothesis and conclude that the monthly attacks series is stationary. Although the ADF states that the original series is stationary, the ACF plots, which clearly indicate seasonality and trend, are more reliable than the ADF test. Therefore, it is safe to conclude that the series non-stationary as per the [ACF](#ACF) section above. \n\n### Log-Transformation of Monthly Attacks and its First and Second Order Differencing\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlx = log(train_series+1); dlx = diff(lx); ddlx = diff(dlx, 12) # add 1 to lx to not get NAs\n\nx = train_series\n\nplot.ts(cbind(x,lx,dlx,ddlx), main=\"\")\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/logadf-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow=c(2,1))\nmonthplot(dlx); monthplot(ddlx)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/logadf-2.png){width=672}\n:::\n:::\n\n\nSimply taking log of the number of monthly attacks does not make it stationary. First-differencing the log number of monthly attacks does, however, make the series stationary and this series should be employed for building our time series model. Keep in mind that because first-differencing was enough to make the series stationary, we do not need to second-difference it, helping us avoid over differencing the number of monthly attacks.\n\n### ADF Test of Log First-Differenced Monthly Attacks \n\n$H_0$: The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\n$H_1$: The time series is stationary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadf.test(dlx)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAugmented Dickey-Fuller Test\n\ndata:  dlx\nDickey-Fuller = -12.802, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n```\n:::\n:::\n\n\nBecause the p-value from the ADF test is less than $\\alpha$ = 0.05, we reject the null hypothesis and conclude that the log first-differenced monthly attacks series is stationary. Let us now check whether the ACF plots supports this hypothesis.\n\n### ACF and PACF Plots of Log First-Differenced Monthly Attacks {#lACF}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndlx %>% \n  ggtsdisplay(main=\"ACF and PACF Plots of Log First-Differenced Monthly Attacks\")\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/lfdpacf-1.png){width=672}\n:::\n:::\n\n\n**p** values obtained from PACF are 0, 1, 2, 3, 4\n**q** values obtained from ACF are: 0, 1 \n**d** (Difference): 1\n\n### Fitting ARIMA(p,d,q) {#best-fit}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*24),nrow=24) # roughly nrow = 3x4x2\n\n\nfor (p in 1:5)# p=0,1,2,3,4 \n{\n  for(q in 1:4)# q=0,1,2,3 (although we only found q=1 to be significant in ACF, we may want to compare a complex ARIMA model with greater \"q\" value compared to a simpler ARIMA model)\n  {\n    for(d in 1)# d=1\n    {\n      \n      if(p-1+d+q-1<=8)\n      {\n        \n        model<- Arima(lx,order=c(p-1,d,q-1)) \n        ls[i,]= c(p-1,d,q-1,model$aic,model$bic,model$aicc)\n        i=i+1\n        #print(i)\n        \n      }\n      \n    }\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\ntemp <- temp[order(temp$BIC, decreasing = FALSE),] \nknitr::kable(temp)\n```\n\n::: {.cell-output-display}\n|   |  p|  d|  q|      AIC|      BIC|     AICc|\n|:--|--:|--:|--:|--------:|--------:|--------:|\n|2  |  0|  1|  1| 1129.146| 1137.892| 1129.166|\n|6  |  1|  1|  1| 1131.028| 1144.148| 1131.069|\n|3  |  0|  1|  2| 1131.045| 1144.165| 1131.087|\n|12 |  2|  1|  3| 1120.047| 1146.287| 1120.192|\n|10 |  2|  1|  1| 1130.116| 1147.609| 1130.185|\n|4  |  0|  1|  3| 1130.121| 1147.614| 1130.189|\n|7  |  1|  1|  2| 1133.117| 1150.610| 1133.186|\n|14 |  3|  1|  1| 1131.179| 1153.046| 1131.283|\n|8  |  1|  1|  3| 1131.272| 1153.139| 1131.376|\n|11 |  2|  1|  2| 1131.710| 1153.577| 1131.813|\n|16 |  3|  1|  3| 1126.189| 1156.802| 1126.383|\n|18 |  4|  1|  1| 1132.357| 1158.597| 1132.502|\n|15 |  3|  1|  2| 1132.897| 1159.137| 1133.042|\n|19 |  4|  1|  2| 1132.672| 1163.285| 1132.866|\n|20 |  4|  1|  3| 1134.670| 1169.657| 1134.920|\n|17 |  4|  1|  0| 1176.672| 1198.538| 1176.775|\n|13 |  3|  1|  0| 1187.101| 1204.594| 1187.170|\n|9  |  2|  1|  0| 1201.337| 1214.457| 1201.379|\n|5  |  1|  1|  0| 1255.509| 1264.255| 1255.529|\n|1  |  0|  1|  0| 1434.634| 1439.007| 1434.640|\n|21 | NA| NA| NA|       NA|       NA|       NA|\n|22 | NA| NA| NA|       NA|       NA|       NA|\n|23 | NA| NA| NA|       NA|       NA|       NA|\n|24 | NA| NA| NA|       NA|       NA|       NA|\n:::\n\n```{.r .cell-code}\ncat(\"\\n Best Model in terms of AIC: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Best Model in terms of AIC: \n```\n:::\n\n```{.r .cell-code}\ntemp[which.min(temp$AIC),] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   p d q      AIC      BIC     AICc\n12 2 1 3 1120.047 1146.287 1120.192\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\n Best Model in terms of AICc: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Best Model in terms of AICc: \n```\n:::\n\n```{.r .cell-code}\ntemp[which.min(temp$AICc),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   p d q      AIC      BIC     AICc\n12 2 1 3 1120.047 1146.287 1120.192\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\n Best Model in terms of BIC: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Best Model in terms of BIC: \n```\n:::\n\n```{.r .cell-code}\ntemp[which.min(temp$BIC),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  p d q      AIC      BIC     AICc\n2 0 1 1 1129.146 1137.892 1129.166\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\nModel summary and error metrics of ARIMA(0, 1, 1): \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nModel summary and error metrics of ARIMA(0, 1, 1): \n```\n:::\n\n```{.r .cell-code}\nfit <- Arima(lx, order=c(0,1,1)) # no drift included \nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: lx \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8436\ns.e.   0.0240\n\nsigma^2 = 0.3992:  log likelihood = -562.57\nAIC=1129.15   AICc=1129.17   BIC=1137.89\n\nTraining set error measures:\n                     ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.0182295 0.6307598 0.4949849 -Inf  Inf 0.7886882 0.01012716\n```\n:::\n:::\n\n\nThe best model with the lowest BIC metric is the ARIMA(0,1,1). This model is a pure moving average model with first-order differencing and a single lagged moving average term. Therefore, the model has no autoregressive terms, i.e., it does not use the past values of the variable to predict its future values. It uses only the difference between the current and previous values of the variable and the error term to make the forecast. Although, according to both AIC and AICc metrics, the ARIMA(2,1,3) model is better, we shall choose our model using the BIC metric because BIC is more stringent than AIC in penalizing the number of parameters used in the model, making it more effective in helping reduce overfitting.\n\nARIMA(2,1,3) is a time series model that involves taking the first-order difference of the series, using two Autoregressive (AR) terms and three Moving Average (MA) terms. This means that the model uses not only the past two values of the variable, but also the past three errors to make the forecast. The inclusion of the MA terms allows the model to capture the influence of random shocks or noise in the data. However, including too many autoregressive terms may lead to overfitting, which can result in poor forecast performance and we shall explore that in the next few sections\n\nThe choice between ARIMA(0,1,1) and ARIMA(2,1,3) depends on the nature of the data and the performance of the models in terms of RMSE or other error metrics. If the data has a clear trend, then including Autoregressive terms may improve the forecast accuracy. On the other hand, if the data is more random, then a simpler model like ARIMA(0,1,1) may be sufficient. There is a clear decreasing trend of monthly terrorist attacks from the 1970s to 2015, with random and/or seasonal fluctuations, but the number of attacks does start increasing sharply after 2015. Therefore, no single pattern is discerned along the entire series and, moreover, we shall be abiding by the principle of parsimony if we select ARIMA(0,1,1) as the best model.\n\nThe equation of the ARIMA(0,1,1) model is given by:\n\n$\\begin{equation}(1-B)(1-\\theta_1B)X_t = \\omega_t\\end{equation}$, giving us:\n\n$\\begin{equation}\\left(1-\\theta_1B+B-\\theta_1B^2\\right)X_t = \\omega_t\\end{equation}$, giving us:\n\n$\\begin{equation}\\left(1-\\theta_1B\\right)X_t - B\\left(1-\\theta_1B\\right)X_t = \\omega_t\\end{equation}$, giving us:\n\n$\\begin{equation}X_t - \\theta_1X_{t-1} - B\\left(X_{t-1}-\\theta_1X_{t-2}\\right) = \\omega_t\\end{equation}$, finally substituting the MA(1) values from the model's summary:\n\n$\\begin{equation}X_t = -0.8436X_{t-1} + X_{t-1} + 0.8436X_{t-2} + \\omega_t\\end{equation}$, where $(1-B)$ is the differencing operator, which represents the first-order difference of the series. $X_t$ is the time series, $\\theta_1$ is the parameter of the MA component, and $\\omega_t$ is the Gaussian white noise process. \n\nNote that $B$ is the backshift operator, which shifts the time series back by one period.\n\n### Model Diagnostics of ARIMA(0,1,1) {#ARIMA-Diag}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_output <- capture.output(sarima(lx, 0,1,1))\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(model_output[24:55], model_output[length(model_output)], sep = \"\\n\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nconverged\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, \n        REPORT = 1, reltol = tol))\n\nCoefficients:\n          ma1  constant\n      -0.8453   -0.0028\ns.e.   0.0239    0.0041\n\nsigma^2 estimated as 0.3982:  log likelihood = -562.33,  aic = 1130.67\n\n$degrees_of_freedom\n[1] 584\n\n$ttable\n         Estimate     SE  t.value p.value\nma1       -0.8453 0.0239 -35.3385  0.0000\nconstant  -0.0028 0.0041  -0.6943  0.4877\n\n$AIC\n[1] 1.929468\n\n$AICc\n[1] 1.929504\n\n$BIC\n[1] 1.951857\n```\n:::\n:::\n\n\nStandardized Residuals: Essentially stating that if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\n\nACF Of Residuals: Auto-correlation of the residuals. The only **q** value to inspect is 1.\n\nQ-Q Plot: The series follows a normal distribution pretty closely as even the tails seem to be on the normal line.\n\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value greater than 0.05, the residuals have no remaining autocorrelations.\n\nThe only MA term in the ARIMA(0,1,1) model is also significant at the $\\alpha$=5% level as shown by its p-value = 0. Let's check whether all terms in the ARIMA(2,1,3) model are significant or not.\n\n### Model Diagnostics of ARIMA(2,1,3) \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_output2 <- capture.output(sarima(lx, 2,1,3))\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(model_output2[205:239], model_output2[length(model_output2)], sep = \"\\n\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, \n        REPORT = 1, reltol = tol))\n\nCoefficients:\n         ar1      ar2      ma1     ma2      ma3  constant\n      0.8068  -0.5518  -1.6452  1.2913  -0.5429   -0.0026\ns.e.  0.4763   0.4308   0.4609  0.7776   0.3347    0.0036\n\nsigma^2 estimated as 0.3934:  log likelihood = -558.77,  aic = 1131.54\n\n$degrees_of_freedom\n[1] 580\n\n$ttable\n         Estimate     SE t.value p.value\nar1        0.8068 0.4763  1.6939  0.0908\nar2       -0.5518 0.4308 -1.2809  0.2007\nma1       -1.6452 0.4609 -3.5693  0.0004\nma2        1.2913 0.7776  1.6608  0.0973\nma3       -0.5429 0.3347 -1.6223  0.1053\nconstant  -0.0026 0.0036 -0.7029  0.4824\n\n$AIC\n[1] 1.93095\n\n$AICc\n[1] 1.931198\n\n$BIC\n[1] 1.983192\n```\n:::\n:::\n\n\nLike the ARIMA(0,1,1) output for the summary of residuals, the ARIMA(2,1,3) does as well, if not better. The ACF of residuals for ARIMA(2,1,3), although, has spikes less significant than ARIMA(0,1,1) and the p-values for Ljung-Box test for ARIMA(2,1,3) are higher than those of ARIMA(0,1,1). However, a key difference is that only the MA(1) term in the ARIMA(2,1,3) model is significant at the $\\alpha$=5% level as shown by its p-value = 0.0004 and all other terms are not significant. Therefore, a simpler model, ARIMA(0,1,1), would be a better fit to the log of monthly attacks series.\n\nLet's see what model is outputted by `auto.arima()`.\n\n### Checking Model Output of Log Monthly Attacks with auto.arima()\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit = auto.arima(lx, seasonal = FALSE)\ncat(\"Model metrics using auto.arima(): \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel metrics using auto.arima(): \n```\n:::\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: lx \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8436\ns.e.   0.0240\n\nsigma^2 = 0.3992:  log likelihood = -562.57\nAIC=1129.15   AICc=1129.17   BIC=1137.89\n\nTraining set error measures:\n                     ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.0182295 0.6307598 0.4949849 -Inf  Inf 0.7886882 0.01012716\n```\n:::\n:::\n\n\nFrom the above output, `auto.arima()` too outputted an ARIMA(0,1,1) model, which is is the best model returned by the `Arima()` function in terms of [lowest BIC](#best-fit). Some points to keep in mind when using these functions is as follows:\n\nThe `auto.arima()` function in R uses a stepwise algorithm to search through the space of possible ARIMA models and select the one with the lowest AIC value. While this approach can be computationally efficient and provide a good starting point for model selection, it does not necessarily always find the best possible model for a given time series.\n\nOn the other hand, the `Arima()` function in R allows us to specify the exact order of the ARIMA model and can be used to fit more complex models, such as those with seasonality, exogenous variables, or other constraints. By specifying the exact order of the model, we have more control over the modeling process and can potentially obtain a better fit to the data.\n\nIn summary, the `auto.arima()` function can be a useful tool for quickly identifying a potentially good model, but it is not a substitute for careful model selection and customization seen when using the `Arima()` function.\n\n### Forecasting ARIMA(0,1,1) and ARIMA(2,1,3)\n\n\n::: {.cell}\n\n```{.r .cell-code}\narimaModel_1 <- arima(lx, order = c(0,1,1))\narimaModel_2 <- arima(lx, order = c(2,1,3))\n\nforecast1=predict(arimaModel_1, length(test_series)) # make forecasts for 2 years ahead as given by length of test_series\nforecast2=predict(arimaModel_2, length(test_series))\n\n# Convert the time series and forecast objects to data frames\nts_df <- data.frame(date = time(monthly_attacks_ts), value = as.numeric(monthly_attacks_ts))\ntrain_df <- data.frame(date = time(monthly_attacks_ts)[1:587], value = as.numeric(lx))\nforecast1_df <- data.frame(date = time(monthly_attacks_ts)[588:612], value = forecast1$pred)\nforecast2_df <- data.frame(date = time(monthly_attacks_ts)[588:612], value = forecast2$pred)\n\n# Plot the time series and forecasts\nggplotly(ggplot() +\n    geom_line(data = train_df[500:588,], aes(x = date, y = value, \n              color = \"Actual Train Values\"), linetype = \"solid\", alpha=0.6, show.legend = TRUE) +\n    geom_point(data = train_df[500:588,], aes(x = date, y = value), \n               color = \"red\", shape = 16, alpha=0.4, show.legend = TRUE) +\n    geom_line(data = forecast1_df, aes(x = date, y = value, \n                                       color = \"ARIMA(0,1,1) Forecast\"), linetype = \"solid\", show.legend = TRUE) +\n    geom_line(data = forecast2_df, aes(x = date, y = value, \n                                       color = \"ARIMA(2,1,3) Forecast\"), linetype = \"solid\", show.legend = TRUE) +\n    geom_line(data = ts_df[588:612,], aes(x = date, y = log(value), \n                                       color = \"Actual Forecast Values\"), linetype = \"solid\", show.legend = TRUE) +\n    labs(x = \"Date\", y = \"Log of Number of Monthly Attacks\", title = \"Forecasting ARIMA(0,1,1) and ARIMA(2,1,3)\") +\n    theme_minimal() +\n    scale_color_manual(name = \"Forecast\", \n                       values = c(\"ARIMA(0,1,1) Forecast\" = \"blue\", \n                                  \"ARIMA(2,1,3) Forecast\" = \"green\",\n                                   \"Actual Forecast Values\" = \"orange\"),\n                       labels = c(\"ARIMA(0,1,1) Forecast\", \n                                  \"ARIMA(2,1,3) Forecast\",\n                                  \"Actual Forecast Values\")))\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"plotly html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-f7e7b93ac78d26755bf8\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-f7e7b93ac78d26755bf8\">{\"x\":{\"data\":[{\"x\":[2011.58333333333,2011.66666666667,2011.75,2011.83333333333,2011.91666666667,2012,2012.08333333333,2012.16666666667,2012.25,2012.33333333333,2012.41666666667,2012.5,2012.58333333333,2012.66666666667,2012.75,2012.83333333333,2012.91666666667,2013,2013.08333333333,2013.16666666667,2013.25,2013.33333333333,2013.41666666667,2013.5,2013.58333333333,2013.66666666667,2013.75,2013.83333333333,2013.91666666667,2014,2014.08333333333,2014.16666666667,2014.25,2014.33333333333,2014.41666666667,2014.5,2014.58333333333,2014.66666666667,2014.75,2014.83333333333,2014.91666666667,2015,2015.08333333333,2015.16666666667,2015.25,2015.33333333333,2015.41666666667,2015.5,2015.58333333333,2015.66666666667,2015.75,2015.83333333333,2015.91666666667,2016,2016.08333333333,2016.16666666667,2016.25,2016.33333333333,2016.41666666667,2016.5,2016.58333333333,2016.66666666667,2016.75,2016.83333333333,2016.91666666667,2017,2017.08333333333,2017.16666666667,2017.25,2017.33333333333,2017.41666666667,2017.5,2017.58333333333,2017.66666666667,2017.75,2017.83333333333,2017.91666666667,2018,2018.08333333333,2018.16666666667,2018.25,2018.33333333333,2018.41666666667,2018.5,2018.58333333333,2018.66666666667,2018.75,2018.83333333333,null],\"y\":[0,0.693147180559945,0,0.693147180559945,0,2.19722457733622,0,0,0.693147180559945,1.38629436111989,0.693147180559945,0.693147180559945,1.6094379124341,0.693147180559945,0,0.693147180559945,0,0.693147180559945,1.09861228866811,0,2.07944154167984,1.38629436111989,0,0.693147180559945,1.09861228866811,0.693147180559945,1.09861228866811,0.693147180559945,0,0,0,1.09861228866811,1.6094379124341,1.38629436111989,1.79175946922805,0,0.693147180559945,1.09861228866811,1.38629436111989,1.94591014905531,1.38629436111989,0.693147180559945,1.79175946922805,1.38629436111989,0,0.693147180559945,1.79175946922805,1.79175946922805,1.79175946922805,1.38629436111989,0.693147180559945,2.07944154167984,1.79175946922805,1.38629436111989,1.38629436111989,0.693147180559945,1.09861228866811,1.38629436111989,1.79175946922805,2.70805020110221,2.39789527279837,2.484906649788,2.19722457733622,1.79175946922805,1.38629436111989,2.30258509299405,2.07944154167984,1.6094379124341,2.19722457733622,2.19722457733622,1.6094379124341,1.79175946922805,1.6094379124341,1.79175946922805,1.94591014905531,1.09861228866811,1.6094379124341,1.38629436111989,1.38629436111989,1.94591014905531,1.6094379124341,1.94591014905531,0.693147180559945,2.39789527279837,1.79175946922805,1.6094379124341,3.17805383034795,2.30258509299405,null],\"text\":[\"date: 2011.583<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2011.667<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2011.750<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2011.833<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2011.917<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2012.000<br />value: 2.1972246<br />colour: Actual Train Values\",\"date: 2012.083<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2012.167<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2012.250<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2012.333<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2012.417<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2012.500<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2012.583<br />value: 1.6094379<br />colour: Actual Train Values\",\"date: 2012.667<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2012.750<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2012.833<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2012.917<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2013.000<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2013.083<br />value: 1.0986123<br />colour: Actual Train Values\",\"date: 2013.167<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2013.250<br />value: 2.0794415<br />colour: Actual Train Values\",\"date: 2013.333<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2013.417<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2013.500<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2013.583<br />value: 1.0986123<br />colour: Actual Train Values\",\"date: 2013.667<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2013.750<br />value: 1.0986123<br />colour: Actual Train Values\",\"date: 2013.833<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2013.917<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2014.000<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2014.083<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2014.167<br />value: 1.0986123<br />colour: Actual Train Values\",\"date: 2014.250<br />value: 1.6094379<br />colour: Actual Train Values\",\"date: 2014.333<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2014.417<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2014.500<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2014.583<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2014.667<br />value: 1.0986123<br />colour: Actual Train Values\",\"date: 2014.750<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2014.833<br />value: 1.9459101<br />colour: Actual Train Values\",\"date: 2014.917<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2015.000<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2015.083<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2015.167<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2015.250<br />value: 0.0000000<br />colour: Actual Train Values\",\"date: 2015.333<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2015.417<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2015.500<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2015.583<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2015.667<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2015.750<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2015.833<br />value: 2.0794415<br />colour: Actual Train Values\",\"date: 2015.917<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2016.000<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2016.083<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2016.167<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2016.250<br />value: 1.0986123<br />colour: Actual Train Values\",\"date: 2016.333<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2016.417<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2016.500<br />value: 2.7080502<br />colour: Actual Train Values\",\"date: 2016.583<br />value: 2.3978953<br />colour: Actual Train Values\",\"date: 2016.667<br />value: 2.4849066<br />colour: Actual Train Values\",\"date: 2016.750<br />value: 2.1972246<br />colour: Actual Train Values\",\"date: 2016.833<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2016.917<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2017.000<br />value: 2.3025851<br />colour: Actual Train Values\",\"date: 2017.083<br />value: 2.0794415<br />colour: Actual Train Values\",\"date: 2017.167<br />value: 1.6094379<br />colour: Actual Train Values\",\"date: 2017.250<br />value: 2.1972246<br />colour: Actual Train Values\",\"date: 2017.333<br />value: 2.1972246<br />colour: Actual Train Values\",\"date: 2017.417<br />value: 1.6094379<br />colour: Actual Train Values\",\"date: 2017.500<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2017.583<br />value: 1.6094379<br />colour: Actual Train Values\",\"date: 2017.667<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2017.750<br />value: 1.9459101<br />colour: Actual Train Values\",\"date: 2017.833<br />value: 1.0986123<br />colour: Actual Train Values\",\"date: 2017.917<br />value: 1.6094379<br />colour: Actual Train Values\",\"date: 2018.000<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2018.083<br />value: 1.3862944<br />colour: Actual Train Values\",\"date: 2018.167<br />value: 1.9459101<br />colour: Actual Train Values\",\"date: 2018.250<br />value: 1.6094379<br />colour: Actual Train Values\",\"date: 2018.333<br />value: 1.9459101<br />colour: Actual Train Values\",\"date: 2018.417<br />value: 0.6931472<br />colour: Actual Train Values\",\"date: 2018.500<br />value: 2.3978953<br />colour: Actual Train Values\",\"date: 2018.583<br />value: 1.7917595<br />colour: Actual Train Values\",\"date: 2018.667<br />value: 1.6094379<br />colour: Actual Train Values\",\"date: 2018.750<br />value: 3.1780538<br />colour: Actual Train Values\",\"date: 2018.833<br />value: 2.3025851<br />colour: Actual Train Values\",\"date:       NA<br />value:        NA<br />colour: Actual Train Values\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(127,127,127,0.6)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Actual Train Values\",\"legendgroup\":\"Actual Train Values\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[2011.58333333333,2011.66666666667,2011.75,2011.83333333333,2011.91666666667,2012,2012.08333333333,2012.16666666667,2012.25,2012.33333333333,2012.41666666667,2012.5,2012.58333333333,2012.66666666667,2012.75,2012.83333333333,2012.91666666667,2013,2013.08333333333,2013.16666666667,2013.25,2013.33333333333,2013.41666666667,2013.5,2013.58333333333,2013.66666666667,2013.75,2013.83333333333,2013.91666666667,2014,2014.08333333333,2014.16666666667,2014.25,2014.33333333333,2014.41666666667,2014.5,2014.58333333333,2014.66666666667,2014.75,2014.83333333333,2014.91666666667,2015,2015.08333333333,2015.16666666667,2015.25,2015.33333333333,2015.41666666667,2015.5,2015.58333333333,2015.66666666667,2015.75,2015.83333333333,2015.91666666667,2016,2016.08333333333,2016.16666666667,2016.25,2016.33333333333,2016.41666666667,2016.5,2016.58333333333,2016.66666666667,2016.75,2016.83333333333,2016.91666666667,2017,2017.08333333333,2017.16666666667,2017.25,2017.33333333333,2017.41666666667,2017.5,2017.58333333333,2017.66666666667,2017.75,2017.83333333333,2017.91666666667,2018,2018.08333333333,2018.16666666667,2018.25,2018.33333333333,2018.41666666667,2018.5,2018.58333333333,2018.66666666667,2018.75,2018.83333333333,null],\"y\":[0,0.693147180559945,0,0.693147180559945,0,2.19722457733622,0,0,0.693147180559945,1.38629436111989,0.693147180559945,0.693147180559945,1.6094379124341,0.693147180559945,0,0.693147180559945,0,0.693147180559945,1.09861228866811,0,2.07944154167984,1.38629436111989,0,0.693147180559945,1.09861228866811,0.693147180559945,1.09861228866811,0.693147180559945,0,0,0,1.09861228866811,1.6094379124341,1.38629436111989,1.79175946922805,0,0.693147180559945,1.09861228866811,1.38629436111989,1.94591014905531,1.38629436111989,0.693147180559945,1.79175946922805,1.38629436111989,0,0.693147180559945,1.79175946922805,1.79175946922805,1.79175946922805,1.38629436111989,0.693147180559945,2.07944154167984,1.79175946922805,1.38629436111989,1.38629436111989,0.693147180559945,1.09861228866811,1.38629436111989,1.79175946922805,2.70805020110221,2.39789527279837,2.484906649788,2.19722457733622,1.79175946922805,1.38629436111989,2.30258509299405,2.07944154167984,1.6094379124341,2.19722457733622,2.19722457733622,1.6094379124341,1.79175946922805,1.6094379124341,1.79175946922805,1.94591014905531,1.09861228866811,1.6094379124341,1.38629436111989,1.38629436111989,1.94591014905531,1.6094379124341,1.94591014905531,0.693147180559945,2.39789527279837,1.79175946922805,1.6094379124341,3.17805383034795,2.30258509299405,null],\"text\":[\"date: 2011.583<br />value: 0.0000000\",\"date: 2011.667<br />value: 0.6931472\",\"date: 2011.750<br />value: 0.0000000\",\"date: 2011.833<br />value: 0.6931472\",\"date: 2011.917<br />value: 0.0000000\",\"date: 2012.000<br />value: 2.1972246\",\"date: 2012.083<br />value: 0.0000000\",\"date: 2012.167<br />value: 0.0000000\",\"date: 2012.250<br />value: 0.6931472\",\"date: 2012.333<br />value: 1.3862944\",\"date: 2012.417<br />value: 0.6931472\",\"date: 2012.500<br />value: 0.6931472\",\"date: 2012.583<br />value: 1.6094379\",\"date: 2012.667<br />value: 0.6931472\",\"date: 2012.750<br />value: 0.0000000\",\"date: 2012.833<br />value: 0.6931472\",\"date: 2012.917<br />value: 0.0000000\",\"date: 2013.000<br />value: 0.6931472\",\"date: 2013.083<br />value: 1.0986123\",\"date: 2013.167<br />value: 0.0000000\",\"date: 2013.250<br />value: 2.0794415\",\"date: 2013.333<br />value: 1.3862944\",\"date: 2013.417<br />value: 0.0000000\",\"date: 2013.500<br />value: 0.6931472\",\"date: 2013.583<br />value: 1.0986123\",\"date: 2013.667<br />value: 0.6931472\",\"date: 2013.750<br />value: 1.0986123\",\"date: 2013.833<br />value: 0.6931472\",\"date: 2013.917<br />value: 0.0000000\",\"date: 2014.000<br />value: 0.0000000\",\"date: 2014.083<br />value: 0.0000000\",\"date: 2014.167<br />value: 1.0986123\",\"date: 2014.250<br />value: 1.6094379\",\"date: 2014.333<br />value: 1.3862944\",\"date: 2014.417<br />value: 1.7917595\",\"date: 2014.500<br />value: 0.0000000\",\"date: 2014.583<br />value: 0.6931472\",\"date: 2014.667<br />value: 1.0986123\",\"date: 2014.750<br />value: 1.3862944\",\"date: 2014.833<br />value: 1.9459101\",\"date: 2014.917<br />value: 1.3862944\",\"date: 2015.000<br />value: 0.6931472\",\"date: 2015.083<br />value: 1.7917595\",\"date: 2015.167<br />value: 1.3862944\",\"date: 2015.250<br />value: 0.0000000\",\"date: 2015.333<br />value: 0.6931472\",\"date: 2015.417<br />value: 1.7917595\",\"date: 2015.500<br />value: 1.7917595\",\"date: 2015.583<br />value: 1.7917595\",\"date: 2015.667<br />value: 1.3862944\",\"date: 2015.750<br />value: 0.6931472\",\"date: 2015.833<br />value: 2.0794415\",\"date: 2015.917<br />value: 1.7917595\",\"date: 2016.000<br />value: 1.3862944\",\"date: 2016.083<br />value: 1.3862944\",\"date: 2016.167<br />value: 0.6931472\",\"date: 2016.250<br />value: 1.0986123\",\"date: 2016.333<br />value: 1.3862944\",\"date: 2016.417<br />value: 1.7917595\",\"date: 2016.500<br />value: 2.7080502\",\"date: 2016.583<br />value: 2.3978953\",\"date: 2016.667<br />value: 2.4849066\",\"date: 2016.750<br />value: 2.1972246\",\"date: 2016.833<br />value: 1.7917595\",\"date: 2016.917<br />value: 1.3862944\",\"date: 2017.000<br />value: 2.3025851\",\"date: 2017.083<br />value: 2.0794415\",\"date: 2017.167<br />value: 1.6094379\",\"date: 2017.250<br />value: 2.1972246\",\"date: 2017.333<br />value: 2.1972246\",\"date: 2017.417<br />value: 1.6094379\",\"date: 2017.500<br />value: 1.7917595\",\"date: 2017.583<br />value: 1.6094379\",\"date: 2017.667<br />value: 1.7917595\",\"date: 2017.750<br />value: 1.9459101\",\"date: 2017.833<br />value: 1.0986123\",\"date: 2017.917<br />value: 1.6094379\",\"date: 2018.000<br />value: 1.3862944\",\"date: 2018.083<br />value: 1.3862944\",\"date: 2018.167<br />value: 1.9459101\",\"date: 2018.250<br />value: 1.6094379\",\"date: 2018.333<br />value: 1.9459101\",\"date: 2018.417<br />value: 0.6931472\",\"date: 2018.500<br />value: 2.3978953\",\"date: 2018.583<br />value: 1.7917595\",\"date: 2018.667<br />value: 1.6094379\",\"date: 2018.750<br />value: 3.1780538\",\"date: 2018.833<br />value: 2.3025851\",\"date:       NA<br />value:        NA\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(255,0,0,1)\",\"opacity\":0.4,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(255,0,0,1)\"}},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[2018.91666666667,2019,2019.08333333333,2019.16666666667,2019.25,2019.33333333333,2019.41666666667,2019.5,2019.58333333333,2019.66666666667,2019.75,2019.83333333333,2019.91666666667,2020,2020.08333333333,2020.16666666667,2020.25,2020.33333333333,2020.41666666667,2020.5,2020.58333333333,2020.66666666667,2020.75,2020.83333333333,2020.91666666667],\"y\":[1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963,1.9778211122963],\"text\":[\"date: 2018.917<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.000<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.083<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.167<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.250<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.333<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.417<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.500<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.583<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.667<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.750<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.833<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2019.917<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.000<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.083<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.167<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.250<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.333<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.417<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.500<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.583<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.667<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.750<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.833<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\",\"date: 2020.917<br />value: 1.977821<br />colour: ARIMA(0,1,1) Forecast\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,255,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"ARIMA(0,1,1) Forecast\",\"legendgroup\":\"ARIMA(0,1,1) Forecast\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[2018.91666666667,2019,2019.08333333333,2019.16666666667,2019.25,2019.33333333333,2019.41666666667,2019.5,2019.58333333333,2019.66666666667,2019.75,2019.83333333333,2019.91666666667,2020,2020.08333333333,2020.16666666667,2020.25,2020.33333333333,2020.41666666667,2020.5,2020.58333333333,2020.66666666667,2020.75,2020.83333333333,2020.91666666667],\"y\":[1.96185854059495,1.95196869136936,1.9446059758522,1.94610137408539,1.95457971865533,1.96212861249843,1.96215249765788,1.95510353014507,1.94763982994639,1.9463663895863,1.95201641469742,1.95917428356553,1.96143583984688,1.9571155288983,1.95043540852534,1.94743209732025,1.95052166153252,1.95659764081797,1.96011653540487,1.95813740195251,1.95275049968133,1.94891843513527,1.94992122296028,1.95457091193706,1.95853967767191],\"text\":[\"date: 2018.917<br />value: 1.961859<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.000<br />value: 1.951969<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.083<br />value: 1.944606<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.167<br />value: 1.946101<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.250<br />value: 1.954580<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.333<br />value: 1.962129<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.417<br />value: 1.962152<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.500<br />value: 1.955104<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.583<br />value: 1.947640<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.667<br />value: 1.946366<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.750<br />value: 1.952016<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.833<br />value: 1.959174<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2019.917<br />value: 1.961436<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.000<br />value: 1.957116<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.083<br />value: 1.950435<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.167<br />value: 1.947432<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.250<br />value: 1.950522<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.333<br />value: 1.956598<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.417<br />value: 1.960117<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.500<br />value: 1.958137<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.583<br />value: 1.952750<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.667<br />value: 1.948918<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.750<br />value: 1.949921<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.833<br />value: 1.954571<br />colour: ARIMA(2,1,3) Forecast\",\"date: 2020.917<br />value: 1.958540<br />colour: ARIMA(2,1,3) Forecast\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,255,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"ARIMA(2,1,3) Forecast\",\"legendgroup\":\"ARIMA(2,1,3) Forecast\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[2018.91666666667,2019,2019.08333333333,2019.16666666667,2019.25,2019.33333333333,2019.41666666667,2019.5,2019.58333333333,2019.66666666667,2019.75,2019.83333333333,2019.91666666667,2020,2020.08333333333,2020.16666666667,2020.25,2020.33333333333,2020.41666666667,2020.5,2020.58333333333,2020.66666666667,2020.75,2020.83333333333,2020.91666666667],\"y\":[0.693147180559945,1.09861228866811,0,2.77258872223978,2.484906649788,2.07944154167984,1.79175946922805,1.38629436111989,1.94591014905531,0,0.693147180559945,1.09861228866811,2.19722457733622,1.6094379124341,2.07944154167984,1.79175946922805,1.6094379124341,2.83321334405622,2.63905732961526,2.07944154167984,2.30258509299405,2.39789527279837,1.94591014905531,1.94591014905531,1.6094379124341],\"text\":[\"date: 2018.917<br />log(value): 0.6931472<br />colour: Actual Forecast Values\",\"date: 2019.000<br />log(value): 1.0986123<br />colour: Actual Forecast Values\",\"date: 2019.083<br />log(value): 0.0000000<br />colour: Actual Forecast Values\",\"date: 2019.167<br />log(value): 2.7725887<br />colour: Actual Forecast Values\",\"date: 2019.250<br />log(value): 2.4849066<br />colour: Actual Forecast Values\",\"date: 2019.333<br />log(value): 2.0794415<br />colour: Actual Forecast Values\",\"date: 2019.417<br />log(value): 1.7917595<br />colour: Actual Forecast Values\",\"date: 2019.500<br />log(value): 1.3862944<br />colour: Actual Forecast Values\",\"date: 2019.583<br />log(value): 1.9459101<br />colour: Actual Forecast Values\",\"date: 2019.667<br />log(value): 0.0000000<br />colour: Actual Forecast Values\",\"date: 2019.750<br />log(value): 0.6931472<br />colour: Actual Forecast Values\",\"date: 2019.833<br />log(value): 1.0986123<br />colour: Actual Forecast Values\",\"date: 2019.917<br />log(value): 2.1972246<br />colour: Actual Forecast Values\",\"date: 2020.000<br />log(value): 1.6094379<br />colour: Actual Forecast Values\",\"date: 2020.083<br />log(value): 2.0794415<br />colour: Actual Forecast Values\",\"date: 2020.167<br />log(value): 1.7917595<br />colour: Actual Forecast Values\",\"date: 2020.250<br />log(value): 1.6094379<br />colour: Actual Forecast Values\",\"date: 2020.333<br />log(value): 2.8332133<br />colour: Actual Forecast Values\",\"date: 2020.417<br />log(value): 2.6390573<br />colour: Actual Forecast Values\",\"date: 2020.500<br />log(value): 2.0794415<br />colour: Actual Forecast Values\",\"date: 2020.583<br />log(value): 2.3025851<br />colour: Actual Forecast Values\",\"date: 2020.667<br />log(value): 2.3978953<br />colour: Actual Forecast Values\",\"date: 2020.750<br />log(value): 1.9459101<br />colour: Actual Forecast Values\",\"date: 2020.833<br />log(value): 1.9459101<br />colour: Actual Forecast Values\",\"date: 2020.917<br />log(value): 1.6094379<br />colour: Actual Forecast Values\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(255,165,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Actual Forecast Values\",\"legendgroup\":\"Actual Forecast Values\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":43.7625570776256,\"r\":7.30593607305936,\"b\":40.1826484018265,\"l\":31.4155251141553},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Forecasting ARIMA(0,1,1) and ARIMA(2,1,3)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[2011.11666666667,2021.38333333333],\"tickmode\":\"array\",\"ticktext\":[\"2012\",\"2014\",\"2016\",\"2018\",\"2020\"],\"tickvals\":[2012,2014,2016,2018,2020],\"categoryorder\":\"array\",\"categoryarray\":[\"2012\",\"2014\",\"2016\",\"2018\",\"2020\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Date\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-0.158902691517397,3.33695652186534],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"1\",\"2\",\"3\"],\"tickvals\":[0,1,2,3],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"1\",\"2\",\"3\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Log of Number of Monthly Attacks\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":true,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895},\"title\":{\"text\":\"Forecast\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"76392c0d6738\":{\"x\":{},\"y\":{},\"colour\":{},\"type\":\"scatter\"},\"763923f3a420\":{\"x\":{},\"y\":{}},\"7639509c4350\":{\"x\":{},\"y\":{},\"colour\":{}},\"763943076288\":{\"x\":{},\"y\":{},\"colour\":{}},\"763919d5f119\":{\"x\":{},\"y\":{},\"colour\":{}}},\"cur_data\":\"76392c0d6738\",\"visdat\":{\"76392c0d6738\":[\"function (y) \",\"x\"],\"763923f3a420\":[\"function (y) \",\"x\"],\"7639509c4350\":[\"function (y) \",\"x\"],\"763943076288\":[\"function (y) \",\"x\"],\"763919d5f119\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nFrom the above graph, we can note that the forecasted number of attacks remains constant at around 1 for both models on the test set (October 2010 to December 2020). This performance is not what was expected and, hence, it is possible that the models are not able to capture the underlying patterns in the data. This can be due to a variety of reasons, such as insufficient data and the models not being complex enough to capture the variation in the data. It is, however, pragmatic to check whether the `sarima.for()` function's predictions may forecast differently. Let us find out below.\n\n### Forecasting ARIMA(0,1,1) using sarima.for()\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_monthly_attacks <- ts(lx, start = c(1970, 1), frequency = 12) # Objects of class <numeric> are not supported by autoplot.\nsarima.for(ts(train_df$value, start = c(1970, 1), frequency = 12), 24, p = 0, d = 1, q = 1, main = \"Forecasting ARIMA(0,1,1) using sarima.for()\") \n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n$pred\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2018                                                                        \n2019 1.954087 1.951260 1.948432 1.945605 1.942778 1.939950 1.937123 1.934296\n2020 1.920159 1.917332 1.914505 1.911678 1.908850 1.906023 1.903196 1.900368\n          Sep      Oct      Nov      Dec\n2018                            1.956914\n2019 1.931469 1.928641 1.925814 1.922987\n2020 1.897541 1.894714 1.891886         \n\n$se\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2018                                                                      \n2019 0.6385446 0.6459664 0.6533040 0.6605600 0.6677372 0.6748381 0.6818650\n2020 0.7225930 0.7291599 0.7356681 0.7421193 0.7485148 0.7548562 0.7611448\n           Aug       Sep       Oct       Nov       Dec\n2018                                         0.6310354\n2019 0.6888203 0.6957060 0.7025242 0.7092769 0.7159659\n2020 0.7673818 0.7735685 0.7797062 0.7857959          \n```\n:::\n:::\n\n\nLike the previous forecast, we can note that `sarima.for()` too does not accurately capture the inherent randomness and/or seasonality in the series and, hence, it outputs a highly linear, downward trending forecast. As per its 95% confidence bound, the number of attacks will fluctuate anywhere between 3 to 12 attacks every month from 2019 to end of 2020  (keep in mind that the plot is log of monthly attacks). \n\n### Comparing ARIMA(0,1,1) with Benchmarks\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(log_monthly_attacks) +\n  autolayer(meanf(log_monthly_attacks, h=24),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(log_monthly_attacks, h=24),\n            series=\"NaÃ¯ve\", PI=FALSE) +\n  autolayer(snaive(log_monthly_attacks, h=24),\n            series=\"SNaÃ¯ve\", PI=FALSE)+\n  autolayer(rwf(log_monthly_attacks, h=24, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n  autolayer(forecast(Arima(log_monthly_attacks, order=c(0,1,1)), 24), \n            series=\"ARIMA(0,1,1)\",PI=FALSE) +\n  guides(colour=guide_legend(title=\"Forecast\")) +\n  ylab(\"Log of Monthly Attacks\") + ggtitle(\"Forecasting ARIMA(0,1,1) and Benchmarks\") + theme_minimal()\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncat(\"ARIMA(0,1,1) model metrics: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nARIMA(0,1,1) model metrics: \n```\n:::\n\n```{.r .cell-code}\nfit <- Arima(log_monthly_attacks, order=c(0,1,1))\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: log_monthly_attacks \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8436\ns.e.   0.0240\n\nsigma^2 = 0.3992:  log likelihood = -562.57\nAIC=1129.15   AICc=1129.17   BIC=1137.89\n\nTraining set error measures:\n                     ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.0182295 0.6307598 0.4949849 -Inf  Inf 0.7143174 0.01012716\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\nMean metrics: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMean metrics: \n```\n:::\n\n```{.r .cell-code}\nf1 <- meanf(log_monthly_attacks, h=24) \n\ncheckresiduals(f1)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from Mean\nQ* = 2327.6, df = 23, p-value < 2.2e-16\n\nModel df: 1.   Total lags used: 24\n```\n:::\n\n```{.r .cell-code}\naccuracy(f1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       ME      RMSE       MAE  MPE MAPE      MASE     ACF1\nTraining set 1.113627e-15 0.8556503 0.6744582 -Inf  Inf 0.9733169 0.534751\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\nSnaive metrics: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSnaive metrics: \n```\n:::\n\n```{.r .cell-code}\nf2 <- snaive(log_monthly_attacks, h=24) \n\ncheckresiduals(f2)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from Seasonal naive method\nQ* = 173.01, df = 24, p-value < 2.2e-16\n\nModel df: 0.   Total lags used: 24\n```\n:::\n\n```{.r .cell-code}\naccuracy(f2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      ME      RMSE       MAE  MPE MAPE MASE      ACF1\nTraining set -0.03643642 0.8807625 0.6929481 -Inf  Inf    1 0.1556335\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\nRandom Walk metrics: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nRandom Walk metrics: \n```\n:::\n\n```{.r .cell-code}\nf3 <- rwf(log_monthly_attacks, h=24) \n\ncheckresiduals(f3)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-10-4.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from Random walk\nQ* = 178.32, df = 24, p-value < 2.2e-16\n\nModel df: 0.   Total lags used: 24\n```\n:::\n\n```{.r .cell-code}\naccuracy(f3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.001694969 0.8215562 0.6276053 -Inf  Inf 0.9057032 -0.5152558\n```\n:::\n:::\n\n\nFrom the above plot, only the Snaive benchmark method's forecasts seem more plausible compared to that of the ARIMA(0,1,1) model. The forecasts produced from the Snaive benchmark have the greatest amount of fluctuations or seasonality in a higher range of number of monthly attacks. However, the metrics paint a different story. The ARIMA(0,1,1) model's training error measures are better than those of all the benchmarks. There are several reasons for this phenomenon:\n\nModel Assumptions: The ARIMA model assumes that the data is stationary, which means that the mean and variance of the data do not change over time. If the data violates this assumption, the ARIMA model may not perform well. In contrast, the Snaive model does not assume stationarity, which may make it more robust to non-stationary data.\n\nParameter Estimation: The ARIMA model has three parameters (p, d, q) that need to be estimated, whereas the Snaive model has only one parameter (the seasonality). It is possible that the parameter estimation process for the ARIMA model was not optimal, leading to suboptimal forecast performance.\n\nForecast Horizon: The Snaive model may perform better than the ARIMA model for shorter forecast horizons, while the ARIMA model may perform better for longer forecast horizons. This is because the Snaive model assumes that the future values of the time series will be the same as the past values at the same time of year, which may be a reasonable assumption for short forecast horizons, but not for longer ones.\n\n## Global Terrorism Database SARIMA Modeling\n\n### Visualizing Seasonal Components of Monthly Attacks \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize Seasonal Component\nattacks.s=decompose(monthly_attacks_ts)$seasonal\nplot(attacks.s, axes=FALSE, main='Seasonal Component of Number of Monthly Terrorist Attacks in the US Over Time', xlab=\"Time\", type='c') \nQuarters = c(\"1\",\"2\",\"3\",\"4\") \npoints(attacks.s, pch=Quarters, cex=1, font=4, col=1:4)\naxis(1, 1:4); abline(v=1:4, lty=2, col=gray(.7))\naxis(2); box()\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/sznlcomp-1.png){width=672}\n:::\n:::\n\n\nFrom the above seasonal component graph of the number of monthly terrorist attacks, we notice there does exist some level of seasonality in the original series. The seasonal component graph illustrates the degree of seasonal variation in the number of terrorist attacks. The magnitude of the seasonal variation is shown on the y-axis of the graph, and it indicates how much the number of terrorist attacks deviates from the average value for each season. The graph shows a repeating pattern in the number of terrorist attacks over time, with clear peaks in the first and second quarters and troughs in the third quarter. This pattern implies that the number of terrorist attacks in the US *might* be influenced by the season of the year. \n\n### Visualizing Seasonally Differenced Monthly Attacks \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Seasonal differenced\nattacks.diff=diff(monthly_attacks_ts,12)\nplot(attacks.diff, axes=FALSE, main='Number of Monthly Terrorist Attacks (S. differenced)',type='c') #with type='c' I get dashed lines\nQuarters = c(\"1\",\"2\",\"3\",\"4\") \npoints(attacks.diff, pch=Quarters, cex=1, font=4, col=1:4)\naxis(1, 1:4); abline(v=1:4, lty=2, col=gray(.7))\naxis(2); box()\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/sznldiff-1.png){width=672}\n:::\n:::\n\n\n### ACF and PACF Plots of Seasonally Differenced Monthly Attacks \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmonthly_attacks_ts %>% \n  diff(lag=12) %>% \n  ggtsdisplay(main=\"ACF and PACF Plots of First Seasonal Differenced Monthly Attacks\")\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/pacfsznldiff-1.png){width=672}\n:::\n:::\n\n\nAfter first ordinary differencing the original series @ACF, we saw a lot of seasonal correlation left, suggesting that first order differencing did not help in transforming the raw data into a stationary series. This differenced series cannot be used for building a robust SARIMA model. Therefore, a seasonal differencing on the original monthly attacks was performed above and we can still notice some correlation left, but lesser compared to when the raw series was differenced with first order. Therefore, it could be that D=1 and d=0. Letâ€™s keep this as one option and let's proceed with performing both seasonal differencing and first-order differencing the raw monthly attacks series.\n\n### ACF and PACF Plots of Seasonally and First Order Differenced Monthly Attacks \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmonthly_attacks_ts %>% \n  diff(lag=12) %>% \n  diff() %>%\n  ggtsdisplay(main=\"ACF and PACF Plots of Seasonally and First Order Differenced Monthly Attacks\")\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/pacfsznlfodiff-1.png){width=672}\n:::\n:::\n\n\nAfter both seasonal differencing and ordinary differencing together the raw data, the ACF and PACF plots seem to portray the least correlation than the individual differencing methods. Next, we shall difference and select the relevant p,d,q,P,D,Q values from the original monthly attacks series for our SARIMA model. \n\nFrom the seasonal differencing and ordinary differencing (together) ACF and PACF plots, the following combinations for p,d,q,P,D,Q are:\n\nq values obtained from ACF = 0,1,2,3,4\nQ values obtained from ACF = 1\np values obtained from PACF = 0,1,2,3,4\nP values obtained from PACF = 1,2\nd (Difference) = 1\nD (Seasonal Difference) = 1\n\n### Fitting ARIMA(p,d,q)(P,D,Q)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n######################## Check for different combinations ########\n\n\n#write a funtion\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  #K=(p2+1)*(q2+1)*(P2+1)*(Q2+1)\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*29),nrow=29)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q<=9) # parsimonious principle\n          {\n            \n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n            }\n          }\n        }\n      }\n    }\n  \n  \n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# q=0,1,2,3,4; Q=1 and PACF plot: p=0,1,2,3,4; P=1,2; D=1 and d=1\n\noutput=SARIMA.c(p1=1,p2=5,q1=1,q2=5,P1=1,P2=3,Q1=1,Q2=2,data=monthly_attacks_ts)\n#output\n\nknitr::kable(output)\n```\n\n::: {.cell-output-display}\n|  p|  d|  q|  P|  D|  Q|      AIC|      BIC|     AICc|\n|--:|--:|--:|--:|--:|--:|--------:|--------:|--------:|\n|  0|  1|  0|  0|  1|  0| 3952.891| 3957.286| 3952.897|\n|  0|  1|  0|  0|  1|  1| 3670.269| 3679.059| 3670.289|\n|  0|  1|  0|  1|  1|  0| 3827.797| 3836.587| 3827.817|\n|  0|  1|  0|  1|  1|  1| 3670.336| 3683.521| 3670.376|\n|  0|  1|  0|  2|  1|  0| 3765.751| 3778.937| 3765.791|\n|  0|  1|  0|  2|  1|  1| 3671.380| 3688.961| 3671.447|\n|  0|  1|  1|  0|  1|  0| 3705.459| 3714.249| 3705.479|\n|  0|  1|  1|  0|  1|  1| 3495.035| 3508.220| 3495.075|\n|  0|  1|  1|  1|  1|  0| 3596.169| 3609.355| 3596.209|\n|  0|  1|  1|  1|  1|  1| 3492.557| 3510.138| 3492.625|\n|  0|  1|  1|  2|  1|  0| 3570.165| 3587.746| 3570.232|\n|  0|  1|  2|  0|  1|  0| 3701.229| 3714.415| 3701.269|\n|  0|  1|  2|  0|  1|  1| 3493.391| 3510.972| 3493.458|\n|  0|  1|  2|  1|  1|  0| 3595.313| 3612.894| 3595.381|\n|  0|  1|  3|  0|  1|  0| 3699.991| 3717.572| 3700.058|\n|  1|  1|  0|  0|  1|  0| 3818.806| 3827.596| 3818.826|\n|  1|  1|  0|  0|  1|  1| 3553.235| 3566.421| 3553.276|\n|  1|  1|  0|  1|  1|  0| 3693.837| 3707.023| 3693.878|\n|  1|  1|  0|  1|  1|  1| 3552.817| 3570.398| 3552.884|\n|  1|  1|  0|  2|  1|  0| 3651.212| 3668.793| 3651.279|\n|  1|  1|  1|  0|  1|  0| 3700.223| 3713.408| 3700.263|\n|  1|  1|  1|  0|  1|  1| 3492.442| 3510.023| 3492.510|\n|  1|  1|  1|  1|  1|  0| 3594.929| 3612.510| 3594.996|\n|  1|  1|  2|  0|  1|  0| 3704.894| 3722.475| 3704.961|\n|  2|  1|  0|  0|  1|  0| 3777.584| 3790.770| 3777.624|\n|  2|  1|  0|  0|  1|  1| 3521.643| 3539.224| 3521.710|\n|  2|  1|  0|  1|  1|  0| 3654.644| 3672.225| 3654.712|\n|  2|  1|  1|  0|  1|  0| 3700.164| 3717.745| 3700.232|\n|  3|  1|  0|  0|  1|  0| 3772.136| 3789.717| 3772.204|\n:::\n\n```{.r .cell-code}\ncat(\"\\n Best Model in terms of AIC: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Best Model in terms of AIC: \n```\n:::\n\n```{.r .cell-code}\noutput[which.min(output$AIC),] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\n Best Model in terms of AICc: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Best Model in terms of AICc: \n```\n:::\n\n```{.r .cell-code}\noutput[which.min(output$AICc),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n```\n:::\n\n```{.r .cell-code}\ncat(\"\\n Best Model in terms of BIC: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Best Model in terms of BIC: \n```\n:::\n\n```{.r .cell-code}\noutput[which.min(output$BIC),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  p d q P D Q      AIC     BIC     AICc\n8 0 1 1 0 1 1 3495.035 3508.22 3495.075\n```\n:::\n:::\n\n\nThe best model with the lowest BIC metric is the SARIMA(0,1,1,0,1,1) model. Although, according to both AIC and AICc metrics, the SARIMA(1,1,1,0,1,1) is better, we shall choose our model using the BIC metric because BIC is more stringent than AIC in penalizing the number of parameters used in the model, making it more effective in helping reduce overfitting. The equation of the SARIMA(0,1,1,0,1,1) model is given by:\n\n$\\begin{equation}(1-B)(1-B^1)y_t = \\delta + (1+\\phi_1B)(1-\\theta_1B-\\theta_2B^2)w_t\\end{equation}$, where $(1-B)$ and $(1-B^1)$ are the differencing operators, which represent the first-order difference of the series. $y_t$ is the time series, $\\delta$ is the drift term, $\\phi_1$ and $\\theta_1$, $\\theta_2$ are the parameters of the AR and MA parts, respectively, and $w_t$ is the Gaussian white noise process.\n\nNote that $B$ is the backshift operator, which shifts the time series back by one period.\n\n### Model Diagnostics of ARIMA(0,1,1)(0,1,1)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_output <- capture.output(sarima(monthly_attacks_ts, 0,1,1,0,1,1,12))\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nStandardized Residuals: Essentially stating if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\n\nACF Of Residuals: However, looking at the ACF of the Residuals gives us a definitive answer to whether the model is stationary. Because some spikes are not within the significance limits, the model is not being able to capture all the signal in the data. In fact, the [ARIMA(1,1,2) model's diagnostics](#ARIMA-Diag) are better than that of ARIMA(0,1,1)(0,1,1) above.\n\nQ-Q Plot: The series weakly follows a normal distribution as the tails waver away significantly from the normal line.\n\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value less than 0.05, residuals have remaining autocorrelations.\n\n### Forecast for the next 3 years using ARIMA(0,1,1)(0,1,1)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- Arima(monthly_attacks_ts, order=c(0,1,1), seasonal=c(0,1,1))\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n```\n:::\n\n```{.r .cell-code}\nfit %>% forecast(h=36) %>% autoplot() #next 3 years\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### Comparing ARIMA(0,1,1)(0,1,1) with benchmarks\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"Best model metrics: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest model metrics: \n```\n:::\n\n```{.r .cell-code}\nfit <- Arima(monthly_attacks_ts, order=c(0,1,1), seasonal=c(0,1,1))\n\nautoplot(monthly_attacks_ts) +\n  autolayer(meanf(monthly_attacks_ts, h=36),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(monthly_attacks_ts, h=36),\n            series=\"NaÃ¯ve\", PI=FALSE) +\n  autolayer(snaive(monthly_attacks_ts, h=36),\n            series=\"SNaÃ¯ve\", PI=FALSE)+\n  autolayer(rwf(monthly_attacks_ts, h=36, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n  autolayer(forecast(fit,36), \n            series=\"fit\",PI=FALSE) +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncat(\"Best model metrics: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest model metrics: \n```\n:::\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n```\n:::\n\n```{.r .cell-code}\ncat(\"Snaive metrics: \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSnaive metrics: \n```\n:::\n\n```{.r .cell-code}\nf2 <- snaive(monthly_attacks_ts, h=36) \n\naccuracy(f2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     ME     RMSE      MAE  MPE MAPE MASE      ACF1\nTraining set -0.6016667 6.093029 3.808333 -Inf  Inf    1 0.4168619\n```\n:::\n:::\n\n\n### Seasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 1 step ahead forecasts \n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 75 # minimum data length for fitting a model \nn <- length(monthly_attacks_ts)\n#n-k # rest of the observations\n\nset.seed(133)\n\nfarima1 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(0,1,1),seasonal=c(0,1,1)), h=h)}\ne <- tsCV(monthly_attacks_ts, farima1, h=1)\n\nMAE1 <-abs(mean(e,na.rm=TRUE))\ncat(\"MAE for ARIMA(0,1,1)(0,1,1) is: \", MAE1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE for ARIMA(0,1,1)(0,1,1) is:  2.155092\n```\n:::\n\n```{.r .cell-code}\nRMSE1=sqrt(mean(e^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"\\nRMSE for ARIMA(0,1,1)(0,1,1) is: \", RMSE1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nRMSE for ARIMA(0,1,1)(0,1,1) is:  7.428068\n```\n:::\n\n```{.r .cell-code}\nfarima2 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(1,1,1),seasonal=c(0,1,1)), h=h)}\ne <- tsCV(monthly_attacks_ts, farima2, h=1)\n\nMAE2 <-abs(mean(e,na.rm=TRUE))\ncat(\"\\nMAE for ARIMA(1,1,1)(0,1,1) is: \", MAE2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMAE for ARIMA(1,1,1)(0,1,1) is:  2.092574\n```\n:::\n\n```{.r .cell-code}\nRMSE2=sqrt(mean(e^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"\\nRMSE for ARIMA(1,1,1)(0,1,1) is: \", RMSE2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nRMSE for ARIMA(1,1,1)(0,1,1) is:  7.410171\n```\n:::\n:::\n\n\nBoth MAE and RMSE metrics agree that ARIMA(1,1,1)(0,1,1) is the best model by a slight margin. However, the BIC metric does not agree with this result as it outputted ARIMA(0,1,1)(0,1,1) as the model with lowest BIC. AIC and AICc metrics, however, do agree with the MAE and RMSE metrics generated from Seasonal Cross Validation using 1 step ahead forecasts. Let's see whether this is the case when forecasting 12 steps ahead.\n\n### Seasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 12 steps (seasonal period) ahead forecasts\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 75 # minimum data length for fitting a model \nn <- length(monthly_attacks_ts)\nn-k # rest of the observations\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 537\n```\n:::\n\n```{.r .cell-code}\nset.seed(133)\n\nfarima1 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(0,1,1),seasonal=c(0,1,1)), h=h)}\n\n# Compute cross-validated errors for up to 12 steps ahead\ne <- tsCV(monthly_attacks_ts, forecastfunction = farima1, h = 12)\n\nmse1 <- colMeans(e^2, na.rm = TRUE)\n\nfarima2 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(1,1,1),seasonal=c(0,1,1)), h=h)}\n# Compute cross-validated errors for up to 12 steps ahead\ne <- tsCV(monthly_attacks_ts, forecastfunction = farima2, h = 12)\n\n# Compute the MSE values and remove missing values\nmse2 <- colMeans(e^2, na.rm = TRUE)\n\n# Plot the MSE values against the forecast horizon\ndata.frame(h = 1:12, MSE1 = mse1, MSE2 = mse2) %>%\n  ggplot() + geom_point(aes(y=MSE1,x= h)) + geom_point(aes(y=MSE2,x= h)) +\n           geom_line(aes(y=MSE1,x= h,colour=\"MSE for ARIMA(0,1,1)(0,1,1)\")) + \n           geom_line(aes(y=MSE2,x= h,colour=\"MSE for ARIMA(1,1,1)(0,1,1)\"))+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nThis plot gives cross-validation statistics up to horizon 12. The procedure for seasonal cross validation using 12 steps ahead is very similar to seasonal cross validation using 1 step ahead. We need to change the \"h\" parameter to the desired the number of time horizons we want to forecast for. The `farima()` function manually written by us helps us call our desired SARIMA model with the number of horizons. Then, `farima()` function is called inside the `tsCV()` function, which helps us store the cross-validated errors for up to 12 steps ahead. Then, because we get forecasts for each time horizon, we need to take the mean of the squared column using `colMeans` to obtain MSE. \n\nAlthough we observed that the MSE and RMSE of ARIMA(1,1,1)(0,1,1) when forecasting 1 step ahead was lower than that of ARIMA(0,1,1)(0,1,1), from the above plot it can be seen that the cross-validated MSEs get lower or better as the number of forecasting steps increases. Both models' MSE performance follow a very similar pattern, with ARIMA(0,1,1)(0,1,1), picked by lowest BIC, having a lower MSE across all forecasting steps, except for step 1. Therefore, ARIMA(0,1,1)(0,1,1) is the better SARIMA model!\n\n## Section Code\n\n**Code for this section can be found [here](https://github.com/TegveerG/Time-Series-Project/blob/main/Time%20Series%20Analysis/ARMA-ARIMA-SARIMA.qmd)**\n",
    "supporting": [
      "ARMA-ARIMA-SARIMA_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/htmlwidgets-1.6.2/htmlwidgets.js\"></script>\n<script src=\"site_libs/plotly-binding-4.10.1/plotly.js\"></script>\n<script src=\"site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"site_libs/crosstalk-1.2.0/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/crosstalk-1.2.0/js/crosstalk.min.js\"></script>\n<link href=\"site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
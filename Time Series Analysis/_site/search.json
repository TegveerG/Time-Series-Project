[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tegveer Ghura",
    "section": "",
    "text": "Tegveer is a first-year graduate student pursuing an MS in Data Science & Analytics at Georgetown University. When not producing insights from data, Tegveer enjoys spending time playing cricket and exploring the DMV."
  },
  {
    "objectID": "Data-Visualization.html",
    "href": "Data-Visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "The analysis of the data collected begins from this pivotal section. Every data science project, especially those utilizing Time Series data, starts with Data Visualization because it allows for easy and intuitive interpretation of complex data sets. These visualizations help data scientists identify patterns, trends, and relationships that might otherwise be difficult to discern by looking at the summary statistics the raw data, for example. The visualizations presented below were created using Tableau and the packages ggplot2 and Plotly in the R software.\nCode for this section can be found here"
  },
  {
    "objectID": "Data-Visualization.html#ethereum-eth-line-plots",
    "href": "Data-Visualization.html#ethereum-eth-line-plots",
    "title": "Data Visualization",
    "section": "Ethereum (ETH) Line Plots",
    "text": "Ethereum (ETH) Line Plots\n\n\n\n\nStatic PlotInteractive Plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestors who bought stocks during the COVID-19 market crash in 2020 have generally experienced some big gains in the past two years. Several factors led to a surge in Ethereum buying in 2020 and especially in 2021. Younger Americans receiving three rounds of direct stimulus payments have poured a significant chunk of that cash into investments, including Ethereum. In addition, cryptocurrency investing became extremely trendy in 2021, and Ethereum was one of the most popular cryptos in the market. At the beginning of 2020, Ethereum was trading around $129. By the beginning of March, the cryptocurrency had risen to $218 as news of the virus spreading in China prompted concerns about a U.S. pandemic. On March 13, 2020, Ethereum plummeted to its pandemic low of $88.50 as global stock markets tanked. The good news for Ethereum investors is the crypto bounced off that level as the stock market began to stabilize shortly thereafter and the government started printing money."
  },
  {
    "objectID": "Data-Visualization.html#ethereum-candlestick-plot",
    "href": "Data-Visualization.html#ethereum-candlestick-plot",
    "title": "Data Visualization",
    "section": "Ethereum Candlestick Plot",
    "text": "Ethereum Candlestick Plot\n\n\n\n\n\n\nTo visualize the candlesticks carefully, we subset the data by viewing only the last few months’ data from the current date, January 15th 2023. Ethereum’s price was generally decreasing since November 2022, experiencing massive drops on November 9th notably. The crypto was trading at a similar level until the hopeful New Year, which then saw its price increase back to former levels in November 2022."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Tegveer Ghura",
    "section": "Education",
    "text": "Education\nBoston University | Boston, MA\nB.A (Cum Laude) Economics | Sept 2017 - May 2021\nGeorgetown University | Washington, DC\nM.S Data Science & Analytics | Aug 2022 - May 2024 (anticipated)"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Tegveer Ghura",
    "section": "Experience",
    "text": "Experience\nMetricStream, Inc. | Finance Associate | Sept 2021 - Apr 2022\nMetricStream, Inc. | Finance Intern | June 2021 - Aug 2022\nUnimoni Financial Services Ltd. | Project Intern | Jul 2019 - Aug 2019"
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Warning\n\n\n\nTrigger warning: The following content contains descriptions of violent acts and extremism related to terrorism, which may be disturbing or triggering for some readers.\n\n\nTerrorism is a puzzling and gripping phenomenon. Its relationship with tourism is intricate and multi-dimensional. Interestingly, international terrorism and tourism share common traits, such as being transnational in nature, involving citizens from different nations, and utilizing travel and communication technologies. The impact of terrorist attacks extends to several other industries related to tourism, including airlines, hotels, restaurants, and tourist-oriented shops and services (Baker, n.d.).\n\nBaker, David. n.d. “The Effects of Terrorism on the Travel and Tourism Industry.” International Journal of Religious Tourism and Pilgrimage. https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1052&amp;context=ijrtp.\n\n“World Tourism Organization.” n.d. UNWTO. https://www.unwto.org/.\nReceipts from international tourism in destinations around the world grew by 4% in 2012 reaching USD 1,075 billion. This growth is equal to a 4% increase in international tourist arrivals over the previous year which reached 1,035 million in 2012. An additional USD 219 billion was recorded in receipts from international passenger transport, bringing total exports generated by international tourism in 2012 to US$ 1.3 trillion (“World Tourism Organization,” n.d.).\n\n\n\n\n\n\n\n\n\nThe Global Terrorism Database™ (GTD) (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.) defines a terrorist attack as the threatened or actual use of illegal force and violence by a nonstate actor to attain a political, economic, religious, or social goal through fear, coercion, or intimidation. In practice this means in order to consider an incident for inclusion in the GTD (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.), all three of the following attributes must be present:\n\nThe incident must be intentional – the result of a conscious calculation on the part of a perpetrator.\nThe incident must entail some level of violence or immediate threat of violence, including property violence, as well as violence against people.\nThe perpetrators of the incidents must be sub-national actors. The database does not include acts of state terrorism.\n\nIn addition, at least two of the following three criteria must be present for an incident to be included in the GTD (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.):\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\n\nCriterion 1: The act must be aimed at attaining a political, economic, religious, or social goal. In terms of economic goals, the exclusive pursuit of profit does not satisfy this criterion. It must involve the pursuit of more profound, systemic economic change.\nCriterion 2: There must be evidence of an intention to coerce, intimidate, or convey some other message to a larger audience (or audiences) than the immediate victims. It is the act taken as a totality that is considered, irrespective if every individual involved in carrying out the act was aware of this intention. As long as any of the planners or decision-makers behind the attack intended to coerce, intimidate or publicize, the intentionality criterion is met.\nCriterion 3: The action must be outside the context of legitimate warfare activities. That is, the act must be outside the parameters permitted by international humanitarian law, insofar as it targets non-combatants"
  },
  {
    "objectID": "Data-Sources.html",
    "href": "Data-Sources.html",
    "title": "Data Sources",
    "section": "",
    "text": "In order to collect time-series data on terrorism, choosing The Global Terrorism Database™ (GTD) by University of Maryland was a pragmatic decision because it contains detailed information of global attacks that occurred daily. This gave enormous flexibility to search for short-term seasonal patterns, if any, regarding terrorist attacks. For assessing the impact of terrorism on economic activity, the SIPRI Military Expenditure Database was employed. Military expenditure as a share of GDP can provide key insights about a country’s allocation of resources. Nonimmigrant Admissions data was also collected from the Department of Homeland Security (DHS) to add an extra dimension of how the sentiment of the US government changed regarding tourist admits in the overall analysis.\nThe Quantmod R package seamlessly allows R users to get stock data, which aids in exploring both changes in prices due to certain terror attacks and how weapons manufacturing companies reacted to these attacks. To analyze domestic financial impacts from terror attacks at a granular level, daily historical stock prices of some of the largest weapons manufacturers in the United States, including Lockheed Martin and Raytheon Technologies, were obtained. Not only stock prices of individual companies, but also data of the Dow Jones U.S. Travel & Tourism Index was gathered to approach the financial analysis at a larger scale."
  },
  {
    "objectID": "Data-Sources.html#the-global-terrorism-database-gtd-by-university-of-maryland",
    "href": "Data-Sources.html#the-global-terrorism-database-gtd-by-university-of-maryland",
    "title": "Data Sources",
    "section": "The Global Terrorism Database™ (GTD) by University of Maryland",
    "text": "The Global Terrorism Database™ (GTD) by University of Maryland\nAn open-source database containing information on terrorist events around the world from 1970 through 2020 (with annual updates planned for the future). Unlike many other event databases, the GTD includes systematic data on domestic as well as international terrorist incidents that have occurred during this time period and now includes more than 200,000 cases.\n\n\n\nPress the logo to access the data!"
  },
  {
    "objectID": "Data-Sources.html#sipri-military-expenditure-database",
    "href": "Data-Sources.html#sipri-military-expenditure-database",
    "title": "Data Sources",
    "section": "SIPRI Military Expenditure Database",
    "text": "SIPRI Military Expenditure Database\nThe SIPRI Military Expenditure Database contains consistent time series on the military spending of countries for the period 1949–2021. The database is updated annually, which may include updates to data for any of the years included in the database. The main purpose of the data on military expenditure is to provide an easily identifiable measure of the scale of resources absorbed by the military. Military expenditure is an input measure which is not directly related to the ‘output’ of military activities, such as military capability or military security. Military expenditure data measured in constant dollars is a trend indicator of the volume of resources used for military activities, which allow comparisons to be made over time for individual countries and between countries.\n\n\n\nPress the logo to access the data!"
  },
  {
    "objectID": "Data-Sources.html#department-of-homeland-security-dhs",
    "href": "Data-Sources.html#department-of-homeland-security-dhs",
    "title": "Data Sources",
    "section": "Department of Homeland Security (DHS)",
    "text": "Department of Homeland Security (DHS)\nThe United States Department of Homeland Security (DHS) is the U.S. federal executive department responsible for public security, roughly comparable to the interior or home ministries of other countries. Its stated missions involve anti-terrorism, border security, immigration and customs, cyber security, and disaster prevention and management.\n\n\n\nPress the logo to access the data!"
  },
  {
    "objectID": "Data-Sources.html#quantmod-r-package",
    "href": "Data-Sources.html#quantmod-r-package",
    "title": "Data Sources",
    "section": "Quantmod R Package",
    "text": "Quantmod R Package\nThe quantmod package for R is designed to assist the quantitative trader in the development, testing, and deployment of statistically based trading models. The getSymbols() function in the package aids in collecting stock price data of US companies and indexes. As previously mentioned, the historical stock prices of Lockheed Martin and the Dow Jones U.S. Travel & Tourism Index were chosen for this analysis.\nSee data collection code and time-series plots below:\n\n\n\n\n\nShow the code\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\n# Collecting Lockheed Martin's Stock Price since IPO\n\ntickers = c(\"LMT\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"1995-03-17\",\n             to = \"2023-01-30\")}\n\nlmt <- data.frame(LMT$LMT.Adjusted)\n\nlmt <- data.frame(lmt,rownames(lmt))\ncolnames(lmt) <- append(tickers,'Dates')\n\nlmt$date<-as.Date(lmt$Dates,\"%Y-%m-%d\")\n\n# Collecting Raytheon Tech Corp Stock Price since IPO\n\ntickers = c(\"RTX\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"1983-03-04\",\n             to = \"2023-01-30\")}\n\nrtx <- data.frame(RTX$RTX.Adjusted)\n\nrtx <- data.frame(rtx,rownames(rtx))\ncolnames(rtx) <- append(tickers,'Dates')\n\nrtx$date<-as.Date(rtx$Dates,\"%Y-%m-%d\")\n\n# Collecting DJUSTT since formation\n\ntickers = c(\"^DJUSTT\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"2008-12-01\",\n             to = \"2023-01-30\")}\n\ndow <- data.frame(DJUSTT$DJUSTT.Adjusted)\n\ndow <- data.frame(dow,rownames(dow))\ncolnames(dow) <- append(tickers,'Dates')\ncolnames(dow)[1] =\"DJUSTT\"\n\ndow$date<-as.Date(dow$Dates,\"%Y-%m-%d\")\n\n\n\nVisualizing Lockheed Martin’s and Raytheon Tech’s Stock Prices and Dow Jones U.S. Travel & Tourism Index\n\nLockheed MartinRaytheon Technologies (formerly American Appliance Company)Dow Jones U.S. Travel & Tourism Index\n\n\n\n\nShow the code\ng1 <- ggplot(lmt, aes(x=date, y=LMT)) +\n  geom_line(color=\"#005BAD\") +\n   labs(\n    title = \"Stock Prices for Lockheed Martin\",\n    subtitle = \"From Dec 2008 - January 2023\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices ($)\") + \n  theme_minimal() \n\nggplotly(g1) %>%\n  layout(hovermode = \"x\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ng2 <- ggplot(rtx, aes(x=date, y=RTX)) +\n  geom_line(color=\"#E61231\") +\n   labs(\n    title = \"Stock Prices for Raytheon Technologies\",\n    subtitle = \"From Mar 1983 - January 2023\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices ($)\") + \n  theme_minimal() \n\nggplotly(g2) %>%\n  layout(hovermode = \"x\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ng3 <- ggplot(dow, aes(x=date, y=DJUSTT)) +\n  geom_line() +\n   labs(\n    title = \"Dow Jones U.S. Travel & Tourism Index\",\n    subtitle = \"From March 2020 - December 2022\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices ($)\") + \n     theme_minimal() \n\nggplotly(g3) %>%\n  layout(hovermode = \"x\")"
  },
  {
    "objectID": "Data-Sources.html#questions-to-adress",
    "href": "Data-Sources.html#questions-to-adress",
    "title": "Data Sources",
    "section": "Questions to Adress",
    "text": "Questions to Adress\n Q1\n Q2\n Q3\n Q4\n Q5\n Q6\n Q7\n Q8\n Q9\n Q10"
  },
  {
    "objectID": "Introduction.html#questions-to-adress",
    "href": "Introduction.html#questions-to-adress",
    "title": "Introduction",
    "section": "Questions to Adress",
    "text": "Questions to Adress\n How have the types of terror attacks in the United States evolved over the last 25 years?\n How have the targets of terror attacks in the United States evolved over the last 25 years?\n Do certain states in the United States suffer more terrorist attacks than others do?\n Are we able to use time-series data on terrorist attacks to predict future attacks and their different kinds in the United States?\n Are we able to use time-series data on military expenditure to predict the government’s future spending in the United States?\n Have certain terrorist attacks on the United States prompted sudden changes in military expenditure over the past 50 years?\n Do terror attacks outside the United States prompt increased domestic military expenditure in the United States?\n What is the correlation between terror attacks and military expenditure over time in the United States?\n To what extent do terror attacks impact the United State’s stance on people entering the United States with B-2 visa (tourist) status?\n To what extent do Lockheed Martin’s stock prices and the Dow Jones U.S. Travel & Tourism Index help us understand trends in terrorist attacks in the United States?"
  },
  {
    "objectID": "Introduction.html#public-us-sentiment",
    "href": "Introduction.html#public-us-sentiment",
    "title": "Introduction",
    "section": "Public US Sentiment",
    "text": "Public US Sentiment\nThe September 11 attacks, commonly known as 9/11, on the World Trade Center in 2001 were a historic aberration in US history, with significant and far-reaching impacts on national security policy, international relations, and the collective psyche of the American people. Immediately after the 9/11 attacks, public sentiment in the US was marked by a strong sense of shock, anger, and a desire for justice, along with a surge in patriotism and a willingness to support government actions to prevent future terrorist attacks. There was also a significant increase in concerns about national security and a greater willingness to sacrifice personal freedoms in the interest of greater security. The figure below conveys that, immediately after 9/11, a share of the US public’s stance on venturing outdoors and travelling overseas stagnated for the next decade. The public’s confidence seemed to restore around 2011."
  },
  {
    "objectID": "Introduction.html#references",
    "href": "Introduction.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\nBaker , David. “The Effects of Terrorism on the Travel and Tourism Industry .” Technological University Dublin. International Journal of Religious Tourism and Pilgrimage. Accessed February 1, 2023. https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1052&context=ijrtp.\n“Codebook Methodology Inclusion Criteria and Ariables - UMD.” Codebook Methodology Inclusion criteria and variables - UMD. University of Maryland. Accessed February 1, 2023. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\n“World Tourism Organization.” UNWTO. Accessed February 1, 2023. https://www.unwto.org/."
  },
  {
    "objectID": "Data-Visualization.html#visualizing-the-gtd",
    "href": "Data-Visualization.html#visualizing-the-gtd",
    "title": "Data Visualization",
    "section": "Visualizing the GTD™",
    "text": "Visualizing the GTD™\nFor the purpose of this project, the focus will be on the United States, so the data has been filtered accordingly. An important point to keep in mind is that incidents of terrorism from 1993 are not present in the GTD™ because they were lost by the authors. Hence, few visualizations created in R, using the GTD™, do reflect this aberration, as missing values for the year 1993 were not imputed.\nTo start, the visualizations below provide a general overview of how the number of terrorist attacks and fatalities have changed over time.\n\nEvolution of Volume of Terrorist Attacks and Fatalaties (1970-2020) in the US\n\nNumber of Monthly Attacks and FatalitiesNumber of Monthly Attacks and Fatalities (adjusted for 9/11)Cumulative Count of Terrorist Attacks & Fatalities\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first plot (Number of Monthly Attacks and Fatalities) conveys the significance of the 9/11 Attacks on US history. The big black spike in fatalities, totaling approximately 3000, is representative of the attack and an “outlier” from both series. As a result, in order to depict the trend of both series clearly, it was imperative to filter out the 9/11 Attacks and that is why the second plot was created. A cumulative graph of number of attacks and fatalities is showcased as well that provides further context about the impact of the 9/11 Attacks. Total fatalities were much lower than total number of attakcs from 1970 to 2000, but the toll of the 9/11 Attacks were significant enough to surpass the 2,424 attacks that occurred up until the tragedy.\nMoreover, the total number of fatalities between 1970 and 2000 was 492 and the total number of fatalities between 2001 and 2020 was 419, suggesting that attacks apart from 9/11 follow a similar trend in death rate. Lastly, the number of attacks between the years 1976 and 2004 follow a concave shape, implying that the volume of attacks must be diminishing through the years. However, a steep, exponential rise in not only the number of attacks but also the number of fatalities is noticed after 2004!\nHere are a few facts (“Terrorist Attacks in the u.s Between 1970 and 2013: Data from the ... - DHS,” n.d.) attacks in the US between 1970 and 2013:\n\nApproximately 85% of all deaths from terrorist attacks during this period occurred in the coordinated attacks on September 11, 2001.\nNearly 80% of all terrorist attacks involved no casualties (fatalities or injuries).\nMore than half of terrorist attacks took place during the 1970s. Between 2000 and 2013, there were fewer than 20 attacks per year on average.\n\n\n\nEvolution of Terrorist Attacks: Approach, Victims, and Weapons (Raw Counts)\n\nNumber of Distinct Attacks Over TimeTrends in Attacks Over Time by Victim TypeTrends in Attacks Over Time by Weapon Type\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\nThe above bar chart races allow for an animated way to display the number of attacks changing over time by the categorical variables, Attack Type, Victim Type, and Weapon Type. The 1970s and 1980s were dominated by Bombing/Explosion Terrorist Attacks in the US, with Facility/Infrastructure Attacks gaining momentum by the end of the 1980s. Many of these bombings were carried out by leftist extremist groups, such as the Weather Underground and the Black Liberation Army, who were motivated by a variety of political and social causes, including opposition to the Vietnam War, racial injustice, and government oppression (Serrano 2008).\n\nSerrano, Richard A. 2008. “The 1970s Bombing Spree.” Los Angeles Times.\n\nRosenau, William. n.d. “Leftist Terrorism in the United States.” Taylor &Amp; Francis. The Journal of Strategic Studies (2013). https://www.tandfonline.com/journals/fjss20.\nOne factor that contributed to the prevalence of domestic bombing attacks during this period was the rise of radical political activism and social unrest. The Vietnam War was a major source of division in American society, and many activists were inspired to use violent tactics in their protests. Additionally, the civil rights movement and the Black Power movement brought attention to issues of racial inequality, and some extremist groups sought to further their agendas through bombings and other violent actions. Another factor was the relative ease with which these groups could obtain explosives and other materials necessary to carry out bombings. Many of the bombs used in these attacks were constructed using readily available materials such as dynamite and pipe bombs, and there were few restrictions on the purchase of these materials at the time (Rosenau, n.d.).\nIn the 1970s and 1980s, a majority of the victims of these attacks included businesses (corporate offices, restaurants, gas stations, bars, cafés, etc.), the government (government building, government member, former members, or events sponsored by political parties, etc.), and private citizens and property (the public in general or attacks in public areas including markets, commercial streets, busy intersections and pedestrian malls) (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.). Moreover, numerous attacks on abortion clinics were conducted in the 1980s and 1990s by anti-abortion activists. These attacks took various forms, including bombings, arson, and other acts of violence, as well as peaceful protests and acts of civil disobedience. Another factor that contributed to the attacks on abortion clinics was the political and legal context of the time. In 1973, the US Supreme Court issued its landmark decision in Roe v. Wade, which established a constitutional right to abortion. This decision was highly controversial and sparked a wave of political and social activism on both sides of the issue.\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\nFrom recent years, the data portrays an increase in attacks against both Religious Figures/Institutions and the police. Therefore, terrorists’ aims and agendas have transformed over time as the underlying narrative of a country’s political climate changes. In a smaller sense, to conduct an attack, the US has also suffered from the evolution of weapons used by terrorists. As aforementioned, the 1970s and 1980s experienced bombings as the majority of attacks and the weapons used during that time support this finding. Explosives and incendiaries made up the majority of weapons used in the 1970s and 1980s, with firearms gaining traction. By the late 90s, less use of explosives is seen and a shift to incendiaries, firearms, chemical, and biological weapons becomes prominent.\nHere are some more facts (“Terrorist Attacks in the u.s Between 1970 and 2013: Data from the ... - DHS,” n.d.) related to the bar chart races:\n\n“Terrorist Attacks in the u.s Between 1970 and 2013: Data from the ... - DHS.” n.d. Terrorist Attacks in the U.S Between 1970 and 2013: Data from the Global Terrorism Database (GTD). START Consortium at the University of Maryland. https://www.dhs.gov/sites/default/files/publications/OPSR_TP_TEVUS_Terrorist-Attacks-US_1970-2013_Overview-508.pdf.\n\n94% of attacks against abortion‐related targets were on clinics, while 6% targeted providers or personnel.\n78% of attacks against educational targets were on schools, universities, or\nother buildings, while 22% targeted teachers or other educational personnel.\n73% of attacks against government targets were on government buildings, facilities, or offices, while 27% targeted personnel, public officials, or politicians.\n\n\n\nEvolution of Terrorist Attacks: Approach, Victims, and Weapons (Percent of Total)\n\nPercentage of Distinct Attacks Over TimePercentage of Attacks Over Time by Victim TypePercentage of Attacks Over Time by Weapon Type\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\nEvolution of Terrorist Attacks By US State (Geospatial)"
  },
  {
    "objectID": "Introduction.html#bibliography",
    "href": "Introduction.html#bibliography",
    "title": "Introduction",
    "section": "Bibliography",
    "text": "Bibliography"
  },
  {
    "objectID": "Data-Visualization.html#visualizing-the-sipri-military-expenditure-database",
    "href": "Data-Visualization.html#visualizing-the-sipri-military-expenditure-database",
    "title": "Data Visualization",
    "section": "Visualizing the SIPRI Military Expenditure Database",
    "text": "Visualizing the SIPRI Military Expenditure Database"
  },
  {
    "objectID": "Data-Visualization.html#visualizing-department-of-homeland-securitys-non-immigrant-admissions-data",
    "href": "Data-Visualization.html#visualizing-department-of-homeland-securitys-non-immigrant-admissions-data",
    "title": "Data Visualization",
    "section": "Visualizing Department of Homeland Security’s Non-Immigrant Admissions Data",
    "text": "Visualizing Department of Homeland Security’s Non-Immigrant Admissions Data"
  },
  {
    "objectID": "Data-Visualization.html#references",
    "href": "Data-Visualization.html#references",
    "title": "Data Visualization",
    "section": "References",
    "text": "References\n“Terrorist Attacks in the U.S between 1970 and 2013: Data from the … - DHS.” Terrorist Attacks in the U.S Between 1970 and 2013: Data from the Global Terrorism Database (GTD). START Consortium at the University of Maryland. Accessed February 12, 2023. https://www.dhs.gov/sites/default/files/publications/OPSR_TP_TEVUS_Terrorist-Attacks-US_1970-2013_Overview-508.pdf.\nSerrano, Richard A. “The 1970s Bombing Spree.” Los Angeles Times. May 19, 2008.\nRosenau, William. “Leftist Terrorism in the United States.” Taylor & Francis. Accessed February 12, 2023. https://www.tandfonline.com/journals/fjss20.\n“Codebook Methodology Inclusion Criteria and Ariables - UMD.” Codebook Methodology Inclusion criteria and variables - UMD. University of Maryland. Accessed February 1, 2023. https://www.start.umd.edu/gtd/downloads/Codebook.pdf."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html",
    "href": "Exploratory-Data-Analysis.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "After producing the data visualizations to gain rudimentary insights about the various datasets collected, the next step of the process is to complete an exploratory data analysis (EDA). Several time series packages exist in the R software that have been utilized to unravel deeper details about the data sets. Some of the famous time series analysis methods used in this section include decomposing and identifying time series components, producing auto-correlation function (ACF) and partial auto-correlation function (PACF) plots, and differencing, and checking for stationarity by the use of the Augmented Dickey-Fuller Test.\nCode for this section can be found here"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#identifying-time-series-components-of-monthly-attacks",
    "href": "Exploratory-Data-Analysis.html#identifying-time-series-components-of-monthly-attacks",
    "title": "Exploratory Data Analysis",
    "section": "Identifying Time Series Components of Monthly Attacks",
    "text": "Identifying Time Series Components of Monthly Attacks"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#identifying-time-series-components-of-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#identifying-time-series-components-of-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Identifying Time Series Components of Monthly Attacks (GTD)",
    "text": "Identifying Time Series Components of Monthly Attacks (GTD)\nPlease note that as per the GTD Codebook (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.), incidents of terrorism from 1993 are not present because they were lost prior to START’s compilation of the database from multiple data collection efforts. Therefore, monthly attack counts for the year 1993 have been interpolated using the na.approx() function from the zoo library in R. Appendix II of the GTD Codebook provides Country-level statistics for 1993 and for the US, the attack count was 28. However, our interpolated estimates, which took into calculation 1992 and 1994 attack counts, sum up to 54 attacks, which shall be used for EDA.\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\nAlso, the data analyzed is count data rather than the measure of a metric. Hence, the results from the time series functions used on this data might not seem like “traditional” outputs seen from data used in class.\n\n\n\n\n\n\n\n\n\nFrom the graph, we see an initial downward trend from 1970 to 1972 and an upward trend soon after until 1975. The trend, however, then remains constant until the 2000s. Another upward trend is noticed after 2010 as more attacks were conducted in recent years. Some seasonality is noticed, with more attacks occurring towards the end of Spring (April and May) and end of Fall (August to October), across the whole timeline, but the number of attacks does vary across months, suggesting periodic fluctuations. From these insights, the series does not seem stationary. Moreover, because we cannot identify whether the average length of cycles is longer than the length of a seasonal pattern, the graph is not cyclical. A stationary time series will have no predictable patterns in the long-term, but given the count of attacks now increasing in recent years, one could deduce or forecast patterns in the number of attacks for the next few months ahead from the present (Dec 2020). Lastly, as the time of the series increases, the seasonal variation remains fairly constant, so we should use an additive decomposition. Next, we shall take a look at this series’ lag plots to check for autocorrelations, if any."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#references",
    "href": "Exploratory-Data-Analysis.html#references",
    "title": "Exploratory Data Analysis",
    "section": "References",
    "text": "References\n“Codebook Methodology Inclusion Criteria and Ariables - UMD.” Codebook Methodology Inclusion criteria and variables - UMD. University of Maryland. Accessed February 1, 2023. https://www.start.umd.edu/gtd/downloads/Codebook.pdf."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#lag-plots-gtd",
    "href": "Exploratory-Data-Analysis.html#lag-plots-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Lag Plots (GTD)",
    "text": "Lag Plots (GTD)"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#lag-plots-of-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#lag-plots-of-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Lag Plots of Monthly Attacks (GTD)",
    "text": "Lag Plots of Monthly Attacks (GTD)\n\n\n\n\n\nConcerning the the faceted lag plots of the monthly series, we see a relatively strong positive autocorrelation at lag 1. Thus indicates that there is a strong relationship between the values of the series in adjacent months. Specifically, it suggests that the value of the series in the current month is positively related to the value of the series in the previous month. This can indicate the presence of some underlying trend or seasonality in the data. There is no evidence of negative autocorrelation too. Therefore, this could make a case for weak autocorrelation. As the level of autocorrelation increases, the points shift away from the diagonal; however, the points move closer at lag 12, indicating that . A positive linear trend (i.e. going upwards from left to right) is suggestive of positive autocorrelation.\nWhen comparing the lag plots for the series with different months, there is not much difference, except for a cluster of data points in the bottom left side of the graph, reinforcing our earlier finding that more than half the attacks from 1970 to 2013 took place in 1970. The trend and seasonal components are very much similar and, hence, the plots hint to us that all the series seem to not be stationary."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#decomposing-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#decomposing-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Decomposing Monthly Attacks (GTD)",
    "text": "Decomposing Monthly Attacks (GTD)"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#acf-and-pacf-plots-of-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#acf-and-pacf-plots-of-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "ACF and PACF Plots of Monthly Attacks (GTD)",
    "text": "ACF and PACF Plots of Monthly Attacks (GTD)\n\n\n\n\n\nThe autocorrelation function (ACF) and partial autocorrelation function (PACF) plots are used to help determine the order of an ARMA model. The ACF plot shows the correlation between the time series and its lagged values, while the PACF plot shows the correlation between the time series and its lagged values after controlling for the effects of any intermediate lagged values.\nBy looking at the ACF, it can be concluded that the series is not Stationary. The dashed blue lines indicate whether the correlations are significantly different from zero. The ACF Plot shows a downward trend in attack counts, with the initial insignificant correlations beginning from lag 24. No clear seasonality is depicted from the ACF plot. If a time series is stationary, its PACF should decline to zero relatively quickly, beyond a certain lag value. On the other hand, if a time series is not stationary, its PACF will show significant autocorrelation for many lag values. The former seems true for these PACF plots, as we see autocorrelations for only lags 1 and 2 in the PACF plot. The PACF does decrease after and stays within the confines of the Confidence Interval, which could mean that it is not significantly different from zero and therefore has no significant correlation with the time series from lag 2 onwards. Therefore, the original series might be weakly stationary!"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#adf-test-of-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#adf-test-of-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "ADF Test of Monthly Attacks (GTD)",
    "text": "ADF Test of Monthly Attacks (GTD)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  monthly_attacks_ts\nDickey-Fuller = -7.3335, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary"
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#detrending-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#detrending-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "Detrending Monthly Attacks (GTD)",
    "text": "Detrending Monthly Attacks (GTD)\n\n\n\nCall:\nlm(formula = monthly_attacks_ts ~ time(monthly_attacks_ts), na.action = NULL)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.347 -3.363 -1.524  1.317 59.172 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              376.72017   36.25612   10.39   <2e-16 ***\ntime(monthly_attacks_ts)  -0.18622    0.01817  -10.25   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.617 on 610 degrees of freedom\nMultiple R-squared:  0.1469,    Adjusted R-squared:  0.1455 \nF-statistic:   105 on 1 and 610 DF,  p-value: < 2.2e-16\n\n\n\n\n\nOur trend using OLS was:\n\\(\\hat\\mu_t\\) = 376.72 - 0.18622t\nTherefore, equation of the fit of the underlying stationary process is:\n\\(\\hat{y_t}\\) = \\(x_t\\) + 376.72 - 0.18622t\nThe Detrended series is very much similar to the original series, signaling that differencing could provide a more stationary transformation. The linear model’s \\(R^2\\) value is 0.1469, suggesting that the model captures 15% of the variation in prices. Therefore, a quadratic model or first differencing would perhaps provide a better fit.\nWe then see that, even after detrending, the series contains seasonality, which further reinforces our above point that the linear model does not do very well in capturing the initial decreasing trend and then the increasing trend for recent years. Moreover, the data is not trend stationary, which bolsters the above argument."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#acf-and-pacf-plots-after-differencing-monthly-attacks-gtd",
    "href": "Exploratory-Data-Analysis.html#acf-and-pacf-plots-after-differencing-monthly-attacks-gtd",
    "title": "Exploratory Data Analysis",
    "section": "ACF and PACF Plots After Differencing Monthly Attacks (GTD)",
    "text": "ACF and PACF Plots After Differencing Monthly Attacks (GTD)\n\n\n\n\n\nFirst order differencing performs better than detrending, so we shall use this series in the next section when building our autoregressive models. However, we also saw from the original PACF plot that the PACF declineS to zero relatively quickly than that of the differenced series. Therefore, the original series could also directly be fitted to the autoregressive models."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#global-terrorism-database-exploratory-data-analysis",
    "href": "Exploratory-Data-Analysis.html#global-terrorism-database-exploratory-data-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Global Terrorism Database Exploratory Data Analysis",
    "text": "Global Terrorism Database Exploratory Data Analysis\n\nIdentifying Time Series Components of Monthly Attacks\nPlease note that as per the GTD Codebook (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.), incidents of terrorism from 1993 are not present because they were lost prior to START’s compilation of the database from multiple data collection efforts. Therefore, monthly attack counts for the year 1993 have been interpolated using the na.approx() function from the zoo library in R. Appendix II of the GTD Codebook provides Country-level statistics for 1993 and for the US, the attack count was 28. However, our interpolated estimates, which took into calculation 1992 and 1994 attack counts, sum up to 54 attacks, which shall be used for EDA.\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\nAlso, the data analyzed is count data rather than the measure of a metric. Hence, the results from the time series functions used on this data might not seem like “traditional” outputs seen from data used in class.\n\n\n\n\n\n\n\n\n\nFrom the graph, we see an initial downward trend from 1970 to 1972 and an upward trend soon after until 1975. The trend, however, then remains constant until the 2000s. Another upward trend is noticed after 2010 as more attacks were conducted in recent years. Some seasonality is noticed, with more attacks occurring towards the end of Spring (April and May) and end of Fall (August to October), across the whole timeline, but the number of attacks does vary across months, suggesting periodic fluctuations. From these insights, the series does not seem stationary. Moreover, because we cannot identify whether the average length of cycles is longer than the length of a seasonal pattern, the graph is not cyclical. A stationary time series will have no predictable patterns in the long-term, but given the count of attacks now increasing in recent years, one could deduce or forecast patterns in the number of attacks for the next few months ahead from the present (Dec 2020). Lastly, as the time of the series increases, the seasonal variation remains fairly constant, so we should use an additive decomposition. Next, we shall take a look at this series’ lag plots to check for autocorrelations, if any.\n\n\nLag Plots of Monthly Attacks\n\n\n\n\n\nConcerning the the faceted lag plots of the monthly series, we see a relatively strong positive autocorrelation at lag 1. Thus indicates that there is a strong relationship between the values of the series in adjacent months. Specifically, it suggests that the value of the series in the current month is positively related to the value of the series in the previous month. This can indicate the presence of some underlying trend or seasonality in the data. There is no evidence of negative autocorrelation too. Therefore, this could make a case for weak autocorrelation. As the level of autocorrelation increases, the points shift away from the diagonal; however, the points move closer at lag 12, indicating that . A positive linear trend (i.e. going upwards from left to right) is suggestive of positive autocorrelation.\nWhen comparing the lag plots for the series with different months, there is not much difference, except for a cluster of data points in the bottom left side of the graph, reinforcing our earlier finding that more than half the attacks from 1970 to 2013 took place in 1970. The trend and seasonal components are very much similar and, hence, the plots hint to us that all the series seem to not be stationary.\n\n\nDecomposing Monthly Attacks\n\n\n\n\n\n\n\nACF and PACF Plots of Monthly Attacks\n\n\n\n\n\nThe autocorrelation function (ACF) and partial autocorrelation function (PACF) plots are used to help determine the order of an ARMA model. The ACF plot shows the correlation between the time series and its lagged values, while the PACF plot shows the correlation between the time series and its lagged values after controlling for the effects of any intermediate lagged values.\nBy looking at the ACF, it can be concluded that the series is not Stationary. The dashed blue lines indicate whether the correlations are significantly different from zero. The ACF Plot shows a downward trend in attack counts, with the initial insignificant correlations beginning from lag 24. No clear seasonality is depicted from the ACF plot. If a time series is stationary, its PACF should decline to zero relatively quickly, beyond a certain lag value. On the other hand, if a time series is not stationary, its PACF will show significant autocorrelation for many lag values. The former seems true for these PACF plots, as we see autocorrelations for only lags 1 and 2 in the PACF plot. The PACF does decrease after and stays within the confines of the Confidence Interval, which could mean that it is not significantly different from zero and therefore has no significant correlation with the time series from lag 2 onwards. Therefore, the original series might be weakly stationary!\n\n\nADF Test of Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  monthly_attacks_ts\nDickey-Fuller = -7.3335, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we cannot reject the null hypothesis and conclude that the time series is non-stationary.\n\n\nDetrending Monthly Attacks\n\n\n\nCall:\nlm(formula = monthly_attacks_ts ~ time(monthly_attacks_ts), na.action = NULL)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.347 -3.363 -1.524  1.317 59.172 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              376.72017   36.25612   10.39   <2e-16 ***\ntime(monthly_attacks_ts)  -0.18622    0.01817  -10.25   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.617 on 610 degrees of freedom\nMultiple R-squared:  0.1469,    Adjusted R-squared:  0.1455 \nF-statistic:   105 on 1 and 610 DF,  p-value: < 2.2e-16\n\n\n\n\n\nOur trend using OLS was:\n\\(\\hat\\mu_t\\) = 376.72 - 0.18622t\nTherefore, equation of the fit of the underlying stationary process is:\n\\(\\hat{y_t}\\) = \\(x_t\\) + 376.72 - 0.18622t\nThe Detrended series is very much similar to the original series, signaling that differencing could provide a more stationary transformation. The linear model’s \\(R^2\\) value is 0.1469, suggesting that the model captures 15% of the variation in prices. Therefore, a quadratic model or first differencing would perhaps provide a better fit.\nWe then see that, even after detrending, the series contains seasonality, which further reinforces our above point that the linear model does not do very well in capturing the initial decreasing trend and then the increasing trend for recent years. Moreover, the data is not trend stationary, which bolsters the above argument.\n\n\nACF and PACF Plots After Differencing Monthly Attacks\n\n\n\n\n\nFirst order differencing performs better than detrending, so we shall use this series in the next section when building our autoregressive models. However, we also saw from the original PACF plot that the PACF declineS to zero relatively quickly than that of the differenced series. Therefore, the original series could also directly be fitted to the autoregressive models.\n\n\nSimple Moving Average Smoothing\n\n\n\n\n\n\n\nMoving Average Smoothing with Windowing (2x4)\n\n\n\n\n\nmonthly_attacks_ts_2\nma4\nma2x4\n\n\n\n\n26\nNA\nNA\n\n\n50\n49.75\nNA\n\n\n54\n58.50\n54.125\n\n\n69\n55.50\n57.000\n\n\n61\n55.00\n55.250\n\n\n38\n45.00\n50.000\n\n\n\n\n\n\n\n\nIn this case, m is even, so it is no longer be symmetric. Therefore, when windowing, we are applying a moving average to a moving average. One reason for doing this is to make an even-order moving average symmetric. Here we have employed a centered 4-month moving average followed by a centered 2-month moving average. Although this helps smooth out both seasonal and longer-term trends in the data, we notice some seasonality still being present in the smoothed overlay. Let’s us try to use other moving averaging windows to obtain a more stationary overlay.\n\n\nMoving Average Smoothing with Windowing (2x6)\n\n\n\n\n\nmonthly_attacks_ts_2\nma6\nma2x6\n\n\n\n\n26\nNA\nNA\n\n\n50\nNA\nNA\n\n\n54\n49.66667\nNA\n\n\n69\n54.00000\n51.83333\n\n\n61\n50.50000\n52.25000\n\n\n38\n44.83333\n47.66667\n\n\n\n\n\n\n\n\nThe moving average did smooth out both seasonal and longer-term trends in the monthly time series. Although, we could still do better by further smoothing out longer-term trends by using a centered 8-month moving average, showcased below.\n\n\nMoving Average Smoothing with Windowing (2x8)\n\n\n\n\n\nmonthly_attacks_ts_2\nma8\nma2x8\n\n\n\n\n26\nNA\nNA\n\n\n50\nNA\nNA\n\n\n54\nNA\nNA\n\n\n69\n47.375\nNA\n\n\n61\n46.625\n47.0\n\n\n38\n44.375\n45.5\n\n\n\n\n\n\n\n\nThe above plot employed a centered 8-month moving average followed by a centered 2-month moving average. The output is similar to that of the 2x6-MA. Let’s make our analysis more constrained by fitting 4x3-MA: A centered 3-month moving average repeated four times. This should smooth out both seasonal and shorter-term fluctuations even further, providing the least seasonal moving average out of all the other moving averages applied yet."
  },
  {
    "objectID": "Exploratory-Data-Analysis.html#detrending-monthly-attacks",
    "href": "Exploratory-Data-Analysis.html#detrending-monthly-attacks",
    "title": "Exploratory Data Analysis",
    "section": "Detrending Monthly Attacks",
    "text": "Detrending Monthly Attacks\n\n\n\nCall:\nlm(formula = monthly_attacks_ts ~ time(monthly_attacks_ts), na.action = NULL)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.347 -3.363 -1.524  1.317 59.172 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              376.72017   36.25612   10.39   <2e-16 ***\ntime(monthly_attacks_ts)  -0.18622    0.01817  -10.25   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.617 on 610 degrees of freedom\nMultiple R-squared:  0.1469,    Adjusted R-squared:  0.1455 \nF-statistic:   105 on 1 and 610 DF,  p-value: < 2.2e-16\n\n\n\n\n\nOur trend using OLS was:\n\\(\\hat\\mu_t\\) = 376.72 - 0.18622t\nTherefore, equation of the fit of the underlying stationary process is:\n\\(\\hat{y_t}\\) = \\(x_t\\) + 376.72 - 0.18622t\nThe Detrended series is very much similar to the original series, signaling that differencing could provide a more stationary transformation. The linear model’s \\(R^2\\) value is 0.1469, suggesting that the model captures 15% of the variation in prices. Therefore, a quadratic model or first differencing would perhaps provide a better fit.\nWe then see that, even after detrending, the series contains seasonality, which further reinforces our above point that the linear model does not do very well in capturing the initial decreasing trend and then the increasing trend for recent years. Moreover, the data is not trend stationary, which bolsters the above argument.\n\nACF and PACF Plots After Differencing Monthly Attacks\n\n\n\n\n\nFirst order differencing performs better than detrending, so we shall use this series in the next section when building our autoregressive models. However, we also saw from the original PACF plot that the PACF declineS to zero relatively quickly than that of the differenced series. Therefore, the original series could also directly be fitted to the autoregressive models.\n\n\nMoving Average Smoothing"
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html",
    "href": "ARMA-ARIMA-SARIMA.html",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "",
    "text": "After completing the exploratory data analysis (EDA) phase, the next step is to begin building time series models. In order to do so, one must first choose an appropriate model type, such as an ARMA (AutoRegressive Moving Average) model or one of its variations, including ARIMA (AutoRegressive Integrated Moving Average) or SARIMA (Seasonal AutoRegressive Integrated Moving Average).\nAn ARIMA model is generally notated as ARIMA(p,d,q) where p is the order of the AR process, d is the degree of differencing and q is the order of the MA process. The general equation of the model is given as follows:\n\\(\\phi(B)(1-B)^d x_t = \\delta + \\theta(B) w_t\\), where \\(B\\) is the backshift operator, \\(w_t\\) is the Gaussian white noise process, \\(\\delta\\) is the drift term and \\(\\phi(B)\\) and \\(\\theta(B)\\) correspond to the AR and MA parts respectively.\nLag plots, auto-correlation function (ACF) and partial auto-correlation function (PACF) plots, decomposing the time series, and differencing are all useful techniques that were employed during the EDA phase to help inform the choice of model type and parameters. With a solid understanding of the data and its characteristics, one can begin to develop and refine time series models that can be used for forecasting.\nCode for this section can be found here"
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-time-series-modeling",
    "href": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-time-series-modeling",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Global Terrorism Database Time Series Modeling",
    "text": "Global Terrorism Database Time Series Modeling\n\n\n\n\nACF and PACF Plots of Monthly Attacks\n\n\n\n\n\n\n\nADF Test of Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  monthly_attacks_ts\nDickey-Fuller = -7.3335, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we reject the null hypothesis and conclude that the monthly attacks series is stationary. Although the ADF states that the original series is stationary, the ACF plots, which clearly indicate seasonality and trend, are more reliable than the ADF test. Therefore, it is safe to conclude that the series non-stationary as per the (ACF?) section above.\n\n\nLog-Transformation of Monthly Attacks\n\n\n\n\n\n\n\n\nSimply taking log of the number of monthly attacks does not make it stationary. First-differencing the log number of monthly attacks does, however, make the series stationary and this series should be employed for building our time series model. Keep in mind that because first-differencing was enough to make the series stationary, we do not need to second-difference it, helping us avoid over differencing the number of monthly attacks.\n\n\nADF Test of Log First-Differenced Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  dlx\nDickey-Fuller = -13.177, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we reject the null hypothesis and conclude that the log first-differenced monthly attacks series is stationary. Let us now check whether the ACF plots supports this hypothesis.\n\n\nACF and PACF Plots of Log First-Differenced Monthly Attacks\n\n\n\n\n\np values obtained from PACF are 1, 2, 3, 4 q values obtained from ACF are: 1 d (Difference): 1\n\n\nFitting ARIMA(p,d,q)\n\n\n\n\n\n\np\nd\nq\nAIC\nBIC\nAICc\n\n\n\n\n2\n1\n1\n2\n1184.760\n1206.827\n1184.859\n\n\n3\n1\n1\n3\n1187.562\n1214.043\n1187.702\n\n\n6\n2\n1\n2\n1188.993\n1215.473\n1189.132\n\n\n4\n1\n1\n4\n1184.796\n1215.690\n1184.982\n\n\n10\n3\n1\n2\n1184.825\n1215.719\n1185.011\n\n\n7\n2\n1\n3\n1188.316\n1219.210\n1188.502\n\n\n11\n3\n1\n3\n1186.472\n1221.780\n1186.712\n\n\n8\n2\n1\n4\n1188.815\n1224.122\n1189.054\n\n\n12\n3\n1\n4\n1187.936\n1227.657\n1188.236\n\n\n9\n3\n1\n1\n1250.578\n1277.059\n1250.718\n\n\n5\n2\n1\n1\n1265.762\n1287.830\n1265.862\n\n\n1\n1\n1\n1\n1319.040\n1336.694\n1319.106\n\n\n\n\n\n\n Best Model in terms of AIC: \n\n\n  p d q     AIC      BIC     AICc\n2 1 1 2 1184.76 1206.827 1184.859\n\n\n\n Best Model in terms of AICc: \n\n\n  p d q     AIC      BIC     AICc\n2 1 1 2 1184.76 1206.827 1184.859\n\n\n\n Best Model in terms of BIC: \n\n\n  p d q     AIC      BIC     AICc\n2 1 1 2 1184.76 1206.827 1184.859\n\n\nThe best model with the lowest AIC, BIC, and AICc metrics is the ARIMA(1, 1, 2) model. The equation of the model is given by:\n\\(\\begin{equation}(1-B)(1-B^1)y_t = \\delta + (1+\\phi_1B)(1-\\theta_1B-\\theta_2B^2)w_t\\end{equation}\\), where \\((1-B)\\) and \\((1-B^1)\\) are the differencing operators, which represent the first-order difference of the series. \\(y_t\\) is the time series, \\(\\delta\\) is the drift term, \\(\\phi_1\\) and \\(\\theta_1\\), \\(\\theta_2\\) are the parameters of the AR and MA parts, respectively, and \\(w_t\\) is the Gaussian white noise process.\nNote that \\(B\\) is the backshift operator, which shifts the time series back by one period.\n\n\nModel Diagnostics of ARIMA(1,1,2)\n\n\n\n\n\nStandardized Residuals: Essentially stating that if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\nACF Of Residuals: Auto-correlation of the residuals. The only q value to inspect is 1.\nQ-Q Plot: The series follows a normal distribution pretty closely as even the tails seem to be on the normal line.\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value greater than 0.05, our series is stationary.\n\n\nChecking Model Output of ARIMA(1,1,2) with auto.arima()\n\n\nModel metrics using auto.arima(): \n\n\nSeries: monthly_attacks_ts \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.1389  -0.7431\ns.e.  0.0645   0.0432\n\nsigma^2 = 18.69:  log likelihood = -1760.85\nAIC=3527.7   AICc=3527.74   BIC=3540.95\n\nTraining set error measures:\n                    ME     RMSE      MAE  MPE MAPE    MASE       ACF1\nTraining set -0.154373 4.313143 2.764126 -Inf  Inf 0.72581 0.01754544\n\n\n\nModel metrics of ARIMA(1, 1, 2) using Arima(): \n\n\nSeries: dlx \nARIMA(1,1,2) \n\nCoefficients:\n         ar1      ma1     ma2\n      0.0327  -1.8568  0.8579\ns.e.  0.0503   0.0299  0.0292\n\nsigma^2 = 0.4:  log likelihood = -589.26\nAIC=1186.51   AICc=1186.58   BIC=1204.17\n\nTraining set error measures:\n                     ME      RMSE       MAE MPE MAPE      MASE         ACF1\nTraining set 0.05076924 0.6304084 0.5003311 NaN  Inf 0.5417286 -0.007967481\n\n\nFrom the above output, auto.arima() outputted an ARIMA(1,1,1) model, which is slightly simpler than the best model obtained with the Arima() function. In fact, the ARIMA(1,1,1) model was the worst model obtained using the Arima() function and that is noted in the table outputted in (best-fit?). This difference can be expected when using auto.arima() because it is not as reliable as the Arima() when building ARIMA models. The case is different when building SARIMA models, which is covered in the next section.\nThe best model outputted by Arima() performs significantly better than the model outputted by auto.arima() in terms of model selection metrics, including AIC, BIC, and AICc. Moreover, the best model outputted by Arima() also outperforms the model outputted by auto.arima() in terms of training set metrics, including RMSE, MAE, and MAPE. Although the auto.arima() model does well to closely match the best Arima() model by including a differenced order in its model and by choosing the right p or AR order, it does not select an additional MA order that would make the model more robust, as seen by the comparison of metrics. Some points to keep in mind when using these functions is as follows.\nThe auto.arima() function in R uses a stepwise algorithm to search through the space of possible ARIMA models and select the one with the lowest AIC value. While this approach can be computationally efficient and provide a good starting point for model selection, it does not necessarily find the best possible model for a given time series.\nOn the other hand, the Arima() function in R allows you to specify the exact order of the ARIMA model and can be used to fit more complex models, such as those with seasonality, exogenous variables, or other constraints. By specifying the exact order of the model, you have more control over the modeling process and can potentially obtain a better fit to the data.\nIn summary, the auto.arima() function can be a useful tool for quickly identifying a potentially good model, but it is not a substitute for careful model selection and customization using the Arima() function.\n\n\nForecasting ARIMA(1,1,2)\n\n\n\n\n\n$pred\n            Jan        Feb        Mar        Apr        May        Jun\n2021 0.37759011 0.02555481 0.01273564 0.01231300 0.01234339 0.01239033\n2022 0.01272329 0.01277086                                            \n            Jul        Aug        Sep        Oct        Nov        Dec\n2021 0.01243788 0.01248544 0.01253301 0.01258058 0.01262815 0.01267572\n2022                                                                  \n\n$se\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2021 0.6282655 0.8166695 0.8168888 0.8168890 0.8168890 0.8168890 0.8168890\n2022 0.8168890 0.8168890                                                  \n           Aug       Sep       Oct       Nov       Dec\n2021 0.8168890 0.8168890 0.8168890 0.8168890 0.8168890\n2022                                                  \n\n\nFrom the above graph, we can note that the number of attacks will fluctuate anywhere between 0 to 6 (converting from log data) every month from 2021 to 2022, as per the 95% confidence bound. A spike is noticed for the first observed forecast after which the model does poorly to forecast the rest of the year. Since the ARIMA(1,1,2) is relatively simple, it is not as robust and complex to forecast more than a month into the future. The straight red line forecast after the first forecasted month suggests that 1 attack per month (converting from log data) would take place, an averaged out value. This is expected.\nMoreover, the other suboptimal models outputted by Arima() also give the same forecast, so overlaying them onto the above plot would be redundant. It is, however, pragmatic to check whether the auto.arima() model’s forecast may forecast differently. Let us find out below.\n\n\nForecasting ARIMA(1,1,1) Outputted by auto.arima()\n\n\n\n\n\n$pred\n              Jan          Feb          Mar          Apr          May\n2021  0.160739303 -0.066511129  0.048747789 -0.009617016  0.020030951\n2022  0.010443266  0.010418886                                       \n              Jun          Jul          Aug          Sep          Oct\n2021  0.005063770  0.012712754  0.008897226  0.010893251  0.009943302\n2022                                                                 \n              Nov          Dec\n2021  0.010486717  0.010273121\n2022                          \n\n$se\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2021 0.7049204 0.7897960 0.8104291 0.8155169 0.8168849 0.8172028 0.8173013\n2022 0.8173278 0.8173277                                                  \n           Aug       Sep       Oct       Nov       Dec\n2021 0.8173181 0.8173267 0.8173267 0.8173278 0.8173276\n2022                                                  \n\n\nLike the previous forecast, we can note that, for the auto.arima() model, the number of attacks will fluctuate anywhere between 0 to 6 every month from 2021 to 2022 (again this is logged data), as per the 95% confidence bound. However, from the above plot, it can be discerned from red line that the auto.arima() model’s forecasts fluctuate more for the initial months’ forecasts than that of the Arima() model’s forecasts, which was smoother for the initial 2 months. Like the Arima() model’s forecasts, the the auto.arima() model’s forecast then lie on a single value, 1 attack per month, as the red line flattens out. Note that the output of the auto.arima() model was ARIMA(1,1,1), so it was expected that the forecast would be slightly less smoother than the ARIMA(1,1,2) model outputted by Arima(). This is attributed to the fact that ARIMA(1,1,2) has an additional Moving-Average term, which help make its forecasts smoother.\n\n\nComparing ARIMA(1,1,2) with Benchmarks\n\n\n\n\n\nBest model metrics: \n\n\nSeries: dlx \nARIMA(1,1,2) \n\nCoefficients:\n         ar1      ma1     ma2\n      0.0327  -1.8568  0.8579\ns.e.  0.0503   0.0299  0.0292\n\nsigma^2 = 0.4:  log likelihood = -589.26\nAIC=1186.51   AICc=1186.58   BIC=1204.17\n\nTraining set error measures:\n                     ME      RMSE       MAE MPE MAPE      MASE         ACF1\nTraining set 0.05076924 0.6304084 0.5003311 NaN  Inf 0.5417286 -0.007967481\n\n\n\nSnaive metrics: \n\n\n                       ME     RMSE       MAE MPE MAPE MASE       ACF1\nTraining set -0.000351788 1.145667 0.9235824 NaN  Inf    1 -0.5112064\n\n\nFrom the above plot, only the Snaive benchmark method’s forecasts seem more plausible compared to that of the ARIMA(1,1,2) model. The forecasts produced from the Snaive benchmark have the greatest amount of fluctuations or seasonality in a higher range of number of monthly attacks. However, the metrics paint a different story. The ARIMA(1,1,2) model’s training error measures are better than those of the Snaive benchmark. There are several reasons for this phenomenon:\nModel Assumptions: The ARIMA model assumes that the data is stationary, which means that the mean and variance of the data do not change over time. If the data violates this assumption, the ARIMA model may not perform well. In contrast, the Snaive model does not assume stationarity, which may make it more robust to non-stationary data.\nParameter Estimation: The ARIMA model has three parameters (p, d, q) that need to be estimated, whereas the Snaive model has only one parameter (the seasonality). It is possible that the parameter estimation process for the ARIMA model was not optimal, leading to suboptimal forecast performance.\nForecast Horizon: The Snaive model may perform better than the ARIMA model for shorter forecast horizons, while the ARIMA model may perform better for longer forecast horizons. This is because the Snaive model assumes that the future values of the time series will be the same as the past values at the same time of year, which may be a reasonable assumption for short forecast horizons, but not for longer ones."
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-arima-modeling",
    "href": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-arima-modeling",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Global Terrorism Database ARIMA Modeling",
    "text": "Global Terrorism Database ARIMA Modeling\n\n\n\n\nSplitting Series into Train and Test Sets for Model Validation Process\nAfter cleaning and aggregating the Global Terrorism Database™ (GTD) (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.) by month, we shall be splitting the aggregated monthly data set into train and test sets for model validation. I have kept 587 observations for training and the remaining 48 observations for testing or validating. Therefore, I have kept aside 2 years (48 months or 48 observations) for forecasting purposes.\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\n\n\n\n\n\nACF and PACF Plots of Monthly Attacks\n\n\n\n\n\n\n\nADF Test of Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  train_series\nDickey-Fuller = -7.2458, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we reject the null hypothesis and conclude that the monthly attacks series is stationary. Although the ADF states that the original series is stationary, the ACF plots, which clearly indicate seasonality and trend, are more reliable than the ADF test. Therefore, it is safe to conclude that the series non-stationary as per the (ACF?) section above.\n\n\nLog-Transformation of Monthly Attacks and its First and Second Order Differencing\n\n\n\n\n\n\n\n\nSimply taking log of the number of monthly attacks does not make it stationary. First-differencing the log number of monthly attacks does, however, make the series stationary and this series should be employed for building our time series model. Keep in mind that because first-differencing was enough to make the series stationary, we do not need to second-difference it, helping us avoid over differencing the number of monthly attacks.\n\n\nADF Test of Log First-Differenced Monthly Attacks\n\\(H_0\\): The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\\(H_1\\): The time series is stationary.\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  dlx\nDickey-Fuller = -12.802, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nBecause the p-value from the ADF test is less than \\(\\alpha\\) = 0.05, we reject the null hypothesis and conclude that the log first-differenced monthly attacks series is stationary. Let us now check whether the ACF plots supports this hypothesis.\n\n\nACF and PACF Plots of Log First-Differenced Monthly Attacks\n\n\n\n\n\np values obtained from PACF are 0, 1, 2, 3, 4 q values obtained from ACF are: 0, 1 d (Difference): 1\n\n\nFitting ARIMA(p,d,q)\n\n\n\n\n\n\np\nd\nq\nAIC\nBIC\nAICc\n\n\n\n\n2\n0\n1\n1\n1129.146\n1137.892\n1129.166\n\n\n6\n1\n1\n1\n1131.028\n1144.148\n1131.069\n\n\n3\n0\n1\n2\n1131.045\n1144.165\n1131.087\n\n\n12\n2\n1\n3\n1120.047\n1146.287\n1120.192\n\n\n10\n2\n1\n1\n1130.116\n1147.609\n1130.185\n\n\n4\n0\n1\n3\n1130.121\n1147.614\n1130.189\n\n\n7\n1\n1\n2\n1133.117\n1150.610\n1133.186\n\n\n14\n3\n1\n1\n1131.179\n1153.046\n1131.283\n\n\n8\n1\n1\n3\n1131.272\n1153.139\n1131.376\n\n\n11\n2\n1\n2\n1131.710\n1153.577\n1131.813\n\n\n16\n3\n1\n3\n1126.189\n1156.802\n1126.383\n\n\n18\n4\n1\n1\n1132.357\n1158.597\n1132.502\n\n\n15\n3\n1\n2\n1132.897\n1159.137\n1133.042\n\n\n19\n4\n1\n2\n1132.672\n1163.285\n1132.866\n\n\n20\n4\n1\n3\n1134.670\n1169.657\n1134.920\n\n\n17\n4\n1\n0\n1176.672\n1198.538\n1176.775\n\n\n13\n3\n1\n0\n1187.101\n1204.594\n1187.170\n\n\n9\n2\n1\n0\n1201.337\n1214.457\n1201.379\n\n\n5\n1\n1\n0\n1255.509\n1264.255\n1255.529\n\n\n1\n0\n1\n0\n1434.634\n1439.007\n1434.640\n\n\n21\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n22\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n23\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n24\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n Best Model in terms of AIC: \n\n\n   p d q      AIC      BIC     AICc\n12 2 1 3 1120.047 1146.287 1120.192\n\n\n\n Best Model in terms of AICc: \n\n\n   p d q      AIC      BIC     AICc\n12 2 1 3 1120.047 1146.287 1120.192\n\n\n\n Best Model in terms of BIC: \n\n\n  p d q      AIC      BIC     AICc\n2 0 1 1 1129.146 1137.892 1129.166\n\n\n\nModel summary and error metrics of ARIMA(0, 1, 1): \n\n\nSeries: lx \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8436\ns.e.   0.0240\n\nsigma^2 = 0.3992:  log likelihood = -562.57\nAIC=1129.15   AICc=1129.17   BIC=1137.89\n\nTraining set error measures:\n                     ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.0182295 0.6307598 0.4949849 -Inf  Inf 0.7886882 0.01012716\n\n\nThe best model with the lowest BIC metric is the ARIMA(0,1,1). This model is a pure moving average model with first-order differencing and a single lagged moving average term. Therefore, the model has no autoregressive terms, i.e., it does not use the past values of the variable to predict its future values. It uses only the difference between the current and previous values of the variable and the error term to make the forecast. Although, according to both AIC and AICc metrics, the ARIMA(2,1,3) model is better, we shall choose our model using the BIC metric because BIC is more stringent than AIC in penalizing the number of parameters used in the model, making it more effective in helping reduce overfitting.\nARIMA(2,1,3) is a time series model that involves taking the first-order difference of the series, using two Autoregressive (AR) terms and three Moving Average (MA) terms. This means that the model uses not only the past two values of the variable, but also the past three errors to make the forecast. The inclusion of the MA terms allows the model to capture the influence of random shocks or noise in the data. However, including too many autoregressive terms may lead to overfitting, which can result in poor forecast performance and we shall explore that in the next few sections\nThe choice between ARIMA(0,1,1) and ARIMA(2,1,3) depends on the nature of the data and the performance of the models in terms of RMSE or other error metrics. If the data has a clear trend, then including Autoregressive terms may improve the forecast accuracy. On the other hand, if the data is more random, then a simpler model like ARIMA(0,1,1) may be sufficient. There is a clear decreasing trend of monthly terrorist attacks from the 1970s to 2015, with random and/or seasonal fluctuations, but the number of attacks does start increasing sharply after 2015. Therefore, no single pattern is discerned along the entire series and, moreover, we shall be abiding by the principle of parsimony if we select ARIMA(0,1,1) as the best model.\nThe equation of the ARIMA(0,1,1) model is given by:\n\\(\\begin{equation}(1-B)(1-\\theta_1B)X_t = \\omega_t\\end{equation}\\), giving us:\n\\(\\begin{equation}\\left(1-\\theta_1B+B-\\theta_1B^2\\right)X_t = \\omega_t\\end{equation}\\), giving us:\n\\(\\begin{equation}\\left(1-\\theta_1B\\right)X_t - B\\left(1-\\theta_1B\\right)X_t = \\omega_t\\end{equation}\\), giving us:\n\\(\\begin{equation}X_t - \\theta_1X_{t-1} - B\\left(X_{t-1}-\\theta_1X_{t-2}\\right) = \\omega_t\\end{equation}\\), finally substituting the MA(1) values from the model’s summary:\n\\(\\begin{equation}X_t = -0.8436X_{t-1} + X_{t-1} + 0.8436X_{t-2} + \\omega_t\\end{equation}\\), where \\((1-B)\\) is the differencing operator, which represents the first-order difference of the series. \\(X_t\\) is the time series, \\(\\theta_1\\) is the parameter of the MA component, and \\(\\omega_t\\) is the Gaussian white noise process.\nNote that \\(B\\) is the backshift operator, which shifts the time series back by one period.\n\n\nModel Diagnostics of ARIMA(0,1,1)\n\n\n\n\n\n\n\nconverged\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, \n        REPORT = 1, reltol = tol))\n\nCoefficients:\n          ma1  constant\n      -0.8453   -0.0028\ns.e.   0.0239    0.0041\n\nsigma^2 estimated as 0.3982:  log likelihood = -562.33,  aic = 1130.67\n\n$degrees_of_freedom\n[1] 584\n\n$ttable\n         Estimate     SE  t.value p.value\nma1       -0.8453 0.0239 -35.3385  0.0000\nconstant  -0.0028 0.0041  -0.6943  0.4877\n\n$AIC\n[1] 1.929468\n\n$AICc\n[1] 1.929504\n\n$BIC\n[1] 1.951857\n\n\nStandardized Residuals: Essentially stating that if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\nACF Of Residuals: Auto-correlation of the residuals. The only q value to inspect is 1.\nQ-Q Plot: The series follows a normal distribution pretty closely as even the tails seem to be on the normal line.\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value greater than 0.05, the residuals have no remaining autocorrelations.\nThe only MA term in the ARIMA(0,1,1) model is also significant at the \\(\\alpha\\)=5% level as shown by its p-value = 0. Let’s check whether all terms in the ARIMA(2,1,3) model are significant or not.\n\n\nModel Diagnostics of ARIMA(2,1,3)\n\n\n\n\n\n\n\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, \n        REPORT = 1, reltol = tol))\n\nCoefficients:\n         ar1      ar2      ma1     ma2      ma3  constant\n      0.8068  -0.5518  -1.6452  1.2913  -0.5429   -0.0026\ns.e.  0.4763   0.4308   0.4609  0.7776   0.3347    0.0036\n\nsigma^2 estimated as 0.3934:  log likelihood = -558.77,  aic = 1131.54\n\n$degrees_of_freedom\n[1] 580\n\n$ttable\n         Estimate     SE t.value p.value\nar1        0.8068 0.4763  1.6939  0.0908\nar2       -0.5518 0.4308 -1.2809  0.2007\nma1       -1.6452 0.4609 -3.5693  0.0004\nma2        1.2913 0.7776  1.6608  0.0973\nma3       -0.5429 0.3347 -1.6223  0.1053\nconstant  -0.0026 0.0036 -0.7029  0.4824\n\n$AIC\n[1] 1.93095\n\n$AICc\n[1] 1.931198\n\n$BIC\n[1] 1.983192\n\n\nLike the ARIMA(0,1,1) output for the summary of residuals, the ARIMA(2,1,3) does as well, if not better. The ACF of residuals for ARIMA(2,1,3), although, has spikes less significant than ARIMA(0,1,1) and the p-values for Ljung-Box test for ARIMA(2,1,3) are higher than those of ARIMA(0,1,1). However, a key difference is that only the MA(1) term in the ARIMA(2,1,3) model is significant at the \\(\\alpha\\)=5% level as shown by its p-value = 0.0004 and all other terms are not significant. Therefore, a simpler model, ARIMA(0,1,1), would be a better fit to the log of monthly attacks series.\nLet’s see what model is outputted by auto.arima().\n\n\nChecking Model Output of Log Monthly Attacks with auto.arima()\n\n\nModel metrics using auto.arima(): \n\n\nSeries: lx \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8436\ns.e.   0.0240\n\nsigma^2 = 0.3992:  log likelihood = -562.57\nAIC=1129.15   AICc=1129.17   BIC=1137.89\n\nTraining set error measures:\n                     ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.0182295 0.6307598 0.4949849 -Inf  Inf 0.7886882 0.01012716\n\n\nFrom the above output, auto.arima() too outputted an ARIMA(0,1,1) model, which is is the best model returned by the Arima() function in terms of lowest BIC (best-fit?). Some points to keep in mind when using these functions is as follows:\nThe auto.arima() function in R uses a stepwise algorithm to search through the space of possible ARIMA models and select the one with the lowest AIC value. While this approach can be computationally efficient and provide a good starting point for model selection, it does not necessarily always find the best possible model for a given time series.\nOn the other hand, the Arima() function in R allows us to specify the exact order of the ARIMA model and can be used to fit more complex models, such as those with seasonality, exogenous variables, or other constraints. By specifying the exact order of the model, we have more control over the modeling process and can potentially obtain a better fit to the data.\nIn summary, the auto.arima() function can be a useful tool for quickly identifying a potentially good model, but it is not a substitute for careful model selection and customization seen when using the Arima() function.\n\n\nForecasting ARIMA(0,1,1) and ARIMA(2,1,3)\n\n\n\n\n\n\nFrom the above graph, we can note that the forecasted number of attacks remains constant at around 1 for both models on the test set (October 2010 to December 2020). This performance is not what was expected and, hence, it is possible that the models are not able to capture the underlying patterns in the data. This can be due to a variety of reasons, such as insufficient data and the models not being complex enough to capture the variation in the data. It is, however, pragmatic to check whether the sarima.for() function’s predictions may forecast differently. Let us find out below.\n\n\nForecasting ARIMA(0,1,1) using sarima.for()\n\n\n\n\n\n$pred\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2018                                                                        \n2019 1.954087 1.951260 1.948432 1.945605 1.942778 1.939950 1.937123 1.934296\n2020 1.920159 1.917332 1.914505 1.911678 1.908850 1.906023 1.903196 1.900368\n          Sep      Oct      Nov      Dec\n2018                            1.956914\n2019 1.931469 1.928641 1.925814 1.922987\n2020 1.897541 1.894714 1.891886         \n\n$se\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2018                                                                      \n2019 0.6385446 0.6459664 0.6533040 0.6605600 0.6677372 0.6748381 0.6818650\n2020 0.7225930 0.7291599 0.7356681 0.7421193 0.7485148 0.7548562 0.7611448\n           Aug       Sep       Oct       Nov       Dec\n2018                                         0.6310354\n2019 0.6888203 0.6957060 0.7025242 0.7092769 0.7159659\n2020 0.7673818 0.7735685 0.7797062 0.7857959          \n\n\nLike the previous forecast, we can note that sarima.for() too does not accurately capture the inherent randomness and/or seasonality in the series and, hence, it outputs a highly linear, downward trending forecast. As per its 95% confidence bound, the number of attacks will fluctuate anywhere between 3 to 12 attacks every month from 2019 to end of 2020 (keep in mind that the plot is log of monthly attacks).\n\n\nComparing ARIMA(0,1,1) with Benchmarks\n\n\n\n\n\nARIMA(0,1,1) model metrics: \n\n\nSeries: log_monthly_attacks \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8436\ns.e.   0.0240\n\nsigma^2 = 0.3992:  log likelihood = -562.57\nAIC=1129.15   AICc=1129.17   BIC=1137.89\n\nTraining set error measures:\n                     ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.0182295 0.6307598 0.4949849 -Inf  Inf 0.7143174 0.01012716\n\n\n\nMean metrics: \n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Mean\nQ* = 2327.6, df = 23, p-value < 2.2e-16\n\nModel df: 1.   Total lags used: 24\n\n\n                       ME      RMSE       MAE  MPE MAPE      MASE     ACF1\nTraining set 1.113627e-15 0.8556503 0.6744582 -Inf  Inf 0.9733169 0.534751\n\n\n\nSnaive metrics: \n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Seasonal naive method\nQ* = 173.01, df = 24, p-value < 2.2e-16\n\nModel df: 0.   Total lags used: 24\n\n\n                      ME      RMSE       MAE  MPE MAPE MASE      ACF1\nTraining set -0.03643642 0.8807625 0.6929481 -Inf  Inf    1 0.1556335\n\n\n\nRandom Walk metrics: \n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Random walk\nQ* = 178.32, df = 24, p-value < 2.2e-16\n\nModel df: 0.   Total lags used: 24\n\n\n                       ME      RMSE       MAE  MPE MAPE      MASE       ACF1\nTraining set -0.001694969 0.8215562 0.6276053 -Inf  Inf 0.9057032 -0.5152558\n\n\nFrom the above plot, only the Snaive benchmark method’s forecasts seem more plausible compared to that of the ARIMA(0,1,1) model. The forecasts produced from the Snaive benchmark have the greatest amount of fluctuations or seasonality in a higher range of number of monthly attacks. However, the metrics paint a different story. The ARIMA(0,1,1) model’s training error measures are better than those of all the benchmarks. There are several reasons for this phenomenon:\nModel Assumptions: The ARIMA model assumes that the data is stationary, which means that the mean and variance of the data do not change over time. If the data violates this assumption, the ARIMA model may not perform well. In contrast, the Snaive model does not assume stationarity, which may make it more robust to non-stationary data.\nParameter Estimation: The ARIMA model has three parameters (p, d, q) that need to be estimated, whereas the Snaive model has only one parameter (the seasonality). It is possible that the parameter estimation process for the ARIMA model was not optimal, leading to suboptimal forecast performance.\nForecast Horizon: The Snaive model may perform better than the ARIMA model for shorter forecast horizons, while the ARIMA model may perform better for longer forecast horizons. This is because the Snaive model assumes that the future values of the time series will be the same as the past values at the same time of year, which may be a reasonable assumption for short forecast horizons, but not for longer ones."
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-sarima-modeling",
    "href": "ARMA-ARIMA-SARIMA.html#global-terrorism-database-sarima-modeling",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Global Terrorism Database SARIMA Modeling",
    "text": "Global Terrorism Database SARIMA Modeling\n\nVisualizing Seasonal Components of Monthly Attacks\n\n\n\n\n\nFrom the above seasonal component graph of the number of monthly terrorist attacks, we notice there does exist some level of seasonality in the original series. The seasonal component graph illustrates the degree of seasonal variation in the number of terrorist attacks. The magnitude of the seasonal variation is shown on the y-axis of the graph, and it indicates how much the number of terrorist attacks deviates from the average value for each season. The graph shows a repeating pattern in the number of terrorist attacks over time, with clear peaks in the first and second quarters and troughs in the third quarter. This pattern implies that the number of terrorist attacks in the US might be influenced by the season of the year.\n\n\nVisualizing Seasonally Differenced Monthly Attacks\n\n\n\n\n\n\n\nACF and PACF Plots of Seasonally Differenced Monthly Attacks\n\n\n\n\n\nAfter first ordinary differencing the original series (ACF?), we saw a lot of seasonal correlation left, suggesting that first order differencing did not help in transforming the raw data into a stationary series. This differenced series cannot be used for building a robust SARIMA model. Therefore, a seasonal differencing on the original monthly attacks was performed above and we can still notice some correlation left, but lesser compared to when the raw series was differenced with first order. Therefore, it could be that D=1 and d=0. Let’s keep this as one option and let’s proceed with performing both seasonal differencing and first-order differencing the raw monthly attacks series.\n\n\nACF and PACF Plots of Seasonally and First Order Differenced Monthly Attacks\n\n\n\n\n\nAfter both seasonal differencing and ordinary differencing together the raw data, the ACF and PACF plots seem to portray the least correlation than the individual differencing methods. Next, we shall difference and select the relevant p,d,q,P,D,Q values from the original monthly attacks series for our SARIMA model.\nFrom the seasonal differencing and ordinary differencing (together) ACF and PACF plots, the following combinations for p,d,q,P,D,Q are:\nq values obtained from ACF = 0,1,2,3,4 Q values obtained from ACF = 1 p values obtained from PACF = 0,1,2,3,4 P values obtained from PACF = 1,2 d (Difference) = 1 D (Seasonal Difference) = 1\n\n\nFitting ARIMA(p,d,q)(P,D,Q)\n\n\n\n\n\n\n\n\np\nd\nq\nP\nD\nQ\nAIC\nBIC\nAICc\n\n\n\n\n0\n1\n0\n0\n1\n0\n3952.891\n3957.286\n3952.897\n\n\n0\n1\n0\n0\n1\n1\n3670.269\n3679.059\n3670.289\n\n\n0\n1\n0\n1\n1\n0\n3827.797\n3836.587\n3827.817\n\n\n0\n1\n0\n1\n1\n1\n3670.336\n3683.521\n3670.376\n\n\n0\n1\n0\n2\n1\n0\n3765.751\n3778.937\n3765.791\n\n\n0\n1\n0\n2\n1\n1\n3671.380\n3688.961\n3671.447\n\n\n0\n1\n1\n0\n1\n0\n3705.459\n3714.249\n3705.479\n\n\n0\n1\n1\n0\n1\n1\n3495.035\n3508.220\n3495.075\n\n\n0\n1\n1\n1\n1\n0\n3596.169\n3609.355\n3596.209\n\n\n0\n1\n1\n1\n1\n1\n3492.557\n3510.138\n3492.625\n\n\n0\n1\n1\n2\n1\n0\n3570.165\n3587.746\n3570.232\n\n\n0\n1\n2\n0\n1\n0\n3701.229\n3714.415\n3701.269\n\n\n0\n1\n2\n0\n1\n1\n3493.391\n3510.972\n3493.458\n\n\n0\n1\n2\n1\n1\n0\n3595.313\n3612.894\n3595.381\n\n\n0\n1\n3\n0\n1\n0\n3699.991\n3717.572\n3700.058\n\n\n1\n1\n0\n0\n1\n0\n3818.806\n3827.596\n3818.826\n\n\n1\n1\n0\n0\n1\n1\n3553.235\n3566.421\n3553.276\n\n\n1\n1\n0\n1\n1\n0\n3693.837\n3707.023\n3693.878\n\n\n1\n1\n0\n1\n1\n1\n3552.817\n3570.398\n3552.884\n\n\n1\n1\n0\n2\n1\n0\n3651.212\n3668.793\n3651.279\n\n\n1\n1\n1\n0\n1\n0\n3700.223\n3713.408\n3700.263\n\n\n1\n1\n1\n0\n1\n1\n3492.442\n3510.023\n3492.510\n\n\n1\n1\n1\n1\n1\n0\n3594.929\n3612.510\n3594.996\n\n\n1\n1\n2\n0\n1\n0\n3704.894\n3722.475\n3704.961\n\n\n2\n1\n0\n0\n1\n0\n3777.584\n3790.770\n3777.624\n\n\n2\n1\n0\n0\n1\n1\n3521.643\n3539.224\n3521.710\n\n\n2\n1\n0\n1\n1\n0\n3654.644\n3672.225\n3654.712\n\n\n2\n1\n1\n0\n1\n0\n3700.164\n3717.745\n3700.232\n\n\n3\n1\n0\n0\n1\n0\n3772.136\n3789.717\n3772.204\n\n\n\n\n\n\n Best Model in terms of AIC: \n\n\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n\n\n\n Best Model in terms of AICc: \n\n\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n\n\n\n Best Model in terms of BIC: \n\n\n  p d q P D Q      AIC     BIC     AICc\n8 0 1 1 0 1 1 3495.035 3508.22 3495.075\n\n\nThe best model with the lowest BIC metric is the SARIMA(0,1,1,0,1,1) model. Although, according to both AIC and AICc metrics, the SARIMA(1,1,1,0,1,1) is better, we shall choose our model using the BIC metric because BIC is more stringent than AIC in penalizing the number of parameters used in the model, making it more effective in helping reduce overfitting. The equation of the SARIMA(0,1,1,0,1,1) model is given by:\n\\(\\begin{equation}(1-B)(1-B^1)y_t = \\delta + (1+\\phi_1B)(1-\\theta_1B-\\theta_2B^2)w_t\\end{equation}\\), where \\((1-B)\\) and \\((1-B^1)\\) are the differencing operators, which represent the first-order difference of the series. \\(y_t\\) is the time series, \\(\\delta\\) is the drift term, \\(\\phi_1\\) and \\(\\theta_1\\), \\(\\theta_2\\) are the parameters of the AR and MA parts, respectively, and \\(w_t\\) is the Gaussian white noise process.\nNote that \\(B\\) is the backshift operator, which shifts the time series back by one period.\n\n\nModel Diagnostics of ARIMA(0,1,1)(0,1,1)\n\n\n\n\n\nStandardized Residuals: Essentially stating if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\nACF Of Residuals: However, looking at the ACF of the Residuals gives us a definitive answer to whether the model is stationary. Because some spikes are not within the significance limits, the model is not being able to capture all the signal in the data. In fact, the ARIMA(1,1,2) model’s diagnostics (ARIMA-Diag?) are better than that of ARIMA(0,1,1)(0,1,1) above.\nQ-Q Plot: The series weakly follows a normal distribution as the tails waver away significantly from the normal line.\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value less than 0.05, residuals have remaining autocorrelations.\n\n\nForecast for the next 3 years using ARIMA(0,1,1)(0,1,1)\n\n\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n\n\n\n\n\n\n\nComparing ARIMA(0,1,1)(0,1,1) with benchmarks\n\n\nBest model metrics: \n\n\n\n\n\nBest model metrics: \n\n\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n\n\nSnaive metrics: \n\n\n                     ME     RMSE      MAE  MPE MAPE MASE      ACF1\nTraining set -0.6016667 6.093029 3.808333 -Inf  Inf    1 0.4168619\n\n\n\n\nSeasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 1 step ahead forecasts\n\n\nMAE for ARIMA(0,1,1)(0,1,1) is:  2.155092\n\n\n\nRMSE for ARIMA(0,1,1)(0,1,1) is:  7.428068\n\n\n\nMAE for ARIMA(1,1,1)(0,1,1) is:  2.092574\n\n\n\nRMSE for ARIMA(1,1,1)(0,1,1) is:  7.410171\n\n\nBoth MAE and RMSE metrics agree that ARIMA(1,1,1)(0,1,1) is the best model by a slight margin. However, the BIC metric does not agree with this result as it outputted ARIMA(0,1,1)(0,1,1) as the model with lowest BIC. AIC and AICc metrics, however, do agree with the MAE and RMSE metrics generated from Seasonal Cross Validation using 1 step ahead forecasts. Let’s see whether this is the case when forecasting 12 steps ahead.\n\n\nSeasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 12 steps (seasonal period) ahead forecasts\n\n\n[1] 537\n\n\n\n\n\nThis plot gives cross-validation statistics up to horizon 12. The procedure for seasonal cross validation using 12 steps ahead is very similar to seasonal cross validation using 1 step ahead. We need to change the “h” parameter to the desired the number of time horizons we want to forecast for. The farima() function manually written by us helps us call our desired SARIMA model with the number of horizons. Then, farima() function is called inside the tsCV() function, which helps us store the cross-validated errors for up to 12 steps ahead. Then, because we get forecasts for each time horizon, we need to take the mean of the squared column using colMeans to obtain MSE.\nAlthough we observed that the MSE and RMSE of ARIMA(1,1,1)(0,1,1) when forecasting 1 step ahead was lower than that of ARIMA(0,1,1)(0,1,1), from the above plot it can be seen that the cross-validated MSEs get lower or better as the number of forecasting steps increases. Both models’ MSE performance follow a very similar pattern, with ARIMA(0,1,1)(0,1,1), picked by lowest BIC, having a lower MSE across all forecasting steps, except for step 1. Therefore, ARIMA(0,1,1)(0,1,1) is the better SARIMA model!"
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#visualizing-seasonal-components-of-monthly-attacks",
    "href": "ARMA-ARIMA-SARIMA.html#visualizing-seasonal-components-of-monthly-attacks",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Visualizing Seasonal Components of Monthly Attacks",
    "text": "Visualizing Seasonal Components of Monthly Attacks\n\n\n\n\n\nFrom the above seasonal component graph of the number of monthly terrorist attacks, we notice there does exist some level of seasonality in the original series. The seasonal component graph illustrates the degree of seasonal variation in the number of terrorist attacks. The magnitude of the seasonal variation is shown on the y-axis of the graph, and it indicates how much the number of terrorist attacks deviates from the average value for each season. The graph shows a repeating pattern in the number of terrorist attacks over time, with clear peaks in the first and second quarters and troughs in the third quarter. This pattern implies that the number of terrorist attacks in the US might be influenced by the season of the year."
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#visualizing-seasonally-differenced-monthly-attacks",
    "href": "ARMA-ARIMA-SARIMA.html#visualizing-seasonally-differenced-monthly-attacks",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "Visualizing Seasonally Differenced Monthly Attacks",
    "text": "Visualizing Seasonally Differenced Monthly Attacks\n\n\n\n\n\n\nACF and PACF Plots of Seasonally Differenced Monthly Attacks\n\n\n\n\n\nAfter first ordinary differencing the original series (ACF?), we saw a lot of seasonal correlation left, suggesting that first order differencing did not help in transforming the raw data into a stationary series. This differenced series cannot be used for building a robust SARIMA model. Therefore, a seasonal differencing on the original monthly attacks was performed above and we can still notice some correlation left, but lesser compared to when the raw series was differenced with first order. Therefore, it could be that D=1 and d=0. Let’s keep this as one option and let’s proceed with performing both seasonal differencing and first-order differencing the raw monthly attacks series.\n\n\nACF and PACF Plots of Seasonally and First Order Differenced Monthly Attacks\n\n\n\n\n\nAfter both seasonal differencing and ordinary differencing together the raw data, the ACF and PACF plots seem to portray the least correlation than the individual differencing methods. Next, we shall difference and select the relevant p,d,q,P,D,Q values from the original monthly attacks series for our SARIMA model.\nFrom the seasonal differencing and ordinary differencing (together) ACF and PACF plots, the following combinations for p,d,q,P,D,Q are:\nq values obtained from ACF = 0,1,2,3,4 Q values obtained from ACF = 1 p values obtained from PACF = 0,1,2,3,4 P values obtained from PACF = 1,2 d (Difference) = 1 D (Seasonal Difference) = 1\n\n\nFitting ARIMA(p,d,q)(P,D,Q)\n\n\n\n\n# q=0,1,2,3,4; Q=1 and PACF plot: p=0,1,2,3,4; P=1,2; D=1 and d=1\n\noutput=SARIMA.c(p1=1,p2=5,q1=1,q2=5,P1=1,P2=3,Q1=1,Q2=2,data=monthly_attacks_ts)\n#output\n\nknitr::kable(output)\n\n\n\n\np\nd\nq\nP\nD\nQ\nAIC\nBIC\nAICc\n\n\n\n\n0\n1\n0\n0\n1\n0\n3952.891\n3957.286\n3952.897\n\n\n0\n1\n0\n0\n1\n1\n3670.269\n3679.059\n3670.289\n\n\n0\n1\n0\n1\n1\n0\n3827.797\n3836.587\n3827.817\n\n\n0\n1\n0\n1\n1\n1\n3670.336\n3683.521\n3670.376\n\n\n0\n1\n0\n2\n1\n0\n3765.751\n3778.937\n3765.791\n\n\n0\n1\n0\n2\n1\n1\n3671.380\n3688.961\n3671.447\n\n\n0\n1\n1\n0\n1\n0\n3705.459\n3714.249\n3705.479\n\n\n0\n1\n1\n0\n1\n1\n3495.035\n3508.220\n3495.075\n\n\n0\n1\n1\n1\n1\n0\n3596.169\n3609.355\n3596.209\n\n\n0\n1\n1\n1\n1\n1\n3492.557\n3510.138\n3492.625\n\n\n0\n1\n1\n2\n1\n0\n3570.165\n3587.746\n3570.232\n\n\n0\n1\n2\n0\n1\n0\n3701.229\n3714.415\n3701.269\n\n\n0\n1\n2\n0\n1\n1\n3493.391\n3510.972\n3493.458\n\n\n0\n1\n2\n1\n1\n0\n3595.313\n3612.894\n3595.381\n\n\n0\n1\n3\n0\n1\n0\n3699.991\n3717.572\n3700.058\n\n\n1\n1\n0\n0\n1\n0\n3818.806\n3827.596\n3818.826\n\n\n1\n1\n0\n0\n1\n1\n3553.235\n3566.421\n3553.276\n\n\n1\n1\n0\n1\n1\n0\n3693.837\n3707.023\n3693.878\n\n\n1\n1\n0\n1\n1\n1\n3552.817\n3570.398\n3552.884\n\n\n1\n1\n0\n2\n1\n0\n3651.212\n3668.793\n3651.279\n\n\n1\n1\n1\n0\n1\n0\n3700.223\n3713.408\n3700.263\n\n\n1\n1\n1\n0\n1\n1\n3492.442\n3510.023\n3492.510\n\n\n1\n1\n1\n1\n1\n0\n3594.929\n3612.510\n3594.996\n\n\n1\n1\n2\n0\n1\n0\n3704.894\n3722.475\n3704.961\n\n\n2\n1\n0\n0\n1\n0\n3777.584\n3790.770\n3777.624\n\n\n2\n1\n0\n0\n1\n1\n3521.643\n3539.224\n3521.710\n\n\n2\n1\n0\n1\n1\n0\n3654.644\n3672.225\n3654.712\n\n\n2\n1\n1\n0\n1\n0\n3700.164\n3717.745\n3700.232\n\n\n3\n1\n0\n0\n1\n0\n3772.136\n3789.717\n3772.204\n\n\n\n\ncat(\"\\n Best Model in terms of AIC: \\n\")\n\n\n Best Model in terms of AIC: \n\noutput[which.min(output$AIC),] \n\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n\ncat(\"\\n Best Model in terms of AICc: \\n\")\n\n\n Best Model in terms of AICc: \n\noutput[which.min(output$AICc),]\n\n   p d q P D Q      AIC      BIC    AICc\n22 1 1 1 0 1 1 3492.442 3510.023 3492.51\n\ncat(\"\\n Best Model in terms of BIC: \\n\")\n\n\n Best Model in terms of BIC: \n\noutput[which.min(output$BIC),]\n\n  p d q P D Q      AIC     BIC     AICc\n8 0 1 1 0 1 1 3495.035 3508.22 3495.075\n\n\nThe best model with the lowest BIC metric is the SARIMA(0,1,1,0,1,1) model. Although, according to both AIC and AICc metrics, the SARIMA(1,1,1,0,1,1) is better, we shall choose our model using the BIC metric because BIC is more stringent than AIC in penalizing the number of parameters used in the model, making it more effective in helping reduce overfitting. The equation of the SARIMA(0,1,1,0,1,1) model is given by:\n\\(\\begin{equation}(1-B)(1-B^1)y_t = \\delta + (1+\\phi_1B)(1-\\theta_1B-\\theta_2B^2)w_t\\end{equation}\\), where \\((1-B)\\) and \\((1-B^1)\\) are the differencing operators, which represent the first-order difference of the series. \\(y_t\\) is the time series, \\(\\delta\\) is the drift term, \\(\\phi_1\\) and \\(\\theta_1\\), \\(\\theta_2\\) are the parameters of the AR and MA parts, respectively, and \\(w_t\\) is the Gaussian white noise process.\nNote that \\(B\\) is the backshift operator, which shifts the time series back by one period.\n\n\nModel Diagnostics of ARIMA(0,1,1)(0,1,1)\n\nmodel_output <- capture.output(sarima(monthly_attacks_ts, 0,1,1,0,1,1,12))\n\n\n\n\nStandardized Residuals: Essentially stating if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\nACF Of Residuals: However, looking at the ACF of the Residuals gives us a definitive answer to whether the model is stationary. Because some spikes are not within the significance limits, the model is not being able to capture all the signal in the data. In fact, the ARIMA(1,1,2) model’s diagnostics (ARIMA-Diag?) are better than that of ARIMA(0,1,1)(0,1,1) above.\nQ-Q Plot: The series weakly follows a normal distribution as the tails waver away significantly from the normal line.\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value less than 0.05, residuals have remaining autocorrelations.\n\n\nForecast for the next 3 years using ARIMA(0,1,1)(0,1,1)\n\nfit <- Arima(monthly_attacks_ts, order=c(0,1,1), seasonal=c(0,1,1))\nsummary(fit)\n\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n\nfit %>% forecast(h=36) %>% autoplot() #next 3 years\n\n\n\n\n\n\nComparing ARIMA(0,1,1)(0,1,1) with benchmarks\n\ncat(\"Best model metrics: \\n\")\n\nBest model metrics: \n\nfit <- Arima(monthly_attacks_ts, order=c(0,1,1), seasonal=c(0,1,1))\n\nautoplot(monthly_attacks_ts) +\n  autolayer(meanf(monthly_attacks_ts, h=36),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(monthly_attacks_ts, h=36),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(monthly_attacks_ts, h=36),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(monthly_attacks_ts, h=36, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n  autolayer(forecast(fit,36), \n            series=\"fit\",PI=FALSE) +\n  guides(colour=guide_legend(title=\"Forecast\"))\n\n\n\ncat(\"Best model metrics: \\n\")\n\nBest model metrics: \n\nsummary(fit)\n\nSeries: monthly_attacks_ts \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.6661  -0.9261\ns.e.   0.0374   0.0322\n\nsigma^2 = 19.11:  log likelihood = -1744.52\nAIC=3495.03   AICc=3495.07   BIC=3508.22\n\nTraining set error measures:\n                    ME     RMSE      MAE MPE MAPE      MASE       ACF1\nTraining set 0.4707554 4.317518 2.887572 NaN  Inf 0.7582246 0.07436485\n\ncat(\"Snaive metrics: \\n\")\n\nSnaive metrics: \n\nf2 <- snaive(monthly_attacks_ts, h=36) \n\naccuracy(f2)\n\n                     ME     RMSE      MAE  MPE MAPE MASE      ACF1\nTraining set -0.6016667 6.093029 3.808333 -Inf  Inf    1 0.4168619\n\n\n\n\nSeasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 1 step ahead forecasts\n\nk <- 75 # minimum data length for fitting a model \nn <- length(monthly_attacks_ts)\n#n-k # rest of the observations\n\nset.seed(133)\n\nfarima1 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(0,1,1),seasonal=c(0,1,1)), h=h)}\ne <- tsCV(monthly_attacks_ts, farima1, h=1)\n\nMAE1 <-abs(mean(e,na.rm=TRUE))\ncat(\"MAE for ARIMA(0,1,1)(0,1,1) is: \", MAE1)\n\nMAE for ARIMA(0,1,1)(0,1,1) is:  2.155092\n\nRMSE1=sqrt(mean(e^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"\\nRMSE for ARIMA(0,1,1)(0,1,1) is: \", RMSE1)\n\n\nRMSE for ARIMA(0,1,1)(0,1,1) is:  7.428068\n\nfarima2 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(1,1,1),seasonal=c(0,1,1)), h=h)}\ne <- tsCV(monthly_attacks_ts, farima2, h=1)\n\nMAE2 <-abs(mean(e,na.rm=TRUE))\ncat(\"\\nMAE for ARIMA(1,1,1)(0,1,1) is: \", MAE2)\n\n\nMAE for ARIMA(1,1,1)(0,1,1) is:  2.092574\n\nRMSE2=sqrt(mean(e^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"\\nRMSE for ARIMA(1,1,1)(0,1,1) is: \", RMSE2)\n\n\nRMSE for ARIMA(1,1,1)(0,1,1) is:  7.410171\n\n\nBoth MAE and RMSE metrics agree that ARIMA(1,1,1)(0,1,1) is the best model by a slight margin. However, the BIC metric does not agree with this result as it outputted ARIMA(0,1,1)(0,1,1) as the model with lowest BIC. AIC and AICc metrics, however, do agree with the MAE and RMSE metrics generated from Seasonal Cross Validation using 1 step ahead forecasts. Let’s see whether this is the case when forecasting 12 steps ahead.\n\n\nSeasonal Cross Validation of ARIMA(0,1,1)(0,1,1) and ARIMA(1,1,1)(0,1,1) using 12 steps (seasonal period) ahead forecasts\n\nk <- 75 # minimum data length for fitting a model \nn <- length(monthly_attacks_ts)\nn-k # rest of the observations\n\n[1] 537\n\nset.seed(133)\n\nfarima1 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(0,1,1),seasonal=c(0,1,1)), h=h)}\n\n# Compute cross-validated errors for up to 12 steps ahead\ne <- tsCV(monthly_attacks_ts, forecastfunction = farima1, h = 12)\n\nmse1 <- colMeans(e^2, na.rm = TRUE)\n\nfarima2 <- function(x, h){forecast(Arima(monthly_attacks_ts, order=c(1,1,1),seasonal=c(0,1,1)), h=h)}\n# Compute cross-validated errors for up to 12 steps ahead\ne <- tsCV(monthly_attacks_ts, forecastfunction = farima2, h = 12)\n\n# Compute the MSE values and remove missing values\nmse2 <- colMeans(e^2, na.rm = TRUE)\n\n# Plot the MSE values against the forecast horizon\ndata.frame(h = 1:12, MSE1 = mse1, MSE2 = mse2) %>%\n  ggplot() + geom_point(aes(y=MSE1,x= h)) + geom_point(aes(y=MSE2,x= h)) +\n           geom_line(aes(y=MSE1,x= h,colour=\"MSE for ARIMA(0,1,1)(0,1,1)\")) + \n           geom_line(aes(y=MSE2,x= h,colour=\"MSE for ARIMA(1,1,1)(0,1,1)\"))+\n  theme_minimal()\n\n\n\n\nThis plot gives cross-validation statistics up to horizon 12. The procedure for seasonal cross validation using 12 steps ahead is very similar to seasonal cross validation using 1 step ahead. We need to change the “h” parameter to the desired the number of time horizons we want to forecast for. The farima() function manually written by us helps us call our desired SARIMA model with the number of horizons. Then, farima() function is called inside the tsCV() function, which helps us store the cross-validated errors for up to 12 steps ahead. Then, because we get forecasts for each time horizon, we need to take the mean of the squared column using colMeans to obtain MSE.\nAlthough we observed that the MSE and RMSE of ARIMA(1,1,1)(0,1,1) when forecasting 1 step ahead was lower than that of ARIMA(0,1,1)(0,1,1), from the above plot it can be seen that the cross-validated MSEs get lower or better as the number of forecasting steps increases. Both models’ MSE performance follow a very similar pattern, with ARIMA(0,1,1)(0,1,1), picked by lowest BIC, having a lower MSE across all forecasting steps, except for step 1. Therefore, ARIMA(0,1,1)(0,1,1) is the better SARIMA model!"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html",
    "href": "ARIMAX-SARIMAX-VAR.html",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "",
    "text": "In the previous ARIMA/SARIMA modeling section, we analyzed a univariate time series of monthly terrorist attacks in the US that occurred from 1970 to 2020. Although the SARIMA model performed better than the ARIMA model, due to the added seasonal Moving Average term, we can gauge our understanding of the monthly terrorist attacks better by including endogenous variables! Endogenous variables are those that are determined within the system being studied and are influenced by other variables in the system. These variables are typically modeled as being interdependent and are affected by changes in the values of other variables. In the case of terrorist attacks and casualties suffered from them, potential endogenous variables could include USA military expenditure, non-immigrant admissions data, and the performance of major weapons contracts, including Lockheed Martin, Boeing, and Raytheon Technologies. With the help of a literature review, (Lit?) it can be reinforced thoroughly and plausibly that the aforementioned endogenous variables have, in fact, not only been employed but also found to have effects related to terrorism in prior research.\nCode for this section can be found here"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#global-terrorism-database-arima-modeling",
    "href": "ARIMAX-SARIMAX-VAR.html#global-terrorism-database-arima-modeling",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Global Terrorism Database ARIMA Modeling",
    "text": "Global Terrorism Database ARIMA Modeling"
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#Lit",
    "href": "ARIMAX-SARIMAX-VAR.html#Lit",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Literature Review",
    "text": "Literature Review\nThe Stimson Study Group’s Report on Counterterrorism Spending (Counterterrorism Spending and Center 2018) in the post-9/11 era provides valuable insights into the amount of resources the United States devotes to counterterrorism efforts. The report found that the US government spent over USD2.8 trillion on counterterrorism efforts from 2002 to 2017, which represents a significant portion of the country’s overall military budget during that period. Specifically, the report notes that counterterrorism spending accounted for 17% to 23% of the US defense budget each year between 2002 and 2017. Hartung (2021) (Hartung 2021) found that the “Global War on Terror”, which emerged in the early 2000s as a result of the 9/11 attacks, had a significant impact on the political environment, resulting in a surge in the Pentagon’s budget, the largest component of the US military budget. This increased funding was largely directed towards military contractors, Lockheed Martin, Boeing, General Dynamics, Raytheon Technologies, and Northrop Grumman, who were enlisted to aid in the efforts. Since Fiscal Year 2001, the total expenditures of the Pentagon for all purposes have surpassed USD14.1 trillion (measured in 2021 dollars). Out of this sum, USD4.4 trillion was used for weapons procurement and research and development (R&D), which mainly benefited corporate contractors. The rest of the funds were utilized for paying and providing benefits to military and civilian personnel and other expenses, necessary for operating and maintaining the United States military. Congressional Research Service (CRS) estimates that in FY2020, the spending for contractors grew to $420 billion - well over half of the total Pentagon budget. Therefore, the biggest financial beneficiaries of the post-9/11 military spending surge have been the aforementioned weapons contractors.\n\nCounterterrorism Spending, Stimson Study Group on, and Henry L. Stimson Center. 2018. Counterterroism Spending: Protecting America While Promoting Efficiencies and Accountability. Stimson. https://books.google.com/books?id=GQRCzgEACAAJ.\n\nHartung, William D. 2021. “Profits of War: Corporate Beneficiaries of the Post-9/11 Pentagon Spending Surge.” Costs of War. Watson Institute for International; Public Affairs, Brown University. https://watson.brown.edu/costsofwar/files/cow/imce/papers/2021/Profits%20of%20War_Hartung_Costs%20of%20War_Sept%2013%2C%202021.pdf.\n\nLi, Quan, and Drew Schaub. 2004. “Economic Globalization and Transnational Terrorism: A Pooled Time-Series Analysis.” The Journal of Conflict Resolution 48 (2): 230–58. http://www.jstor.org/stable/3176252.\nFurthermore, several papers have discussed and analyzed the relation between military spending or counterterrorism efforts with transnational terrorism prior to the 9/11 attacks. Li and Schaub (2004) (Li and Schaub 2004) employed GOVCAPABILITY, a control variable in their Pooled Time-Series Analysis , that comprised military manpower and military expenditures for 112 countries from 1975 to 1997. Because the variable captured state military and economic strength, it represented a proxy that the government could use for combating terrorism. Gaibulloev, K., Sandler, T., & Sul, D. (2014) (gaibulloev_sandler_sul_2014Such?) challenged extant literature about terrorism and its impact on economic growth that suffered from Nickell Bias, a type of bias that arises in statistical models when the independent variable is measured with error, and cross-sectional dependence, a statistical issue that arises in panel data analysis when the individual units (e.g., countries or firms) in the panel are not completely independent of one another. They mentioned that cross-sectional dependence is apt to affect other variables, such as democracy, threat, military spending, and financial measures. However, when Nickell bias and cross-sectional dependence are addressed, terrorism has no influence whatsoever on economic growth.\nTherefore, the perused literature about counterterrorism and military spending underscores the importance of counterterrorism efforts, including funding weapons contractors, in shaping the country’s military spending priorities, particularly in the wake of the 9/11 terrorist attacks. By highlighting the amount of resources devoted to counterterrorism, these reports and papers help us understand how the overall US budget and military budget are allocated and the policy decisions that drive those allocations. However, it might also possible that during the VAR model building phase of this section, we find that military spending may not be a significant indicator of the number of casualties stemming from terrorist attacks in the Global Terrorism Database™ (GTD) (“Codebook Methodology Inclusion Criteria and Variables - UMD,” n.d.).\n\n“Codebook Methodology Inclusion Criteria and Variables - UMD.” n.d. Global Terrorism Database. University of Maryland. https://www.start.umd.edu/gtd/downloads/Codebook.pdf.\n\nNowrasteh, Alex. 2019. “Terrorists by Immigration Status and Nationality: A Risk Analysis, 1975–2017.” Cato.org. Cato Institute. https://www.cato.org/publications/policy-analysis/terrorists-immigration-status-nationality-risk-analysis-1975-2017#foreign-born-terrorism-risk-for-visas-issued-by-category.\nSecondly, Nowrasteh (2019) (Nowrasteh 2019) found, by carefully analyzing the GTD, that the chance of being murdered by a tourist on a B visa, the most common tourist visa, is about 1 in 4.1 million per year. Compared to foreign‐born terrorists, the chance of being murdered by a native‐born terrorist is about 1 in 28 million per year. Moreover, there were 192 foreign‐born terrorists, relative to the 788 native-born terrorists, who planned, attempted, or carried out attacks on U.S. soil from 1975 through 2017. Through a cost-benefit risk analysis, it was also found that the combined human, property, business, and economic costs of terrorism from 1975 through 2017 are estimated at USD216.58 billion. Spread over 43 years, the average annual cost of terrorism is USD5.04 billion, which is about one‐hundredth the minimum estimated yearly benefit of $553.9 billion from immigration and tourism. Therefore, foreign‐born terrorism on U.S. soil is a low‐probability event that imposes high costs on its victims, despite relatively small risks."
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#var-model-justification",
    "href": "ARIMAX-SARIMAX-VAR.html#var-model-justification",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "VAR Model Justification",
    "text": "VAR Model Justification\nUsing a VAR model over an ARIMAX model for this research has a multitude of benefits, including:\n\nSimultaneous modeling of multivariate time series: VAR allows for the simultaneous modeling of multiple endogenous variables, whereas ARIMAX (Autoregressive Integrated Moving Average with Explanatory Variables) can only model one dependent variable at a time. This means that VAR can capture the complex relationships between multiple variables that may be influencing each other.\nBetter handling of lags: VAR can handle multiple lags in the data more efficiently than ARIMAX. This is important in the case of studying the impact of terrorist attacks, as the effects of a single attack may persist over a longer period of time and may have delayed impacts on different variables.\nMore robust to missing data: VAR can handle missing data more effectively than ARIMAX, as it does not require the same level of complete data in order to estimate the model parameters. This is particularly relevant in the case of studying the impact of terrorist attacks, as data may be missing or incomplete for certain variables in certain time periods.\nBetter captures dynamic relationships: VAR is better suited for capturing the dynamic relationships between variables over time, whereas ARIMAX can only capture the static relationships between variables at a particular point in time. This is important in the case of studying the impact of terrorist attacks, as the relationships between variables may change over time due to factors such as changes in government policies or public opinion.\nNo clear seasonality: Another reason why the VAR model is justified is that there may not be a clear seasonality pattern in the data related to terrorist attacks. This means that traditional time-series models may not be effective in capturing the complex relationships between the variables. The VAR model, on the other hand, does not rely on a specific seasonal pattern and can account for the complex relationships between variables without requiring seasonal adjustments. Moreover, the data that will be analyzed is aggregated yearly from 1970 to 2020, which makes it more difficult to identify and capture seasonal patterns. Yearly data may also be influenced by other factors that are not related to seasonality, such as long-term trends or cyclical patterns, that occur over longer periods of time. This can make it more challenging to distinguish between seasonal effects and other underlying factors that may be driving the data.\nNon-linearity: The relationships between variables in the case of terrorist attacks may not be linear, and traditional linear models may not be able to capture the non-linear effects. The VAR model is capable of modeling non-linear relationships between variables and can account for the complex interactions that may exist between them."
  },
  {
    "objectID": "ARIMAX-SARIMAX-VAR.html#building-the-var-model",
    "href": "ARIMAX-SARIMAX-VAR.html#building-the-var-model",
    "title": "ARIMAX/SARIMAX/VAR Models",
    "section": "Building the VAR Model",
    "text": "Building the VAR Model\n\n\n\n\nTime Series Plots\n\n\n\n\n\n\n\nPairs Plot\n\n\n\n\n\n\n\n\nMulticollinearity! Removing Correlated Variables\n\n\n\n\n\nFitting VAR Model\nHere we use the VARselect() function to find the best p to fit VAR(p). We will choose a maximum lag of 10 and check which p value returns lowest AIC.\n\n\n$selection\nAIC(n)  HQ(n)  SC(n) FPE(n) \n     2      1      1      2 \n\n$criteria\n              1        2        3        4        5        6        7        8\nAIC(n) 1.091791 1.045844 1.204512 1.335694 1.440519 1.577721 1.728764 1.829026\nHQ(n)  1.213545 1.228475 1.448020 1.640078 1.805780 2.003859 2.215779 2.376919\nSC(n)  1.426146 1.547377 1.873223 2.171582 2.443585 2.747965 3.066186 3.333626\nFPE(n) 2.983318 2.857871 3.369113 3.879711 4.374444 5.128738 6.148074 7.078170\n              9       10\nAIC(n) 1.974601 1.548992\nHQ(n)  2.583371 2.218638\nSC(n)  3.646379 3.387947\nFPE(n) 8.637254 6.049901\n\n\nNow, we will fit VAR(1), VAR(2), and VAR(3):\nVAR(1) output:\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_fatal, milexp.gdp \nDeterministic variables: both \nSample size: 50 \nLog Likelihood: -156.054 \nRoots of the characteristic polynomial:\n0.8623 0.08703\nCall:\nVAR(y = var_ts, p = 1, type = \"both\")\n\n\nEstimation results for equation num_fatal: \n========================================== \nnum_fatal = num_fatal.l1 + milexp.gdp.l1 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)  \nnum_fatal.l1  -9.631e-02  1.465e-01  -0.657   0.5143  \nmilexp.gdp.l1 -1.401e+04  7.687e+03  -1.823   0.0749 .\nconst          9.409e+02  5.176e+02   1.818   0.0756 .\ntrend         -6.862e+00  6.433e+00  -1.067   0.2916  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 422.1 on 46 degrees of freedom\nMultiple R-Squared: 0.07287,    Adjusted R-squared: 0.01241 \nF-statistic: 1.205 on 3 and 46 DF,  p-value: 0.3185 \n\n\nEstimation results for equation milexp.gdp: \n=========================================== \nmilexp.gdp = num_fatal.l1 + milexp.gdp.l1 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)    \nnum_fatal.l1   6.347e-07  1.189e-06   0.534    0.596    \nmilexp.gdp.l1  8.716e-01  6.238e-02  13.971   <2e-16 ***\nconst          6.091e-03  4.200e-03   1.450    0.154    \ntrend         -3.141e-05  5.221e-05  -0.602    0.550    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.003425 on 46 degrees of freedom\nMultiple R-Squared: 0.9185, Adjusted R-squared: 0.9132 \nF-statistic: 172.9 on 3 and 46 DF,  p-value: < 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n            num_fatal milexp.gdp\nnum_fatal   1.781e+05 -9.236e-02\nmilexp.gdp -9.236e-02  1.173e-05\n\nCorrelation matrix of residuals:\n           num_fatal milexp.gdp\nnum_fatal    1.00000   -0.06388\nmilexp.gdp  -0.06388    1.00000\n\n\nVAR(2) output:\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_fatal, milexp.gdp \nDeterministic variables: both \nSample size: 49 \nLog Likelihood: -145.735 \nRoots of the characteristic polynomial:\n0.7139 0.5935 0.3244 0.3244\nCall:\nVAR(y = var_ts, p = 2, type = \"both\")\n\n\nEstimation results for equation num_fatal: \n========================================== \nnum_fatal = num_fatal.l1 + milexp.gdp.l1 + num_fatal.l2 + milexp.gdp.l2 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)  \nnum_fatal.l1     -0.1154     0.1512  -0.763   0.4495  \nmilexp.gdp.l1 -7542.4239 18769.9771  -0.402   0.6898  \nnum_fatal.l2     -0.1020     0.1511  -0.675   0.5031  \nmilexp.gdp.l2 -9590.1881 18131.7059  -0.529   0.5996  \nconst          1143.1762   569.6714   2.007   0.0511 .\ntrend            -8.3498     6.8180  -1.225   0.2274  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 431.8 on 43 degrees of freedom\nMultiple R-Squared: 0.09241,    Adjusted R-squared: -0.01312 \nF-statistic: 0.8757 on 5 and 43 DF,  p-value: 0.5054 \n\n\nEstimation results for equation milexp.gdp: \n=========================================== \nmilexp.gdp = num_fatal.l1 + milexp.gdp.l1 + num_fatal.l2 + milexp.gdp.l2 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)    \nnum_fatal.l1   7.472e-07  1.061e-06   0.704  0.48517    \nmilexp.gdp.l1  1.274e+00  1.317e-01   9.673 2.35e-12 ***\nnum_fatal.l2   6.724e-07  1.060e-06   0.634  0.52932    \nmilexp.gdp.l2 -3.739e-01  1.272e-01  -2.938  0.00529 ** \nconst          5.674e-03  3.998e-03   1.419  0.16305    \ntrend         -5.050e-05  4.785e-05  -1.055  0.29711    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.00303 on 43 degrees of freedom\nMultiple R-Squared: 0.9355, Adjusted R-squared: 0.928 \nF-statistic: 124.7 on 5 and 43 DF,  p-value: < 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n            num_fatal milexp.gdp\nnum_fatal   1.865e+05 -8.394e-02\nmilexp.gdp -8.394e-02  9.183e-06\n\nCorrelation matrix of residuals:\n           num_fatal milexp.gdp\nnum_fatal    1.00000   -0.06415\nmilexp.gdp  -0.06415    1.00000\n\n\nVAR(3) output:\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: num_fatal, milexp.gdp \nDeterministic variables: both \nSample size: 48 \nLog Likelihood: -142.005 \nRoots of the characteristic polynomial:\n0.7981 0.7981 0.4925 0.4925 0.4315 0.3136\nCall:\nVAR(y = var_ts, p = 3, type = \"both\")\n\n\nEstimation results for equation num_fatal: \n========================================== \nnum_fatal = num_fatal.l1 + milexp.gdp.l1 + num_fatal.l2 + milexp.gdp.l2 + num_fatal.l3 + milexp.gdp.l3 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)  \nnum_fatal.l1  -1.331e-01  1.571e-01  -0.848   0.4017  \nmilexp.gdp.l1 -3.862e+03  2.260e+04  -0.171   0.8652  \nnum_fatal.l2  -1.239e-01  1.573e-01  -0.787   0.4357  \nmilexp.gdp.l2 -1.181e+04  3.451e+04  -0.342   0.7341  \nnum_fatal.l3  -1.095e-01  1.569e-01  -0.698   0.4892  \nmilexp.gdp.l3 -4.098e+03  2.051e+04  -0.200   0.8427  \nconst          1.310e+03  6.349e+02   2.064   0.0456 *\ntrend         -9.324e+00  7.342e+00  -1.270   0.2114  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 443.6 on 40 degrees of freedom\nMultiple R-Squared: 0.1086, Adjusted R-squared: -0.04738 \nF-statistic: 0.6963 on 7 and 40 DF,  p-value: 0.6747 \n\n\nEstimation results for equation milexp.gdp: \n=========================================== \nmilexp.gdp = num_fatal.l1 + milexp.gdp.l1 + num_fatal.l2 + milexp.gdp.l2 + num_fatal.l3 + milexp.gdp.l3 + const + trend \n\n                Estimate Std. Error t value Pr(>|t|)    \nnum_fatal.l1   5.676e-07  1.084e-06   0.524   0.6034    \nmilexp.gdp.l1  1.205e+00  1.559e-01   7.725 1.87e-09 ***\nnum_fatal.l2   5.849e-07  1.086e-06   0.539   0.5931    \nmilexp.gdp.l2 -1.376e-01  2.382e-01  -0.578   0.5668    \nnum_fatal.l3  -1.487e-07  1.083e-06  -0.137   0.8915    \nmilexp.gdp.l3 -1.966e-01  1.416e-01  -1.388   0.1727    \nconst          7.824e-03  4.381e-03   1.786   0.0817 .  \ntrend         -7.158e-05  5.067e-05  -1.413   0.1654    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.003061 on 40 degrees of freedom\nMultiple R-Squared: 0.9351, Adjusted R-squared: 0.9237 \nF-statistic: 82.28 on 7 and 40 DF,  p-value: < 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n            num_fatal milexp.gdp\nnum_fatal   1.968e+05 -1.064e-01\nmilexp.gdp -1.064e-01  9.371e-06\n\nCorrelation matrix of residuals:\n           num_fatal milexp.gdp\nnum_fatal    1.00000   -0.07837\nmilexp.gdp  -0.07837    1.00000\n\n\n\n\nK-Fold Cross Validation and Model Diagnostics\n\n\n\n\n\nP Values\nRMSE\nAIC\n\n\n\n\n1\n842.84\n226.09\n\n\n2\n869.69\n216.43\n\n\n3\n900.83\n216.98\n\n\n\n\n\nLowest Test RMSE is given by p=1; however, it also has highest AIC score on the train set. Because test set performance is best and it is the simplest model, we shall choose this.\n\n\nForecasting Chosen Model (p=1)\n\n\n$num_fatal\n         fcst     lower    upper       CI\n[1,] 167.6021 -660.8578 996.0621 828.4600\n[2,] 154.4513 -677.8052 986.7077 832.2565\n[3,] 153.3720 -679.9722 986.7162 833.3442\n[4,] 151.6575 -682.5675 985.8825 834.2250\n[5,] 150.1764 -684.7512 985.1041 834.9277\n\n$milexp.gdp\n           fcst      lower      upper          CI\n[1,] 0.03735113 0.03068326 0.04401900 0.006667872\n[2,] 0.03761949 0.02864728 0.04659170 0.008972207\n[3,] 0.03785150 0.02739770 0.04830531 0.010453805\n[4,] 0.03805958 0.02655696 0.04956221 0.011502626\n[5,] 0.03824566 0.02596832 0.05052299 0.012277336"
  },
  {
    "objectID": "ARMA-ARIMA-SARIMA.html#references",
    "href": "ARMA-ARIMA-SARIMA.html#references",
    "title": "ARMA/ARIMA/SARIMA Models",
    "section": "References",
    "text": "References\n“Codebook Methodology Inclusion Criteria and Ariables - UMD.” Codebook Methodology Inclusion criteria and variables - UMD. University of Maryland. Accessed February 1, 2023. https://www.start.umd.edu/gtd/downloads/Codebook.pdf."
  }
]
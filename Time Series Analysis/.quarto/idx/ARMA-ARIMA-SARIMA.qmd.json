{"title":"ARMA/ARIMA/SARIMA Models","markdown":{"yaml":{"title":"ARMA/ARIMA/SARIMA Models","format":{"html":{"page-layout":"full","fontsize":"14px"}},"reference-location":"margin","citation-location":"margin","bibliography":"bibliography.bib"},"headingText":"Summary","containsRefs":false,"markdown":"\n\n\nAfter completing the exploratory data analysis (EDA) phase, the next step is  to begin building time series models. In order to do so, one must first choose an appropriate model type, such as an ARMA (AutoRegressive Moving Average) model or one of its variations, including ARIMA (AutoRegressive Integrated Moving Average) or SARIMA (Seasonal AutoRegressive Integrated Moving Average).\n\nAn ARIMA model is generally notated as ARIMA(p,d,q) where p is the order of the AR process, d is the degree of differencing and q is the order of the MA process. The general equation of the model is given as follows:\n\n$\\phi(B)(1-B)^d x_t = \\delta + \\theta(B) w_t$, \nwhere $B$ is the backshift operator, $w_t$ is the Gaussian white noise process, $\\delta$ is the drift term and $\\phi(B)$ and $\\theta(B)$ correspond to the AR and MA parts respectively.\n\nLag plots, auto-correlation function (ACF) and partial auto-correlation function (PACF) plots, decomposing the time series, and differencing are all useful techniques that were employed during the EDA phase to help inform the choice of model type and parameters. With a solid understanding of the data and its characteristics, one can begin to develop and refine time series models that can be used for forecasting. \n\nCode for this section can be found [here](https://tegveerg.georgetown.domains/Time-Series-Project/ARMA-ARIMA-SARIMA.qmd)\n\n## Global Terrorism Database Time Series Modeling\n\n```{r,include=FALSE, message=FALSE, warning=FALSE}\nlibrary(flipbookr)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(padr)\nlibrary(gridExtra)\n```\n\n```{r load,include=FALSE, message=FALSE, warning=FALSE}\ngtd <- readxl::read_xlsx(\"../Data/gtd.xlsx\")\nsipri_gdp <- readxl::read_xlsx(\"../Data/SIPRI_GDP.xlsx\")\nsipri_region <- readxl::read_xlsx(\"../Data/SIPRI_Region.xlsx\")\ndhs <- readxl::read_xls(\"../Data/DHS_98_21.xls\")\n```\n\n```{r createdate,include=FALSE, message=FALSE, warning=FALSE}\n# if the exact day/month of the event is unknown, this is recorded as “0”\ngtd$Date <- as.Date(with(gtd,paste(iyear,imonth,iday,sep=\"-\")),\"%Y-%m-%d\")\n# results in 891 NAs total, 33 of which correspond to country_txt==USA\n```\n\n```{r filterUS,include=FALSE, message=FALSE, warning=FALSE}\n# Filter country_txt==USA\ngtd_USA <- gtd %>% \n            filter(country_txt==\"United States\")\n\n# drop 33 observations from a total of 3121 observations (if taking for '70)\ngtd_USA <- gtd_USA[complete.cases(gtd_USA$Date),]\n\n# impute missing values for nkill (Total Number of Fatalities: victims and attackers) as 0\n\ngtd_USA$nkill[is.na(gtd_USA$nkill)] <- 0\n\n# select desired columns for analysis\ngtd_USA <- gtd_USA %>% \n              select(Date, provstate, city, \n                     attacktype1_txt, targtype1_txt,\n                     gname, nkill, nkillus, weaptype1_txt)\n```\n\n```{r monthlyattdeath,include=FALSE, message=FALSE, warning=FALSE}\n# new dataframe for monthly number of attacks 1970-2020\ngtd_monthly_attacks_deaths <- gtd_USA %>% \n              group_by(year(Date), month(Date)) %>% \n                  summarise(num_attacks = n(), \n                            nkill=sum(nkill))\n\ncolnames(gtd_monthly_attacks_deaths)[1] =\"Year\"\ncolnames(gtd_monthly_attacks_deaths)[2] =\"Month\"\ncolnames(gtd_monthly_attacks_deaths)[4] =\"num_fatal\"\n\ngtd_monthly_attacks_deaths$Date <- as.Date(paste0(gtd_monthly_attacks_deaths$Year, \"-\", gtd_monthly_attacks_deaths$Month, \"-01\"), \"%Y-%m-%d\")\n\n# Fill missing dates (0 attacks for those dates)\ngtd_monthly_attacks_deaths <- gtd_monthly_attacks_deaths %>% \n              complete(Date = seq.Date(min(Date), max(Date), by=\"month\")) \n\ngtd_monthly_attacks_deaths <- subset(gtd_monthly_attacks_deaths, select=-c(Year, Month))\n\n# create 1993 months -> returns NA's for num_attacks and num_fatal\ngtd_monthly_attacks_deaths <- pad(gtd_monthly_attacks_deaths, by=\"Date\")\n```\n\n```{r interpolateattack, message=FALSE, warning=FALSE, echo=FALSE}\n# interpolating 1993 monthly attacks values (as per GTD only 28 attacks took place)\n\n# fill in NAs with 0 for all years except 1993\ngtd_monthly_attacks_deaths$num_attacks <- ifelse(year(gtd_monthly_attacks_deaths$Date) != 1993 & is.na(gtd_monthly_attacks_deaths$num_attacks), 0, gtd_monthly_attacks_deaths$num_attacks)   \n\n# method 1 of interpolation: 58 estimated total attacks in 1993\nattacks_interp <- approx(gtd_monthly_attacks_deaths$num_attacks[265:276], xout = 1:12)$y + approx(gtd_monthly_attacks_deaths$num_attacks[289:300], xout = 1:12)$y / 2\n\n# method 2 using zoo library: 54 estimated total attacks in 1993 so we use this\n# first create time series object of num_attacks\nmonthly_attacks_ts <- ts(gtd_monthly_attacks_deaths$num_attacks, start = c(1970, 1), frequency = 12)\n\nts_attacks_interp <- na.approx(monthly_attacks_ts) # approximate year 1993 NAs\n\n# round and add up to see how many attacks estimated by approx()\n#cat(\"Number of attacks interpolated for 1993: \", sum(round(ts_attacks_interp[277:288],0)))\n\n# impute use these values in original dataframe\ngtd_monthly_attacks_deaths$num_attacks[277:288] <- round(ts_attacks_interp[277:288],0)\n\n# convert to time series object\nmonthly_attacks_ts <- ts(gtd_monthly_attacks_deaths$num_attacks, start = c(1970, 1), frequency = 12)\n```\n\n### ACF and PACF Plots of Monthly Attacks {#ACF}\n\n```{r pacf, message=FALSE, warning=FALSE, echo=FALSE}\nmonthly_attacks_ts %>% \n  ggtsdisplay(main=\"ACF and PACF Plots of Monthly Attacks\")\n```\n\n### ADF Test of Monthly Attacks \n\n$H_0$: The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\n$H_1$: The time series is stationary.\n\n```{r adf, message=FALSE, warning=FALSE, echo=FALSE}\nadf.test(monthly_attacks_ts)\n```\n\nBecause the p-value from the ADF test is less than $\\alpha$ = 0.05, we reject the null hypothesis and conclude that the monthly attacks series is stationary. Although the ADF states that the original series is stationary, the ACF plots, which clearly indicate seasonality and trend, are more reliable than the ADF test. Therefore, it is safe to conclude that the series non-stationary as per the @ACF section above.\n\n### Log-Transformation of Monthly Attacks\n\n```{r logadf, message=FALSE, warning=FALSE, echo=FALSE}\nlx = log(monthly_attacks_ts+1); dlx = diff(lx); ddlx = diff(dlx, 12)\n\nx = monthly_attacks_ts\n\nplot.ts(cbind(x,lx,dlx,ddlx), main=\"\")\n\npar(mfrow=c(2,1))\nmonthplot(dlx); monthplot(ddlx)\n```\n\nSimply taking log of the number of monthly attacks does not make it stationary. First-differencing the log number of monthly attacks does, however, make the series stationary and this series should be employed for building our time series model. Keep in mind that because first-differencing was enough to make the series stationary, we do not need to second-difference it, helping us avoid over differencing the number of monthly attacks.\n\n### ADF Test of Log First-Differenced Monthly Attacks \n\n$H_0$: The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n\n$H_1$: The time series is stationary.\n\n```{r lfdadf, message=FALSE, warning=FALSE, echo=FALSE}\nadf.test(dlx)\n```\n\nBecause the p-value from the ADF test is less than $\\alpha$ = 0.05, we reject the null hypothesis and conclude that the log first-differenced monthly attacks series is stationary. Let us now check whether the ACF plots supports this hypothesis.\n\n### ACF and PACF Plots of Log First-Differenced Monthly Attacks {#lACF}\n\n```{r lfdpacf, message=FALSE, warning=FALSE, echo=FALSE}\ndlx %>% \n  ggtsdisplay(main=\"ACF and PACF Plots of Log First-Differenced Monthly Attacks\")\n```\n\n\n**p** values obtained from PACF are 1, 2, 3, 4\n**q** values obtained from ACF are: 1 \n**d** (Difference): 1\n\n### Fitting ARIMA(p,d,q) {#best-fit}\n\n```{r, message=FALSE, warning=FALSE, echo=FALSE}\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*12),nrow=12) # roughly nrow = 3x4x2\n\n\nfor (p in 2:4)# p=1,2,3,4 \n{\n  for(q in 2:5)# q=1\n  {\n    for(d in 1)# d=1\n    {\n      \n      if(p-1+d+q-1<=8)\n      {\n        \n        model<- Arima(dlx,order=c(p-1,d,q-1),include.drift=TRUE) \n        ls[i,]= c(p-1,d,q-1,model$aic,model$bic,model$aicc)\n        i=i+1\n        #print(i)\n        \n      }\n      \n    }\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\ntemp <- temp[order(temp$BIC, decreasing = FALSE),] \nknitr::kable(temp)\n\ncat(\"\\n Best Model in terms of AIC: \\n\")\ntemp[which.min(temp$AIC),] \ncat(\"\\n Best Model in terms of AICc: \\n\")\ntemp[which.min(temp$AICc),]\ncat(\"\\n Best Model in terms of BIC: \\n\")\ntemp[which.min(temp$BIC),]\n```\n\nThe best model with the lowest AIC, BIC, and AICc metrics is the ARIMA(1, 1, 2) model. The equation of the model is given by:\n\n$\\begin{equation}(1-B)(1-B^1)y_t = \\delta + (1+\\phi_1B)(1-\\theta_1B-\\theta_2B^2)w_t\\end{equation}$, where $(1-B)$ and $(1-B^1)$ are the differencing operators, which represent the first-order difference of the series. $y_t$ is the time series, $\\delta$ is the drift term, $\\phi_1$ and $\\theta_1$, $\\theta_2$ are the parameters of the AR and MA parts, respectively, and $w_t$ is the Gaussian white noise process.\n\nNote that $B$ is the backshift operator, which shifts the time series back by one period.\n\n### Model Diagnostics of ARIMA(1,1,2)\n\n```{r, message=FALSE, warning=FALSE, echo=FALSE}\nmodel_output <- capture.output(sarima(dlx, 1,1,2))\n```\n\nStandardized Residuals: Essentially stating that if the errors are white noise. The model does look stationary as it captures all the signals and essentially captures the raw white noise.\n\nACF Of Residuals: Auto-correlation of the residuals. The only **q** value to inspect is 1.\n\nQ-Q Plot: The series follows a normal distribution pretty closely as even the tails seem to be on the normal line.\n\np values of the Ljung-Box statistic: Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test be greater than 0.05 because this means the residuals for our time series model are independent, which is often an assumption we make when creating a model. Since all lag values greater than 5 have a p-value greater than 0.05, our series is stationary.\n\n### Checking Model Output of ARIMA(1,1,2) with auto.arima()\n\n```{r, message=FALSE, warning=FALSE, echo=FALSE}\nfit = auto.arima(monthly_attacks_ts, seasonal = FALSE)\ncat(\"Model metrics using auto.arima(): \\n\")\nsummary(fit)\n\nfit <- Arima(dlx, order=c(1,1,2))\ncat(\"\\nModel metrics of ARIMA(1, 1, 2) using Arima(): \\n\")\nsummary(fit)\n```\n\nFrom the above output, `auto.arima()` outputted an ARIMA(1,1,1) model, which is slightly simpler than the best model obtained with the `Arima()` function. In fact, the ARIMA(1,1,1) model was the worst model obtained using the `Arima()` function and that is noted in the table outputted in @best-fit. This difference can be expected when using `auto.arima()` because it is not as reliable as the `Arima()` when building ARIMA models. The case is different when building SARIMA models, which is covered in the next section. \n\nThe best model outputted by `Arima()` performs significantly better than the model outputted by `auto.arima()` in terms of model selection metrics, including AIC, BIC, and AICc. Moreover, the best model outputted by `Arima()` also outperforms the model outputted by `auto.arima()` in terms of training set metrics, including RMSE, MAE, and MAPE. Although the `auto.arima()` model does well to closely match the best `Arima()` model by including a differenced order in its model and by choosing the right **p** or AR order, it does not select an additional MA order that would make the model more robust, as seen by the comparison of metrics. Some points to keep in mind when using these functions is as follows.\n\nThe `auto.arima()` function in R uses a stepwise algorithm to search through the space of possible ARIMA models and select the one with the lowest AIC value. While this approach can be computationally efficient and provide a good starting point for model selection, it does not necessarily find the best possible model for a given time series.\n\nOn the other hand, the `Arima()` function in R allows you to specify the exact order of the ARIMA model and can be used to fit more complex models, such as those with seasonality, exogenous variables, or other constraints. By specifying the exact order of the model, you have more control over the modeling process and can potentially obtain a better fit to the data.\n\nIn summary, the `auto.arima()` function can be a useful tool for quickly identifying a potentially good model, but it is not a substitute for careful model selection and customization using the Arima() function.\n\n### Forecasting ARIMA(1,1,2)\n\n```{r, message=FALSE, warning=FALSE, echo=FALSE}\nsarima.for(dlx, 14, p = 1, d = 1, q = 2)\n```\n\nFrom the above graph, we can note that the number of attacks will fluctuate anywhere between 0 to 6 (converting from log data) every month from 2021 to 2022, as per the 95% confidence bound. A spike is noticed for the first observed forecast after which the model does poorly to forecast the rest of the year. Since the ARIMA(1,1,2) is relatively simple, it is not as robust and complex to forecast more than a month into the future. The straight red line forecast after the first forecasted month suggests that 1 attack per month (converting from log data) would take place, an averaged out value. This is expected. \n\nMoreover, the other suboptimal models outputted by `Arima()` also give the same forecast, so overlaying them onto the above plot would be redundant. It is, however, pragmatic to check whether the `auto.arima()` model's forecast may forecast differently. Let us find out below.\n\n### Forecasting ARIMA(1,1,1) Outputted by auto.arima()\n\n```{r, message=FALSE, warning=FALSE, echo=FALSE}\nsarima.for(dlx, 14, p = 1, d = 1, q = 1)\n```\n\nLike the previous forecast, we can note that, for the `auto.arima()` model, the number of attacks will fluctuate anywhere between 0 to 6 every month from 2021 to 2022 (again this is logged data), as per the 95% confidence bound. However, from the above plot, it can be discerned from red line that the `auto.arima()` model's forecasts fluctuate more for the initial months' forecasts than that of the `Arima()` model's forecasts, which was smoother for the initial 2 months. Like the `Arima()` model's forecasts, the the `auto.arima()` model's forecast then lie on a single value, 1 attack per month, as the red line flattens out. Note that the output of the `auto.arima()` model was ARIMA(1,1,1), so it was expected that the forecast would be slightly less smoother than the ARIMA(1,1,2) model outputted by `Arima()`. This is attributed to the fact that ARIMA(1,1,2) has an additional Moving-Average term, which help make its forecasts smoother.\n\n### Comparing ARIMA(1,1,2) with Benchmarks\n\n```{r, message=FALSE, warning=FALSE, echo=FALSE}\nautoplot(dlx) +\n  autolayer(meanf(dlx, h=36),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(dlx, h=36),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(dlx, h=36),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(dlx, h=36, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n  autolayer(forecast(fit,36), \n            series=\"fit\",PI=FALSE) +\n  guides(colour=guide_legend(title=\"Forecast\"))\n\ncat(\"Best model metrics: \\n\")\nfit <- Arima(dlx, order=c(1,1,2))\nsummary(fit)\n\ncat(\"\\nSnaive metrics: \\n\")\nf2 <- snaive(dlx, h=36) \n\naccuracy(f2)\n```\n\nFrom the above plot, only the Snaive benchmark method's forecasts seem more plausible compared to that of the ARIMA(1,1,2) model. The forecasts produced from the Snaive benchmark have the greatest amount of fluctuations or seasonality in a higher range of number of monthly attacks. However, the metrics paint a different story. The ARIMA(1,1,2) model's training error measures are better than those of the Snaive benchmark. There are several reasons for this phenomenon:\n\nModel Assumptions: The ARIMA model assumes that the data is stationary, which means that the mean and variance of the data do not change over time. If the data violates this assumption, the ARIMA model may not perform well. In contrast, the Snaive model does not assume stationarity, which may make it more robust to non-stationary data.\n\nParameter Estimation: The ARIMA model has three parameters (p, d, q) that need to be estimated, whereas the Snaive model has only one parameter (the seasonality). It is possible that the parameter estimation process for the ARIMA model was not optimal, leading to suboptimal forecast performance.\n\nForecast Horizon: The Snaive model may perform better than the ARIMA model for shorter forecast horizons, while the ARIMA model may perform better for longer forecast horizons. This is because the Snaive model assumes that the future values of the time series will be the same as the past values at the same time of year, which may be a reasonable assumption for short forecast horizons, but not for longer ones."},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"reference-location":"margin","output-file":"ARMA-ARIMA-SARIMA.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","editor":"visual","theme":["lux","custom.scss"],"toc_float":{"collapsed":false,"smooth_scroll":false},"code":true,"title":"ARMA/ARIMA/SARIMA Models","citation-location":"margin","bibliography":["bibliography.bib"],"page-layout":"full","fontsize":"14px"},"extensions":{"book":{"multiFile":true}}}}}